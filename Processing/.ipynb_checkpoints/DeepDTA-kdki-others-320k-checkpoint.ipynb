{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import DeepPurpose.DTI as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *\n",
    "import Processing.dataset_filter as processors\n",
    "\n",
    "if not os.path.exists('./result/DeepDTA'):\n",
    "    os.makedirs('./result/DeepDTA')\n",
    "#Morgan+CNN, CNN+Trans, Morgan+AAC, Daylight+AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 320000 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 183904\n",
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc2ccccc2c1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:52] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:02:52] Can't kekulize mol.  Unkekulized atoms: 1 2 4 5 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1cocc(CN2CCC(CC2)NC(=O)[C@@](O)([C@@H]2CCC(F)(F)C2)c2ccccc2)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:53] Explicit valence for atom # 29 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:02:53] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccoc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:54] Can't kekulize mol.  Unkekulized atoms: 9 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:55] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(F)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:56] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:02:56] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:56] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:02:56] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCNCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CC(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:57] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:02:58] Explicit valence for atom # 31 H, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)C1CC[C@H]1c1nc([H]C(F)F)cc(n1)C(F)F convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:59] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COc1ccccc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:02:59] Explicit valence for atom # 16 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:02:59] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CCCN(CCNC(=O)c2ccc(N[N]3=CN4C=CC=C(N5CCC(O)(CC5)c5ccc(Cl)cc5)C4=N3)cc2)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)CCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:00] Explicit valence for atom # 2 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC[N]1(CC)CCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:01] Can't kekulize mol.  Unkekulized atoms: 8 9 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)nnc1C)[nH]c1ccnc(Cl)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:03] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:03] Explicit valence for atom # 18 N, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(C(=O)N2)c2ccc(cn2)[N](C)(=O)=O)CC1)c1cccc(F)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:04] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1Cl)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:05] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 8 28 29 30 31\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:05] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=C)n1ccc2cc(OCCCN3CCN(CC3)c3cccc4sccc34)ccc2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cccc2nc(CCNC(C)=O)cc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:06] Can't kekulize mol.  Unkekulized atoms: 11 13 14 15 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:06] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 17 18 19 30 31 32\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)[C@]3(C)Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:07] Explicit valence for atom # 33 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cc4ccccc4s1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:07] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:07] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cn1ccc(COc2cc3c(NC([C@@H]4CCCC[C@@H]4C(O)=O)=[N]3Cc3ccc(OC(F)(F)F)cc3F)cc2F)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(Cl)c(Cl)c1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:08] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccnc(Oc2ccc(cc2)-c2c(C)c(=O)nc(=O)n2C)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:08] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2ccccc2o1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:09] Explicit valence for atom # 29 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:09] Can't kekulize mol.  Unkekulized atoms: 16 17 18 19 20 21 22 23 25\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccsc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(F)c(NC(=O)Nc2cnn(c2)-c2cccc3nnc(N)c23)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:09] Can't kekulize mol.  Unkekulized atoms: 3 20 24\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:09] Can't kekulize mol.  Unkekulized atoms: 9 10 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(-c2ccc(Oc3ncccc3C(F)F)cc2)c(C)c(=O)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H]1CCC[C@H](NC(=O)c2nnc(c2C)-c2cccc(Cl)c2F)c2cc(ccn2)-c2ccc(Nc3ccncn3)cc2NC1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:09] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1F)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:10] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 14 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2cc(CCNC(C)=O)nc2c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:10] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:11] Explicit valence for atom # 14 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:12] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC1(CCN(CC1)c1ccc[nH]\\c1=N/[N](=C)Nc1ccc(cc1)C(=O)NC1CCNC1)c1ccc(Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccco1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:12] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(CC(=O)NC[N]3=COC=C3)C(=O)N2CC2CCC2)CC1)c1ccccc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:12] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CC#N convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:13] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:13] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CNc1cc(NC2=CC=C[N](C3CCOCC3)=[C]2=O)nc2c(cnn12)C(=O)N[C@@H]1CCC[C@H](C1)OC convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:15] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccoc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:15] Can't kekulize mol.  Unkekulized atoms: 8 10 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:16] Can't kekulize mol.  Unkekulized atoms: 7 9 10 11 12\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:16] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 17 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:17] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[N]1=CC(N2C(=O)c3c(C2=O)c(NS(=O)(=O)c2ccc(cc2)C(C)(C)C)ccc3Cl)=C(N1)C(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:17] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1=C(C(C)=[N](C)C=N1)c1ccc(Oc2nccc3N(CCc23)C2CCCCO2)cc1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:18] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(F)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:18] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:19] Explicit valence for atom # 33 H, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(C)cc1)C5 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)[C@@H]1CC[C@H]1c1nccc([H]C(F)F)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:19] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC1CCN(CC1)c1cccc2C(N(CCc12)C(=O)C1=NC=C[N](=C1)c1cccc(Cl)c1F)C(=O)Nc1ccc(cc1)C(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:20] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:20] Explicit valence for atom # 8 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C1CCC(CC1)N(=O)C=C)c1cc(cn2cncc12)-c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:21] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:21] Explicit valence for atom # 9 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: On1nnc2cc(CC[N]3=NNN=C3)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:21] Can't kekulize mol.  Unkekulized atoms: 15 17 18 19 20\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:21] Can't kekulize mol.  Unkekulized atoms: 18 19 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:22] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cnc(Oc2ccc(c(C)c2)-c2c(C)c(=O)nc(=O)n2C)c(Cl)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:23] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc(Nc2ccc3ncc(nc3c2C#N)N2CCOCC2)ccc1OCC1=C[N](O)=C(C)C=C1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:23] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16 19 20 21 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:23] Explicit valence for atom # 17 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:23] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)NC3CCNC3)N=C12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1nc2n(CCOCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:24] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(Cl)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:24] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(C)C1=CC=[N](C=C1)C1CCCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:25] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2OCOc2cc1Cl)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:25] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc(COC[C@H]2C[C@]34CC[C@]2(OC)[C@@H]2Oc5c6c(C[C@H]3[N](C)(CC3CC3)CC[C@@]426)ccc5OC)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:26] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 15 18 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:27] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 28 29 30\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC=C)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:28] Can't kekulize mol.  Unkekulized atoms: 1 2 24\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:28] Can't kekulize mol.  Unkekulized atoms: 2 3 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3OC(F)F)cc2)n(C)c(=O)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1c(-c2ccc(Oc3ncccc3Cl)cc2C)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:29] Explicit valence for atom # 1 C, 7, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: N[C]12=34[B]567[B]89%10[B]55%11[B]%12%13%14[B]%15%16%17[B]88([B]169[B]2%158[B]=3%12%16[B]475%13)[C]%10%11%14%17c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:30] Can't kekulize mol.  Unkekulized atoms: 3 4 8\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(c(C)c(=O)nc1=O)-c1ccc(Oc2ncccc2Cl)cc1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:32] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:32] Explicit valence for atom # 17 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: [H][N]1(CC)CCC[C@H](C1)NC(=O)NCCc1ccc(OC(C)C)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)N3CCCCC3c3cccnc3)N=C12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:32] Can't kekulize mol.  Unkekulized atoms: 14 16 17 18 19\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:32] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:32] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(COc2ccc3NC([C@@H]4[C@@H](C(O)=O)C4(C)C)=[N](Cc4ccc(Br)cc4)c3c2)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(Cc2cc(O)c(O)cc2N([O-])=O)cc1O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:33] Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:33] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5 6 7 30 31\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:33] Can't kekulize mol.  Unkekulized atoms: 1 2 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc(F)cc1-c1noc(n1)-c1ccc(N2CCCCC2C)c(c1)N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cccc2cc(OCCCCN3CCN(CC3)c3cccc4sccc34)c(=O)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)F)cc2)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:33] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(C)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:34] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: O[N]1=C(C=CC=C1)c1ccc(cc1)C(=O)NC\\C=C\\CN1CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:34] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:34] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:35] Explicit valence for atom # 29 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Oc1cc(Cc2cc(O)c(O)cc2N([O-])=O)c(cc1O)N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[N]1(C\\C=C\\CNC(=O)c2ccc(cc2)-c2ccccn2)CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:35] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:35] Can't kekulize mol.  Unkekulized atoms: 11 13 14 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)CCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:35] Explicit valence for atom # 30 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:36] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:36] Can't kekulize mol.  Unkekulized atoms: 17 18 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:37] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cccc2cc(CCNC(C)=O)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:38] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:03:38] Can't kekulize mol.  Unkekulized atoms: 21 22 24 25 26\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)noc1C)[nH]c1ccnc(-c3c(C)nnc3-c3ccccc3)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:39] Can't kekulize mol.  Unkekulized atoms: 13 14 15 16 18 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2F)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:41] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(C)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:41] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:44] Explicit valence for atom # 22 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2ncnc(Oc3cccc(NC(=O)NC4=CC(=[N](N4)c4ccccc4)C(F)(F)F)c3)c2cc1OC convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:44] Can't kekulize mol.  Unkekulized atoms: 1 2 27\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)(F)F)c3[nH]ccc23)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:45] Explicit valence for atom # 13 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC1(CCN(CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)NCCc3cccnc3)N=C12)c1ccc(Cl)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:47] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(cc1)C(N)=O)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:47] Can't kekulize mol.  Unkekulized atoms: 12 13 14 16 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3[nH]c(OC)ccc3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:49] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: FC(F)(F)c1cccc(Nc2ccc3C(CCCN4CCOCC4)[N](=Cc3c2)c2ccccc2)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:51] Explicit valence for atom # 19 C, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(C)[C@@H]1N(C)c2cc(ccc2C[C@@H](CO)NC1=O)[C]1234[B]567[B]89%10[B]%11%12%13[B]585[B]%118%11[B]%12%12%14[B]9%139[B]16%10[B]2%129[C]38%14[B]475%11 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:53] Can't kekulize mol.  Unkekulized atoms: 6 7 8 9 10 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=O)NCCc1cc2ccccc2n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:53] Explicit valence for atom # 1 B, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[B]1234[B]567[B]89%10[B]%11%12%13[B]%14%15%16[B]15([B]2%141[B]%11%152=[C]311(CO)[B]8%122[B]4691)[C]7%10%13%16c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:53] Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:53] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OP(O)(=O)CCOCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:55] Explicit valence for atom # 23 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:03:55] non-ring atom 14 marked aromatic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)c1cc(nc(C)n1)C1CCCN(C1)C(=O)c1ccc(N[N]2=CN3C=CC=C(N4CCC(O)(CC4)c4ccc(Cl)cc4)C3=N2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(O)(CS(=O)(=O)c1ccc(F)cc1)[c](=O):c:n-c1ccc(C#N)c(c1)C(F)(F)F convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:56] Can't kekulize mol.  Unkekulized atoms: 20 21 22 23 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[C@H](NC(=O)c1cc(Cn2ccn(C)c2=N)cc(c1F)-c1ccccn1C(F)(F)F)c1ccc(F)c(C)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:57] Explicit valence for atom # 26 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccccc1-c1noc(n1)-c1ccc(-c2ccccc2C)c(c1)N(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:58] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 8 9 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=O)n1cccc2cc(OCCCN3CCN(CC3)c3cccc4sccc34)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:59] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCNCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:03:59] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [12:04:00] Explicit valence for atom # 30 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(nc1)C1CCCN1C(=O)c1ccc(N[N]2=CN3C=CC=C(N4CCC(O)(CC4)c4ccc(Cl)cc4)C3=N2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)(F)CCC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:04:00] Can't kekulize mol.  Unkekulized atoms: 15 16 20\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [12:04:01] Explicit valence for atom # 8 C, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2Cl)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OCC1O[C@H](SC2=C[C](=O)=NC=C2)C(O)[C@H]([C@H]1O)n1cc(nn1)-c1cc(F)c(F)c(F)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:04:02] Can't kekulize mol.  Unkekulized atoms: 41 42 43 44 45\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN1CCN(Cc2ccc(cc2)C(=O)Nc2ccc(C)c(Nc3nccc(n3)-c3cncc(c3)C3=NN=C(C3)C(=O)c3nccn3)c2)CC1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:04:02] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cnc3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [12:04:03] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(COc2ccc3NC(C4[C@@H](C(O)=O)C4(C)C)=[N](Cc4ccc(Br)cc4)c3c2)nc1 convert to all 0 features\n",
      "encoding protein...\n",
      "unique target sequence: 3738\n",
      "splitting dataset...\n",
      "Done.\n",
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 49.8600. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 1.59948. Total time 0.00777 hours\n",
      "Training at Epoch 1 iteration 200 with loss 1.49899. Total time 0.01583 hours\n",
      "Training at Epoch 1 iteration 300 with loss 1.74326. Total time 0.02361 hours\n",
      "Training at Epoch 1 iteration 400 with loss 1.18851. Total time 0.03166 hours\n",
      "Training at Epoch 1 iteration 500 with loss 1.14531. Total time 0.03944 hours\n",
      "Training at Epoch 1 iteration 600 with loss 1.14497. Total time 0.0475 hours\n",
      "Training at Epoch 1 iteration 700 with loss 1.00298. Total time 0.05527 hours\n",
      "Training at Epoch 1 iteration 800 with loss 1.17920. Total time 0.06333 hours\n",
      "Validation at Epoch 1 with loss:1.01398, MSE: 1.03850 , Pearson Correlation: 0.71097 with p-value: 0.00E+00 , Concordance Index: 0.74993\n",
      "Training at Epoch 2 iteration 0 with loss 1.08959. Total time 0.07916 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.84070. Total time 0.08694 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.99777. Total time 0.095 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.97352. Total time 0.10277 hours\n",
      "Training at Epoch 2 iteration 400 with loss 1.03275. Total time 0.11083 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.90750. Total time 0.11861 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.90971. Total time 0.12666 hours\n",
      "Training at Epoch 2 iteration 700 with loss 0.84519. Total time 0.13472 hours\n",
      "Training at Epoch 2 iteration 800 with loss 0.85686. Total time 0.1425 hours\n",
      "Validation at Epoch 2 with loss:0.93171, MSE: 0.95856 , Pearson Correlation: 0.74423 with p-value: 0.00E+00 , Concordance Index: 0.76643\n",
      "Training at Epoch 3 iteration 0 with loss 0.64147. Total time 0.15861 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.78217. Total time 0.16638 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.66207. Total time 0.17444 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.85052. Total time 0.1825 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.78516. Total time 0.19055 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.95819. Total time 0.19833 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.82491. Total time 0.20638 hours\n",
      "Training at Epoch 3 iteration 700 with loss 0.84610. Total time 0.21444 hours\n",
      "Training at Epoch 3 iteration 800 with loss 0.84905. Total time 0.2225 hours\n",
      "Validation at Epoch 3 with loss:0.96011, MSE: 0.96219 , Pearson Correlation: 0.75048 with p-value: 0.00E+00 , Concordance Index: 0.76953\n",
      "Training at Epoch 4 iteration 0 with loss 0.90530. Total time 0.23833 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.79109. Total time 0.24611 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.81368. Total time 0.25416 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.59531. Total time 0.26194 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.71604. Total time 0.27 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.66663. Total time 0.27805 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.80622. Total time 0.28583 hours\n",
      "Training at Epoch 4 iteration 700 with loss 0.90352. Total time 0.29388 hours\n",
      "Training at Epoch 4 iteration 800 with loss 0.85741. Total time 0.30194 hours\n",
      "Validation at Epoch 4 with loss:0.99375, MSE: 0.88890 , Pearson Correlation: 0.76056 with p-value: 0.00E+00 , Concordance Index: 0.77426\n",
      "Training at Epoch 5 iteration 0 with loss 0.74024. Total time 0.31777 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.72821. Total time 0.32555 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.62433. Total time 0.33333 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.75458. Total time 0.34083 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.60215. Total time 0.34861 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.64517. Total time 0.35638 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.83488. Total time 0.36388 hours\n",
      "Training at Epoch 5 iteration 700 with loss 0.68212. Total time 0.37166 hours\n",
      "Training at Epoch 5 iteration 800 with loss 0.64223. Total time 0.37944 hours\n",
      "Validation at Epoch 5 with loss:0.72810, MSE: 0.87246 , Pearson Correlation: 0.77618 with p-value: 0.00E+00 , Concordance Index: 0.78543\n",
      "Training at Epoch 6 iteration 0 with loss 0.57449. Total time 0.395 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.65660. Total time 0.40277 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.48718. Total time 0.41055 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.50314. Total time 0.41833 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.54427. Total time 0.42583 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.54568. Total time 0.43361 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.56263. Total time 0.44138 hours\n",
      "Training at Epoch 6 iteration 700 with loss 0.64001. Total time 0.44916 hours\n",
      "Training at Epoch 6 iteration 800 with loss 0.62782. Total time 0.45666 hours\n",
      "Validation at Epoch 6 with loss:1.04151, MSE: 0.99577 , Pearson Correlation: 0.78354 with p-value: 0.00E+00 , Concordance Index: 0.78958\n",
      "Training at Epoch 7 iteration 0 with loss 0.75076. Total time 0.47222 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.40708. Total time 0.47972 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.55743. Total time 0.4875 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.50995. Total time 0.49527 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.47983. Total time 0.50277 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.49691. Total time 0.51055 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.52733. Total time 0.51805 hours\n",
      "Training at Epoch 7 iteration 700 with loss 0.56972. Total time 0.52583 hours\n",
      "Training at Epoch 7 iteration 800 with loss 0.47765. Total time 0.53361 hours\n",
      "Validation at Epoch 7 with loss:0.70238, MSE: 0.79244 , Pearson Correlation: 0.79166 with p-value: 0.00E+00 , Concordance Index: 0.79587\n",
      "Training at Epoch 8 iteration 0 with loss 0.48361. Total time 0.54916 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.48692. Total time 0.55694 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.48097. Total time 0.56472 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.43746. Total time 0.5725 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.54993. Total time 0.58027 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.43598. Total time 0.58777 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.52154. Total time 0.59555 hours\n",
      "Training at Epoch 8 iteration 700 with loss 0.45078. Total time 0.60333 hours\n",
      "Training at Epoch 8 iteration 800 with loss 0.51770. Total time 0.61111 hours\n",
      "Validation at Epoch 8 with loss:0.65963, MSE: 0.75853 , Pearson Correlation: 0.79944 with p-value: 0.00E+00 , Concordance Index: 0.79923\n",
      "Training at Epoch 9 iteration 0 with loss 0.42166. Total time 0.62666 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.41274. Total time 0.63472 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.43549. Total time 0.6425 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.55301. Total time 0.65 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.42787. Total time 0.65777 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.46097. Total time 0.66555 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.45555. Total time 0.67305 hours\n",
      "Training at Epoch 9 iteration 700 with loss 0.48218. Total time 0.68083 hours\n",
      "Training at Epoch 9 iteration 800 with loss 0.47151. Total time 0.68833 hours\n",
      "Validation at Epoch 9 with loss:0.95673, MSE: 0.77295 , Pearson Correlation: 0.80467 with p-value: 0.00E+00 , Concordance Index: 0.80300\n",
      "Training at Epoch 10 iteration 0 with loss 0.39842. Total time 0.70388 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.34229. Total time 0.71166 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.41247. Total time 0.71916 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.36720. Total time 0.72694 hours\n",
      "Training at Epoch 10 iteration 400 with loss 0.44222. Total time 0.73472 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.39792. Total time 0.7425 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 10 iteration 600 with loss 0.37593. Total time 0.75027 hours\n",
      "Training at Epoch 10 iteration 700 with loss 0.45845. Total time 0.75805 hours\n",
      "Training at Epoch 10 iteration 800 with loss 0.45611. Total time 0.76583 hours\n",
      "Validation at Epoch 10 with loss:0.61994, MSE: 0.73742 , Pearson Correlation: 0.80850 with p-value: 0.00E+00 , Concordance Index: 0.80500\n",
      "Training at Epoch 11 iteration 0 with loss 0.40030. Total time 0.78138 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.31811. Total time 0.78888 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.35918. Total time 0.79666 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.36227. Total time 0.80444 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.35737. Total time 0.81222 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.43811. Total time 0.82 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.36457. Total time 0.82777 hours\n",
      "Training at Epoch 11 iteration 700 with loss 0.42020. Total time 0.83555 hours\n",
      "Training at Epoch 11 iteration 800 with loss 0.49330. Total time 0.84305 hours\n",
      "Validation at Epoch 11 with loss:0.75250, MSE: 0.72216 , Pearson Correlation: 0.81106 with p-value: 0.00E+00 , Concordance Index: 0.80695\n",
      "Training at Epoch 12 iteration 0 with loss 0.29024. Total time 0.85861 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.34354. Total time 0.86666 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.44753. Total time 0.87444 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.38198. Total time 0.88222 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.38758. Total time 0.88972 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.52591. Total time 0.8975 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.35607. Total time 0.90527 hours\n",
      "Training at Epoch 12 iteration 700 with loss 0.38165. Total time 0.91305 hours\n",
      "Training at Epoch 12 iteration 800 with loss 0.36003. Total time 0.92055 hours\n",
      "Validation at Epoch 12 with loss:0.90237, MSE: 0.73231 , Pearson Correlation: 0.80924 with p-value: 0.00E+00 , Concordance Index: 0.80611\n",
      "Training at Epoch 13 iteration 0 with loss 0.36796. Total time 0.93722 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.27955. Total time 0.94472 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.28719. Total time 0.9525 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.28836. Total time 0.96027 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.38242. Total time 0.96805 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.28215. Total time 0.97583 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.36431. Total time 0.98333 hours\n",
      "Training at Epoch 13 iteration 700 with loss 0.35901. Total time 0.99111 hours\n",
      "Training at Epoch 13 iteration 800 with loss 0.34459. Total time 0.99888 hours\n",
      "Validation at Epoch 13 with loss:0.93065, MSE: 0.72226 , Pearson Correlation: 0.81368 with p-value: 0.00E+00 , Concordance Index: 0.80919\n",
      "Training at Epoch 14 iteration 0 with loss 0.34171. Total time 1.01416 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.25310. Total time 1.02194 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.32403. Total time 1.02972 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.25712. Total time 1.03722 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.28667. Total time 1.045 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.29070. Total time 1.05277 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.30356. Total time 1.06027 hours\n",
      "Training at Epoch 14 iteration 700 with loss 0.39135. Total time 1.06805 hours\n",
      "Training at Epoch 14 iteration 800 with loss 0.45618. Total time 1.07583 hours\n",
      "Validation at Epoch 14 with loss:0.71674, MSE: 0.73810 , Pearson Correlation: 0.81143 with p-value: 0.00E+00 , Concordance Index: 0.80811\n",
      "Training at Epoch 15 iteration 0 with loss 0.29436. Total time 1.09111 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.29274. Total time 1.09888 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.28392. Total time 1.10666 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.28469. Total time 1.11444 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.31037. Total time 1.12222 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.32966. Total time 1.13 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.38865. Total time 1.13777 hours\n",
      "Training at Epoch 15 iteration 700 with loss 0.22860. Total time 1.14583 hours\n",
      "Training at Epoch 15 iteration 800 with loss 0.39213. Total time 1.15388 hours\n",
      "Validation at Epoch 15 with loss:0.63257, MSE: 0.70194 , Pearson Correlation: 0.81722 with p-value: 0.00E+00 , Concordance Index: 0.81209\n",
      "Training at Epoch 16 iteration 0 with loss 0.24948. Total time 1.16972 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.30702. Total time 1.1775 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.29939. Total time 1.18555 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.33694. Total time 1.19333 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.25230. Total time 1.20111 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.31537. Total time 1.20888 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.33129. Total time 1.21694 hours\n",
      "Training at Epoch 16 iteration 700 with loss 0.37578. Total time 1.225 hours\n",
      "Training at Epoch 16 iteration 800 with loss 0.23391. Total time 1.23277 hours\n",
      "Validation at Epoch 16 with loss:0.67342, MSE: 0.71307 , Pearson Correlation: 0.81728 with p-value: 0.00E+00 , Concordance Index: 0.81295\n",
      "Training at Epoch 17 iteration 0 with loss 0.27917. Total time 1.24888 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.26018. Total time 1.25666 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.30195. Total time 1.26472 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.26285. Total time 1.2725 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.23259. Total time 1.28055 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.30285. Total time 1.28833 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.27250. Total time 1.29638 hours\n",
      "Training at Epoch 17 iteration 700 with loss 0.28421. Total time 1.30416 hours\n",
      "Training at Epoch 17 iteration 800 with loss 0.24445. Total time 1.31222 hours\n",
      "Validation at Epoch 17 with loss:0.79623, MSE: 0.69194 , Pearson Correlation: 0.82157 with p-value: 0.00E+00 , Concordance Index: 0.81471\n",
      "Training at Epoch 18 iteration 0 with loss 0.23452. Total time 1.32805 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.26102. Total time 1.33583 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.22991. Total time 1.34388 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.25378. Total time 1.35166 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.29963. Total time 1.35972 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.28832. Total time 1.36777 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.26292. Total time 1.37555 hours\n",
      "Training at Epoch 18 iteration 700 with loss 0.21071. Total time 1.38361 hours\n",
      "Training at Epoch 18 iteration 800 with loss 0.28222. Total time 1.39138 hours\n",
      "Validation at Epoch 18 with loss:0.66078, MSE: 0.70089 , Pearson Correlation: 0.81849 with p-value: 0.00E+00 , Concordance Index: 0.81262\n",
      "Training at Epoch 19 iteration 0 with loss 0.24498. Total time 1.4075 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.25119. Total time 1.41527 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.25470. Total time 1.42333 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.26877. Total time 1.43111 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.29992. Total time 1.43888 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.21371. Total time 1.44694 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.24483. Total time 1.45472 hours\n",
      "Training at Epoch 19 iteration 700 with loss 0.26217. Total time 1.46277 hours\n",
      "Training at Epoch 19 iteration 800 with loss 0.23668. Total time 1.47055 hours\n",
      "Validation at Epoch 19 with loss:0.72544, MSE: 0.69160 , Pearson Correlation: 0.82053 with p-value: 0.00E+00 , Concordance Index: 0.81514\n",
      "Training at Epoch 20 iteration 0 with loss 0.25107. Total time 1.48638 hours\n",
      "Training at Epoch 20 iteration 100 with loss 0.21771. Total time 1.49444 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.19257. Total time 1.5025 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 20 iteration 300 with loss 0.25373. Total time 1.51027 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.28430. Total time 1.51833 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.29425. Total time 1.52611 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.22806. Total time 1.53416 hours\n",
      "Training at Epoch 20 iteration 700 with loss 0.23906. Total time 1.54222 hours\n",
      "Training at Epoch 20 iteration 800 with loss 0.20628. Total time 1.55 hours\n",
      "Validation at Epoch 20 with loss:0.82789, MSE: 0.71738 , Pearson Correlation: 0.81893 with p-value: 0.00E+00 , Concordance Index: 0.81350\n",
      "Training at Epoch 21 iteration 0 with loss 0.21862. Total time 1.56611 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.22317. Total time 1.57388 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.24990. Total time 1.58194 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.27201. Total time 1.58972 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.18158. Total time 1.59777 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.19219. Total time 1.60583 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.23331. Total time 1.61361 hours\n",
      "Training at Epoch 21 iteration 700 with loss 0.26454. Total time 1.62166 hours\n",
      "Training at Epoch 21 iteration 800 with loss 0.28578. Total time 1.62972 hours\n",
      "Validation at Epoch 21 with loss:0.86566, MSE: 0.68630 , Pearson Correlation: 0.82295 with p-value: 0.00E+00 , Concordance Index: 0.81578\n",
      "Training at Epoch 22 iteration 0 with loss 0.19724. Total time 1.64583 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.21935. Total time 1.65361 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.22079. Total time 1.66166 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.19777. Total time 1.66972 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.21285. Total time 1.67777 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.21173. Total time 1.68555 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.26940. Total time 1.69333 hours\n",
      "Training at Epoch 22 iteration 700 with loss 0.22472. Total time 1.70083 hours\n",
      "Training at Epoch 22 iteration 800 with loss 0.20773. Total time 1.70833 hours\n",
      "Validation at Epoch 22 with loss:0.79469, MSE: 0.68450 , Pearson Correlation: 0.82274 with p-value: 0.00E+00 , Concordance Index: 0.81594\n",
      "Training at Epoch 23 iteration 0 with loss 0.16224. Total time 1.72388 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.21327. Total time 1.73194 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.13706. Total time 1.73972 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.18624. Total time 1.74777 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.25784. Total time 1.75555 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.22107. Total time 1.76361 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.23974. Total time 1.77166 hours\n",
      "Training at Epoch 23 iteration 700 with loss 0.24084. Total time 1.77944 hours\n",
      "Training at Epoch 23 iteration 800 with loss 0.29643. Total time 1.7875 hours\n",
      "Validation at Epoch 23 with loss:0.68341, MSE: 0.67781 , Pearson Correlation: 0.82329 with p-value: 0.00E+00 , Concordance Index: 0.81657\n",
      "Training at Epoch 24 iteration 0 with loss 0.17046. Total time 1.80416 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.18929. Total time 1.8125 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.17869. Total time 1.82083 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.25020. Total time 1.82916 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.18560. Total time 1.83722 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.20540. Total time 1.845 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.29729. Total time 1.85305 hours\n",
      "Training at Epoch 24 iteration 700 with loss 0.22271. Total time 1.86111 hours\n",
      "Training at Epoch 24 iteration 800 with loss 0.28862. Total time 1.86916 hours\n",
      "Validation at Epoch 24 with loss:0.73174, MSE: 0.69384 , Pearson Correlation: 0.82227 with p-value: 0.00E+00 , Concordance Index: 0.81666\n",
      "Training at Epoch 25 iteration 0 with loss 0.17475. Total time 1.885 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.20749. Total time 1.89277 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.17950. Total time 1.90083 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.16436. Total time 1.90861 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.20782. Total time 1.91666 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.23157. Total time 1.92472 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.22168. Total time 1.93277 hours\n",
      "Training at Epoch 25 iteration 700 with loss 0.21370. Total time 1.94055 hours\n",
      "Training at Epoch 25 iteration 800 with loss 0.18684. Total time 1.94861 hours\n",
      "Validation at Epoch 25 with loss:0.63523, MSE: 0.67874 , Pearson Correlation: 0.82420 with p-value: 0.00E+00 , Concordance Index: 0.81679\n",
      "Training at Epoch 26 iteration 0 with loss 0.16072. Total time 1.96472 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.16485. Total time 1.97277 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.14451. Total time 1.98083 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.17271. Total time 1.98861 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.16069. Total time 1.99638 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.17909. Total time 2.00416 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.19500. Total time 2.01222 hours\n",
      "Training at Epoch 26 iteration 700 with loss 0.21209. Total time 2.02 hours\n",
      "Training at Epoch 26 iteration 800 with loss 0.22583. Total time 2.02777 hours\n",
      "Validation at Epoch 26 with loss:0.52555, MSE: 0.68647 , Pearson Correlation: 0.82512 with p-value: 0.00E+00 , Concordance Index: 0.81787\n",
      "Training at Epoch 27 iteration 0 with loss 0.21862. Total time 2.04416 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.17667. Total time 2.0525 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.13406. Total time 2.06055 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.14684. Total time 2.06861 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.22305. Total time 2.07638 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.22836. Total time 2.08444 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.26329. Total time 2.09222 hours\n",
      "Training at Epoch 27 iteration 700 with loss 0.18384. Total time 2.1 hours\n",
      "Training at Epoch 27 iteration 800 with loss 0.22750. Total time 2.10805 hours\n",
      "Validation at Epoch 27 with loss:0.71950, MSE: 0.69560 , Pearson Correlation: 0.82362 with p-value: 0.00E+00 , Concordance Index: 0.81692\n",
      "Training at Epoch 28 iteration 0 with loss 0.18483. Total time 2.12416 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.17584. Total time 2.13194 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.22109. Total time 2.14 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.17353. Total time 2.14777 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.17064. Total time 2.15583 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.15724. Total time 2.16361 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.20603. Total time 2.17138 hours\n",
      "Training at Epoch 28 iteration 700 with loss 0.12757. Total time 2.17944 hours\n",
      "Training at Epoch 28 iteration 800 with loss 0.15864. Total time 2.18722 hours\n",
      "Validation at Epoch 28 with loss:0.69197, MSE: 0.68533 , Pearson Correlation: 0.82485 with p-value: 0.00E+00 , Concordance Index: 0.81733\n",
      "Training at Epoch 29 iteration 0 with loss 0.23303. Total time 2.20333 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.13967. Total time 2.21111 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.15813. Total time 2.21916 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.15911. Total time 2.22722 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.21430. Total time 2.23527 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.18665. Total time 2.24333 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.20601. Total time 2.25111 hours\n",
      "Training at Epoch 29 iteration 700 with loss 0.21397. Total time 2.25888 hours\n",
      "Training at Epoch 29 iteration 800 with loss 0.26917. Total time 2.26666 hours\n",
      "Validation at Epoch 29 with loss:0.76710, MSE: 0.67459 , Pearson Correlation: 0.82692 with p-value: 0.00E+00 , Concordance Index: 0.81916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 30 iteration 0 with loss 0.17514. Total time 2.28222 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.14048. Total time 2.29027 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.13396. Total time 2.29805 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.15394. Total time 2.30611 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.16141. Total time 2.31416 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.20958. Total time 2.32222 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.16045. Total time 2.33 hours\n",
      "Training at Epoch 30 iteration 700 with loss 0.18600. Total time 2.33805 hours\n",
      "Training at Epoch 30 iteration 800 with loss 0.22023. Total time 2.34611 hours\n",
      "Validation at Epoch 30 with loss:0.68355, MSE: 0.68093 , Pearson Correlation: 0.82380 with p-value: 0.00E+00 , Concordance Index: 0.81700\n",
      "Training at Epoch 31 iteration 0 with loss 0.22294. Total time 2.36222 hours\n",
      "Training at Epoch 31 iteration 100 with loss 0.20909. Total time 2.37 hours\n",
      "Training at Epoch 31 iteration 200 with loss 0.18556. Total time 2.37805 hours\n",
      "Training at Epoch 31 iteration 300 with loss 0.15050. Total time 2.38611 hours\n",
      "Training at Epoch 31 iteration 400 with loss 0.19536. Total time 2.39388 hours\n",
      "Training at Epoch 31 iteration 500 with loss 0.16004. Total time 2.40166 hours\n",
      "Training at Epoch 31 iteration 600 with loss 0.15649. Total time 2.40944 hours\n",
      "Training at Epoch 31 iteration 700 with loss 0.16896. Total time 2.41722 hours\n",
      "Training at Epoch 31 iteration 800 with loss 0.23971. Total time 2.42527 hours\n",
      "Validation at Epoch 31 with loss:0.66287, MSE: 0.68251 , Pearson Correlation: 0.82384 with p-value: 0.00E+00 , Concordance Index: 0.81710\n",
      "Training at Epoch 32 iteration 0 with loss 0.14765. Total time 2.44166 hours\n",
      "Training at Epoch 32 iteration 100 with loss 0.15218. Total time 2.44972 hours\n",
      "Training at Epoch 32 iteration 200 with loss 0.19006. Total time 2.45777 hours\n",
      "Training at Epoch 32 iteration 300 with loss 0.18249. Total time 2.46555 hours\n",
      "Training at Epoch 32 iteration 400 with loss 0.19400. Total time 2.47333 hours\n",
      "Training at Epoch 32 iteration 500 with loss 0.14835. Total time 2.48138 hours\n",
      "Training at Epoch 32 iteration 600 with loss 0.22395. Total time 2.48944 hours\n",
      "Training at Epoch 32 iteration 700 with loss 0.20404. Total time 2.4975 hours\n",
      "Training at Epoch 32 iteration 800 with loss 0.18876. Total time 2.50555 hours\n",
      "Validation at Epoch 32 with loss:0.75557, MSE: 0.69786 , Pearson Correlation: 0.82316 with p-value: 0.00E+00 , Concordance Index: 0.81676\n",
      "Training at Epoch 33 iteration 0 with loss 0.18906. Total time 2.52166 hours\n",
      "Training at Epoch 33 iteration 100 with loss 0.16199. Total time 2.52944 hours\n",
      "Training at Epoch 33 iteration 200 with loss 0.12136. Total time 2.5375 hours\n",
      "Training at Epoch 33 iteration 300 with loss 0.19008. Total time 2.54555 hours\n",
      "Training at Epoch 33 iteration 400 with loss 0.20259. Total time 2.55361 hours\n",
      "Training at Epoch 33 iteration 500 with loss 0.14253. Total time 2.56166 hours\n",
      "Training at Epoch 33 iteration 600 with loss 0.16789. Total time 2.56944 hours\n",
      "Training at Epoch 33 iteration 700 with loss 0.20052. Total time 2.5775 hours\n",
      "Training at Epoch 33 iteration 800 with loss 0.22898. Total time 2.58555 hours\n",
      "Validation at Epoch 33 with loss:0.78659, MSE: 0.70037 , Pearson Correlation: 0.82439 with p-value: 0.00E+00 , Concordance Index: 0.81755\n",
      "Training at Epoch 34 iteration 0 with loss 0.16342. Total time 2.60138 hours\n",
      "Training at Epoch 34 iteration 100 with loss 0.13913. Total time 2.60944 hours\n",
      "Training at Epoch 34 iteration 200 with loss 0.13498. Total time 2.61722 hours\n",
      "Training at Epoch 34 iteration 300 with loss 0.17765. Total time 2.62527 hours\n",
      "Training at Epoch 34 iteration 400 with loss 0.15944. Total time 2.63305 hours\n",
      "Training at Epoch 34 iteration 500 with loss 0.19479. Total time 2.64111 hours\n",
      "Training at Epoch 34 iteration 600 with loss 0.12372. Total time 2.64888 hours\n",
      "Training at Epoch 34 iteration 700 with loss 0.17747. Total time 2.65694 hours\n",
      "Training at Epoch 34 iteration 800 with loss 0.13241. Total time 2.66472 hours\n",
      "Validation at Epoch 34 with loss:0.83270, MSE: 0.68035 , Pearson Correlation: 0.82579 with p-value: 0.00E+00 , Concordance Index: 0.81852\n",
      "Training at Epoch 35 iteration 0 with loss 0.18101. Total time 2.68083 hours\n",
      "Training at Epoch 35 iteration 100 with loss 0.14511. Total time 2.68888 hours\n",
      "Training at Epoch 35 iteration 200 with loss 0.12995. Total time 2.69666 hours\n",
      "Training at Epoch 35 iteration 300 with loss 0.18558. Total time 2.70472 hours\n",
      "Training at Epoch 35 iteration 400 with loss 0.17972. Total time 2.7125 hours\n",
      "Training at Epoch 35 iteration 500 with loss 0.22502. Total time 2.72055 hours\n",
      "Training at Epoch 35 iteration 600 with loss 0.16707. Total time 2.72833 hours\n",
      "Training at Epoch 35 iteration 700 with loss 0.17753. Total time 2.73638 hours\n",
      "Training at Epoch 35 iteration 800 with loss 0.19465. Total time 2.74416 hours\n",
      "Validation at Epoch 35 with loss:0.67161, MSE: 0.66572 , Pearson Correlation: 0.82649 with p-value: 0.00E+00 , Concordance Index: 0.81913\n",
      "Training at Epoch 36 iteration 0 with loss 0.11332. Total time 2.76027 hours\n",
      "Training at Epoch 36 iteration 100 with loss 0.11934. Total time 2.76805 hours\n",
      "Training at Epoch 36 iteration 200 with loss 0.17413. Total time 2.77611 hours\n",
      "Training at Epoch 36 iteration 300 with loss 0.15248. Total time 2.78416 hours\n",
      "Training at Epoch 36 iteration 400 with loss 0.12536. Total time 2.79222 hours\n",
      "Training at Epoch 36 iteration 500 with loss 0.17175. Total time 2.80027 hours\n",
      "Training at Epoch 36 iteration 600 with loss 0.12435. Total time 2.80805 hours\n",
      "Training at Epoch 36 iteration 700 with loss 0.17024. Total time 2.81611 hours\n",
      "Training at Epoch 36 iteration 800 with loss 0.16697. Total time 2.82416 hours\n",
      "Validation at Epoch 36 with loss:0.67610, MSE: 0.69107 , Pearson Correlation: 0.82592 with p-value: 0.00E+00 , Concordance Index: 0.81873\n",
      "Training at Epoch 37 iteration 0 with loss 0.13407. Total time 2.84027 hours\n",
      "Training at Epoch 37 iteration 100 with loss 0.19445. Total time 2.84805 hours\n",
      "Training at Epoch 37 iteration 200 with loss 0.14378. Total time 2.85611 hours\n",
      "Training at Epoch 37 iteration 300 with loss 0.15085. Total time 2.86416 hours\n",
      "Training at Epoch 37 iteration 400 with loss 0.16360. Total time 2.87194 hours\n",
      "Training at Epoch 37 iteration 500 with loss 0.12563. Total time 2.88 hours\n",
      "Training at Epoch 37 iteration 600 with loss 0.15336. Total time 2.88777 hours\n",
      "Training at Epoch 37 iteration 700 with loss 0.17668. Total time 2.89583 hours\n",
      "Training at Epoch 37 iteration 800 with loss 0.21003. Total time 2.90388 hours\n",
      "Validation at Epoch 37 with loss:0.75476, MSE: 0.67333 , Pearson Correlation: 0.82696 with p-value: 0.00E+00 , Concordance Index: 0.81928\n",
      "Training at Epoch 38 iteration 0 with loss 0.18840. Total time 2.92 hours\n",
      "Training at Epoch 38 iteration 100 with loss 0.17004. Total time 2.92777 hours\n",
      "Training at Epoch 38 iteration 200 with loss 0.14818. Total time 2.93583 hours\n",
      "Training at Epoch 38 iteration 300 with loss 0.16880. Total time 2.94361 hours\n",
      "Training at Epoch 38 iteration 400 with loss 0.12926. Total time 2.95166 hours\n",
      "Training at Epoch 38 iteration 500 with loss 0.20174. Total time 2.95972 hours\n",
      "Training at Epoch 38 iteration 600 with loss 0.15549. Total time 2.9675 hours\n",
      "Training at Epoch 38 iteration 700 with loss 0.16977. Total time 2.97555 hours\n",
      "Training at Epoch 38 iteration 800 with loss 0.13586. Total time 2.98333 hours\n",
      "Validation at Epoch 38 with loss:0.58450, MSE: 0.67170 , Pearson Correlation: 0.82655 with p-value: 0.00E+00 , Concordance Index: 0.81902\n",
      "Training at Epoch 39 iteration 0 with loss 0.12313. Total time 2.99944 hours\n",
      "Training at Epoch 39 iteration 100 with loss 0.19913. Total time 3.0075 hours\n",
      "Training at Epoch 39 iteration 200 with loss 0.12838. Total time 3.01555 hours\n",
      "Training at Epoch 39 iteration 300 with loss 0.17370. Total time 3.02333 hours\n",
      "Training at Epoch 39 iteration 400 with loss 0.15678. Total time 3.03138 hours\n",
      "Training at Epoch 39 iteration 500 with loss 0.14399. Total time 3.03944 hours\n",
      "Training at Epoch 39 iteration 600 with loss 0.12804. Total time 3.0475 hours\n",
      "Training at Epoch 39 iteration 700 with loss 0.16450. Total time 3.05527 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 39 iteration 800 with loss 0.15440. Total time 3.06333 hours\n",
      "Validation at Epoch 39 with loss:0.55874, MSE: 0.67728 , Pearson Correlation: 0.82503 with p-value: 0.00E+00 , Concordance Index: 0.81877\n",
      "Training at Epoch 40 iteration 0 with loss 0.12079. Total time 3.07944 hours\n",
      "Training at Epoch 40 iteration 100 with loss 0.10188. Total time 3.0875 hours\n",
      "Training at Epoch 40 iteration 200 with loss 0.14724. Total time 3.09527 hours\n",
      "Training at Epoch 40 iteration 300 with loss 0.13109. Total time 3.10361 hours\n",
      "Training at Epoch 40 iteration 400 with loss 0.13540. Total time 3.11194 hours\n",
      "Training at Epoch 40 iteration 500 with loss 0.15992. Total time 3.12 hours\n",
      "Training at Epoch 40 iteration 600 with loss 0.15038. Total time 3.12805 hours\n",
      "Training at Epoch 40 iteration 700 with loss 0.13058. Total time 3.13583 hours\n",
      "Training at Epoch 40 iteration 800 with loss 0.16925. Total time 3.14388 hours\n",
      "Validation at Epoch 40 with loss:0.61877, MSE: 0.66736 , Pearson Correlation: 0.82587 with p-value: 0.00E+00 , Concordance Index: 0.81897\n",
      "Training at Epoch 41 iteration 0 with loss 0.12188. Total time 3.16 hours\n",
      "Training at Epoch 41 iteration 100 with loss 0.10620. Total time 3.16777 hours\n",
      "Training at Epoch 41 iteration 200 with loss 0.19366. Total time 3.17583 hours\n",
      "Training at Epoch 41 iteration 300 with loss 0.13342. Total time 3.18361 hours\n",
      "Training at Epoch 41 iteration 400 with loss 0.12714. Total time 3.19166 hours\n",
      "Training at Epoch 41 iteration 500 with loss 0.13263. Total time 3.19972 hours\n",
      "Training at Epoch 41 iteration 600 with loss 0.17324. Total time 3.2075 hours\n",
      "Training at Epoch 41 iteration 700 with loss 0.16153. Total time 3.21555 hours\n",
      "Training at Epoch 41 iteration 800 with loss 0.13950. Total time 3.22333 hours\n",
      "Validation at Epoch 41 with loss:0.71227, MSE: 0.68457 , Pearson Correlation: 0.82619 with p-value: 0.00E+00 , Concordance Index: 0.81914\n",
      "Training at Epoch 42 iteration 0 with loss 0.11162. Total time 3.23944 hours\n",
      "Training at Epoch 42 iteration 100 with loss 0.12038. Total time 3.24722 hours\n",
      "Training at Epoch 42 iteration 200 with loss 0.13924. Total time 3.255 hours\n",
      "Training at Epoch 42 iteration 300 with loss 0.11853. Total time 3.26277 hours\n",
      "Training at Epoch 42 iteration 400 with loss 0.11183. Total time 3.27055 hours\n",
      "Training at Epoch 42 iteration 500 with loss 0.17440. Total time 3.27861 hours\n",
      "Training at Epoch 42 iteration 600 with loss 0.16646. Total time 3.28666 hours\n",
      "Training at Epoch 42 iteration 700 with loss 0.12078. Total time 3.29472 hours\n",
      "Training at Epoch 42 iteration 800 with loss 0.12341. Total time 3.3025 hours\n",
      "Validation at Epoch 42 with loss:0.55623, MSE: 0.68661 , Pearson Correlation: 0.82689 with p-value: 0.00E+00 , Concordance Index: 0.81930\n",
      "Training at Epoch 43 iteration 0 with loss 0.11355. Total time 3.31805 hours\n",
      "Training at Epoch 43 iteration 100 with loss 0.13551. Total time 3.32611 hours\n",
      "Training at Epoch 43 iteration 200 with loss 0.13427. Total time 3.33416 hours\n",
      "Training at Epoch 43 iteration 300 with loss 0.10139. Total time 3.3425 hours\n",
      "Training at Epoch 43 iteration 400 with loss 0.11212. Total time 3.35083 hours\n",
      "Training at Epoch 43 iteration 500 with loss 0.17593. Total time 3.35916 hours\n",
      "Training at Epoch 43 iteration 600 with loss 0.10277. Total time 3.3675 hours\n",
      "Training at Epoch 43 iteration 700 with loss 0.11883. Total time 3.37555 hours\n",
      "Training at Epoch 43 iteration 800 with loss 0.15711. Total time 3.38388 hours\n",
      "Validation at Epoch 43 with loss:0.70077, MSE: 0.67325 , Pearson Correlation: 0.82585 with p-value: 0.00E+00 , Concordance Index: 0.81908\n",
      "Training at Epoch 44 iteration 0 with loss 0.09123. Total time 3.40083 hours\n",
      "Training at Epoch 44 iteration 100 with loss 0.09858. Total time 3.40916 hours\n",
      "Training at Epoch 44 iteration 200 with loss 0.10738. Total time 3.4175 hours\n",
      "Training at Epoch 44 iteration 300 with loss 0.13197. Total time 3.42555 hours\n",
      "Training at Epoch 44 iteration 400 with loss 0.10953. Total time 3.43388 hours\n",
      "Training at Epoch 44 iteration 500 with loss 0.15721. Total time 3.44222 hours\n",
      "Training at Epoch 44 iteration 600 with loss 0.13814. Total time 3.45055 hours\n",
      "Training at Epoch 44 iteration 700 with loss 0.21715. Total time 3.45861 hours\n",
      "Training at Epoch 44 iteration 800 with loss 0.14133. Total time 3.46666 hours\n",
      "Validation at Epoch 44 with loss:0.58142, MSE: 0.67538 , Pearson Correlation: 0.82617 with p-value: 0.00E+00 , Concordance Index: 0.81888\n",
      "Training at Epoch 45 iteration 0 with loss 0.12343. Total time 3.48277 hours\n",
      "Training at Epoch 45 iteration 100 with loss 0.12582. Total time 3.49083 hours\n",
      "Training at Epoch 45 iteration 200 with loss 0.14011. Total time 3.49888 hours\n",
      "Training at Epoch 45 iteration 300 with loss 0.11852. Total time 3.50722 hours\n",
      "Training at Epoch 45 iteration 400 with loss 0.11711. Total time 3.51527 hours\n",
      "Training at Epoch 45 iteration 500 with loss 0.11698. Total time 3.52333 hours\n",
      "Training at Epoch 45 iteration 600 with loss 0.11367. Total time 3.53138 hours\n",
      "Training at Epoch 45 iteration 700 with loss 0.10595. Total time 3.53972 hours\n",
      "Training at Epoch 45 iteration 800 with loss 0.12924. Total time 3.54777 hours\n",
      "Validation at Epoch 45 with loss:0.76139, MSE: 0.66121 , Pearson Correlation: 0.82781 with p-value: 0.00E+00 , Concordance Index: 0.81962\n",
      "Training at Epoch 46 iteration 0 with loss 0.11830. Total time 3.56388 hours\n",
      "Training at Epoch 46 iteration 100 with loss 0.14142. Total time 3.57194 hours\n",
      "Training at Epoch 46 iteration 200 with loss 0.14412. Total time 3.58 hours\n",
      "Training at Epoch 46 iteration 300 with loss 0.14919. Total time 3.58805 hours\n",
      "Training at Epoch 46 iteration 400 with loss 0.12569. Total time 3.59611 hours\n",
      "Training at Epoch 46 iteration 500 with loss 0.10731. Total time 3.60444 hours\n",
      "Training at Epoch 46 iteration 600 with loss 0.12587. Total time 3.6125 hours\n",
      "Training at Epoch 46 iteration 700 with loss 0.12102. Total time 3.62055 hours\n",
      "Training at Epoch 46 iteration 800 with loss 0.13768. Total time 3.62861 hours\n",
      "Validation at Epoch 46 with loss:0.67283, MSE: 0.66658 , Pearson Correlation: 0.82712 with p-value: 0.00E+00 , Concordance Index: 0.81953\n",
      "Training at Epoch 47 iteration 0 with loss 0.09344. Total time 3.64472 hours\n",
      "Training at Epoch 47 iteration 100 with loss 0.12736. Total time 3.65277 hours\n",
      "Training at Epoch 47 iteration 200 with loss 0.16538. Total time 3.66083 hours\n",
      "Training at Epoch 47 iteration 300 with loss 0.12388. Total time 3.66888 hours\n",
      "Training at Epoch 47 iteration 400 with loss 0.12326. Total time 3.67694 hours\n",
      "Training at Epoch 47 iteration 500 with loss 0.14289. Total time 3.685 hours\n",
      "Training at Epoch 47 iteration 600 with loss 0.10583. Total time 3.69277 hours\n",
      "Training at Epoch 47 iteration 700 with loss 0.12329. Total time 3.70055 hours\n",
      "Training at Epoch 47 iteration 800 with loss 0.13508. Total time 3.70833 hours\n",
      "Validation at Epoch 47 with loss:0.65997, MSE: 0.66596 , Pearson Correlation: 0.82705 with p-value: 0.00E+00 , Concordance Index: 0.81950\n",
      "Training at Epoch 48 iteration 0 with loss 0.09990. Total time 3.72388 hours\n",
      "Training at Epoch 48 iteration 100 with loss 0.13176. Total time 3.73166 hours\n",
      "Training at Epoch 48 iteration 200 with loss 0.09818. Total time 3.73944 hours\n",
      "Training at Epoch 48 iteration 300 with loss 0.13577. Total time 3.74722 hours\n",
      "Training at Epoch 48 iteration 400 with loss 0.11511. Total time 3.755 hours\n",
      "Training at Epoch 48 iteration 500 with loss 0.16701. Total time 3.76305 hours\n",
      "Training at Epoch 48 iteration 600 with loss 0.12827. Total time 3.77083 hours\n",
      "Training at Epoch 48 iteration 700 with loss 0.15717. Total time 3.77888 hours\n",
      "Training at Epoch 48 iteration 800 with loss 0.10520. Total time 3.78694 hours\n",
      "Validation at Epoch 48 with loss:0.65779, MSE: 0.68379 , Pearson Correlation: 0.82710 with p-value: 0.00E+00 , Concordance Index: 0.81967\n",
      "Training at Epoch 49 iteration 0 with loss 0.11151. Total time 3.80277 hours\n",
      "Training at Epoch 49 iteration 100 with loss 0.10350. Total time 3.81083 hours\n",
      "Training at Epoch 49 iteration 200 with loss 0.12706. Total time 3.81888 hours\n",
      "Training at Epoch 49 iteration 300 with loss 0.11205. Total time 3.82666 hours\n",
      "Training at Epoch 49 iteration 400 with loss 0.12752. Total time 3.83472 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 49 iteration 500 with loss 0.13718. Total time 3.84277 hours\n",
      "Training at Epoch 49 iteration 600 with loss 0.11971. Total time 3.85055 hours\n",
      "Training at Epoch 49 iteration 700 with loss 0.10296. Total time 3.85833 hours\n",
      "Training at Epoch 49 iteration 800 with loss 0.09242. Total time 3.86611 hours\n",
      "Validation at Epoch 49 with loss:0.85778, MSE: 0.66348 , Pearson Correlation: 0.82793 with p-value: 0.00E+00 , Concordance Index: 0.81965\n",
      "Training at Epoch 50 iteration 0 with loss 0.10114. Total time 3.88166 hours\n",
      "Training at Epoch 50 iteration 100 with loss 0.13782. Total time 3.88972 hours\n",
      "Training at Epoch 50 iteration 200 with loss 0.12203. Total time 3.8975 hours\n",
      "Training at Epoch 50 iteration 300 with loss 0.08182. Total time 3.90527 hours\n",
      "Training at Epoch 50 iteration 400 with loss 0.13434. Total time 3.91333 hours\n",
      "Training at Epoch 50 iteration 500 with loss 0.11797. Total time 3.92111 hours\n",
      "Training at Epoch 50 iteration 600 with loss 0.11123. Total time 3.92888 hours\n",
      "Training at Epoch 50 iteration 700 with loss 0.12283. Total time 3.93694 hours\n",
      "Training at Epoch 50 iteration 800 with loss 0.19702. Total time 3.945 hours\n",
      "Validation at Epoch 50 with loss:0.71134, MSE: 0.68279 , Pearson Correlation: 0.82515 with p-value: 0.00E+00 , Concordance Index: 0.81856\n",
      "Training at Epoch 51 iteration 0 with loss 0.12582. Total time 3.96055 hours\n",
      "Training at Epoch 51 iteration 100 with loss 0.13132. Total time 3.96833 hours\n",
      "Training at Epoch 51 iteration 200 with loss 0.12609. Total time 3.97638 hours\n",
      "Training at Epoch 51 iteration 300 with loss 0.12784. Total time 3.98444 hours\n",
      "Training at Epoch 51 iteration 400 with loss 0.11108. Total time 3.9925 hours\n",
      "Training at Epoch 51 iteration 500 with loss 0.10893. Total time 4.00027 hours\n",
      "Training at Epoch 51 iteration 600 with loss 0.13392. Total time 4.00805 hours\n",
      "Training at Epoch 51 iteration 700 with loss 0.11984. Total time 4.01583 hours\n",
      "Training at Epoch 51 iteration 800 with loss 0.14427. Total time 4.02361 hours\n",
      "Validation at Epoch 51 with loss:0.68830, MSE: 0.67578 , Pearson Correlation: 0.82619 with p-value: 0.00E+00 , Concordance Index: 0.81956\n",
      "Training at Epoch 52 iteration 0 with loss 0.07792. Total time 4.03944 hours\n",
      "Training at Epoch 52 iteration 100 with loss 0.13208. Total time 4.04722 hours\n",
      "Training at Epoch 52 iteration 200 with loss 0.14092. Total time 4.055 hours\n",
      "Training at Epoch 52 iteration 300 with loss 0.11803. Total time 4.06277 hours\n",
      "Training at Epoch 52 iteration 400 with loss 0.09193. Total time 4.07055 hours\n",
      "Training at Epoch 52 iteration 500 with loss 0.10032. Total time 4.07861 hours\n",
      "Training at Epoch 52 iteration 600 with loss 0.10894. Total time 4.08638 hours\n",
      "Training at Epoch 52 iteration 700 with loss 0.10993. Total time 4.09444 hours\n",
      "Training at Epoch 52 iteration 800 with loss 0.11005. Total time 4.10277 hours\n",
      "Validation at Epoch 52 with loss:0.60412, MSE: 0.67093 , Pearson Correlation: 0.82651 with p-value: 0.00E+00 , Concordance Index: 0.81921\n",
      "Training at Epoch 53 iteration 0 with loss 0.09794. Total time 4.11888 hours\n",
      "Training at Epoch 53 iteration 100 with loss 0.10790. Total time 4.12666 hours\n",
      "Training at Epoch 53 iteration 200 with loss 0.10796. Total time 4.13444 hours\n",
      "Training at Epoch 53 iteration 300 with loss 0.08838. Total time 4.14222 hours\n",
      "Training at Epoch 53 iteration 400 with loss 0.13707. Total time 4.15 hours\n",
      "Training at Epoch 53 iteration 500 with loss 0.12473. Total time 4.15777 hours\n",
      "Training at Epoch 53 iteration 600 with loss 0.13072. Total time 4.16583 hours\n",
      "Training at Epoch 53 iteration 700 with loss 0.11547. Total time 4.17388 hours\n",
      "Training at Epoch 53 iteration 800 with loss 0.10473. Total time 4.18194 hours\n",
      "Validation at Epoch 53 with loss:0.61047, MSE: 0.67494 , Pearson Correlation: 0.82609 with p-value: 0.00E+00 , Concordance Index: 0.81917\n",
      "Training at Epoch 54 iteration 0 with loss 0.10726. Total time 4.19805 hours\n",
      "Training at Epoch 54 iteration 100 with loss 0.14730. Total time 4.20611 hours\n",
      "Training at Epoch 54 iteration 200 with loss 0.11751. Total time 4.21416 hours\n",
      "Training at Epoch 54 iteration 300 with loss 0.12844. Total time 4.22222 hours\n",
      "Training at Epoch 54 iteration 400 with loss 0.09871. Total time 4.23 hours\n",
      "Training at Epoch 54 iteration 500 with loss 0.11066. Total time 4.23805 hours\n",
      "Training at Epoch 54 iteration 600 with loss 0.10901. Total time 4.24611 hours\n",
      "Training at Epoch 54 iteration 700 with loss 0.13072. Total time 4.25416 hours\n",
      "Training at Epoch 54 iteration 800 with loss 0.11420. Total time 4.26222 hours\n",
      "Validation at Epoch 54 with loss:0.63012, MSE: 0.66326 , Pearson Correlation: 0.82716 with p-value: 0.00E+00 , Concordance Index: 0.82028\n",
      "Training at Epoch 55 iteration 0 with loss 0.08703. Total time 4.27833 hours\n",
      "Training at Epoch 55 iteration 100 with loss 0.08719. Total time 4.28638 hours\n",
      "Training at Epoch 55 iteration 200 with loss 0.12713. Total time 4.29444 hours\n",
      "Training at Epoch 55 iteration 300 with loss 0.11529. Total time 4.30222 hours\n",
      "Training at Epoch 55 iteration 400 with loss 0.12096. Total time 4.31 hours\n",
      "Training at Epoch 55 iteration 500 with loss 0.09480. Total time 4.31777 hours\n",
      "Training at Epoch 55 iteration 600 with loss 0.12288. Total time 4.32555 hours\n",
      "Training at Epoch 55 iteration 700 with loss 0.11500. Total time 4.33333 hours\n",
      "Training at Epoch 55 iteration 800 with loss 0.15841. Total time 4.34111 hours\n",
      "Validation at Epoch 55 with loss:0.71436, MSE: 0.67450 , Pearson Correlation: 0.82687 with p-value: 0.00E+00 , Concordance Index: 0.81997\n",
      "Training at Epoch 56 iteration 0 with loss 0.09519. Total time 4.35694 hours\n",
      "Training at Epoch 56 iteration 100 with loss 0.13979. Total time 4.365 hours\n",
      "Training at Epoch 56 iteration 200 with loss 0.08553. Total time 4.37277 hours\n",
      "Training at Epoch 56 iteration 300 with loss 0.10877. Total time 4.38083 hours\n",
      "Training at Epoch 56 iteration 400 with loss 0.13374. Total time 4.38861 hours\n",
      "Training at Epoch 56 iteration 500 with loss 0.10337. Total time 4.39666 hours\n",
      "Training at Epoch 56 iteration 600 with loss 0.10627. Total time 4.40444 hours\n",
      "Training at Epoch 56 iteration 700 with loss 0.08968. Total time 4.4125 hours\n",
      "Training at Epoch 56 iteration 800 with loss 0.12463. Total time 4.42055 hours\n",
      "Validation at Epoch 56 with loss:0.94673, MSE: 0.68542 , Pearson Correlation: 0.82671 with p-value: 0.00E+00 , Concordance Index: 0.81954\n",
      "Training at Epoch 57 iteration 0 with loss 0.08840. Total time 4.43666 hours\n",
      "Training at Epoch 57 iteration 100 with loss 0.10713. Total time 4.44472 hours\n",
      "Training at Epoch 57 iteration 200 with loss 0.11958. Total time 4.4525 hours\n",
      "Training at Epoch 57 iteration 300 with loss 0.10233. Total time 4.46027 hours\n",
      "Training at Epoch 57 iteration 400 with loss 0.12789. Total time 4.46861 hours\n",
      "Training at Epoch 57 iteration 500 with loss 0.11638. Total time 4.47666 hours\n",
      "Training at Epoch 57 iteration 600 with loss 0.09775. Total time 4.48472 hours\n",
      "Training at Epoch 57 iteration 700 with loss 0.09805. Total time 4.49277 hours\n",
      "Training at Epoch 57 iteration 800 with loss 0.11019. Total time 4.50111 hours\n",
      "Validation at Epoch 57 with loss:0.52456, MSE: 0.67356 , Pearson Correlation: 0.82584 with p-value: 0.00E+00 , Concordance Index: 0.82007\n",
      "Training at Epoch 58 iteration 0 with loss 0.12265. Total time 4.51777 hours\n",
      "Training at Epoch 58 iteration 100 with loss 0.10973. Total time 4.52611 hours\n",
      "Training at Epoch 58 iteration 200 with loss 0.11662. Total time 4.53416 hours\n",
      "Training at Epoch 58 iteration 300 with loss 0.10741. Total time 4.54194 hours\n",
      "Training at Epoch 58 iteration 400 with loss 0.11899. Total time 4.55 hours\n",
      "Training at Epoch 58 iteration 500 with loss 0.10553. Total time 4.55777 hours\n",
      "Training at Epoch 58 iteration 600 with loss 0.08173. Total time 4.56583 hours\n",
      "Training at Epoch 58 iteration 700 with loss 0.09572. Total time 4.57361 hours\n",
      "Training at Epoch 58 iteration 800 with loss 0.10799. Total time 4.58138 hours\n",
      "Validation at Epoch 58 with loss:0.95825, MSE: 0.66757 , Pearson Correlation: 0.82694 with p-value: 0.00E+00 , Concordance Index: 0.81950\n",
      "Training at Epoch 59 iteration 0 with loss 0.09442. Total time 4.59722 hours\n",
      "Training at Epoch 59 iteration 100 with loss 0.08798. Total time 4.605 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 59 iteration 200 with loss 0.08771. Total time 4.61305 hours\n",
      "Training at Epoch 59 iteration 300 with loss 0.10865. Total time 4.62111 hours\n",
      "Training at Epoch 59 iteration 400 with loss 0.11038. Total time 4.62916 hours\n",
      "Training at Epoch 59 iteration 500 with loss 0.13957. Total time 4.63666 hours\n",
      "Training at Epoch 59 iteration 600 with loss 0.16038. Total time 4.64472 hours\n",
      "Training at Epoch 59 iteration 700 with loss 0.11369. Total time 4.6525 hours\n",
      "Training at Epoch 59 iteration 800 with loss 0.11057. Total time 4.66055 hours\n",
      "Validation at Epoch 59 with loss:0.75724, MSE: 0.67479 , Pearson Correlation: 0.82670 with p-value: 0.00E+00 , Concordance Index: 0.81988\n",
      "Training at Epoch 60 iteration 0 with loss 0.09315. Total time 4.67666 hours\n",
      "Training at Epoch 60 iteration 100 with loss 0.11245. Total time 4.68472 hours\n",
      "Training at Epoch 60 iteration 200 with loss 0.10541. Total time 4.6925 hours\n",
      "Training at Epoch 60 iteration 300 with loss 0.12675. Total time 4.70027 hours\n",
      "Training at Epoch 60 iteration 400 with loss 0.15959. Total time 4.70805 hours\n",
      "Training at Epoch 60 iteration 500 with loss 0.08911. Total time 4.71638 hours\n",
      "Training at Epoch 60 iteration 600 with loss 0.12095. Total time 4.72472 hours\n",
      "Training at Epoch 60 iteration 700 with loss 0.12745. Total time 4.73222 hours\n",
      "Training at Epoch 60 iteration 800 with loss 0.13444. Total time 4.74 hours\n",
      "Validation at Epoch 60 with loss:0.63151, MSE: 0.67012 , Pearson Correlation: 0.82674 with p-value: 0.00E+00 , Concordance Index: 0.81976\n",
      "Training at Epoch 61 iteration 0 with loss 0.07899. Total time 4.75555 hours\n",
      "Training at Epoch 61 iteration 100 with loss 0.11081. Total time 4.76333 hours\n",
      "Training at Epoch 61 iteration 200 with loss 0.12712. Total time 4.77111 hours\n",
      "Training at Epoch 61 iteration 300 with loss 0.11701. Total time 4.77916 hours\n",
      "Training at Epoch 61 iteration 400 with loss 0.09835. Total time 4.78694 hours\n",
      "Training at Epoch 61 iteration 500 with loss 0.12018. Total time 4.795 hours\n",
      "Training at Epoch 61 iteration 600 with loss 0.11883. Total time 4.80305 hours\n",
      "Training at Epoch 61 iteration 700 with loss 0.10954. Total time 4.81111 hours\n",
      "Training at Epoch 61 iteration 800 with loss 0.10073. Total time 4.81916 hours\n",
      "Validation at Epoch 61 with loss:0.73234, MSE: 0.67675 , Pearson Correlation: 0.82717 with p-value: 0.00E+00 , Concordance Index: 0.81997\n",
      "Training at Epoch 62 iteration 0 with loss 0.09307. Total time 4.83527 hours\n",
      "Training at Epoch 62 iteration 100 with loss 0.09968. Total time 4.84333 hours\n",
      "Training at Epoch 62 iteration 200 with loss 0.09012. Total time 4.85111 hours\n",
      "Training at Epoch 62 iteration 300 with loss 0.08774. Total time 4.85888 hours\n",
      "Training at Epoch 62 iteration 400 with loss 0.09716. Total time 4.86666 hours\n",
      "Training at Epoch 62 iteration 500 with loss 0.14015. Total time 4.87444 hours\n",
      "Training at Epoch 62 iteration 600 with loss 0.14119. Total time 4.88222 hours\n",
      "Training at Epoch 62 iteration 700 with loss 0.15062. Total time 4.89027 hours\n",
      "Training at Epoch 62 iteration 800 with loss 0.12430. Total time 4.89805 hours\n",
      "Validation at Epoch 62 with loss:0.57629, MSE: 0.67646 , Pearson Correlation: 0.82601 with p-value: 0.00E+00 , Concordance Index: 0.81942\n",
      "Training at Epoch 63 iteration 0 with loss 0.12495. Total time 4.91361 hours\n",
      "Training at Epoch 63 iteration 100 with loss 0.09698. Total time 4.92138 hours\n",
      "Training at Epoch 63 iteration 200 with loss 0.07751. Total time 4.92916 hours\n",
      "Training at Epoch 63 iteration 300 with loss 0.12132. Total time 4.93694 hours\n",
      "Training at Epoch 63 iteration 400 with loss 0.10490. Total time 4.94472 hours\n",
      "Training at Epoch 63 iteration 500 with loss 0.09247. Total time 4.95305 hours\n",
      "Training at Epoch 63 iteration 600 with loss 0.10350. Total time 4.96111 hours\n",
      "Training at Epoch 63 iteration 700 with loss 0.10695. Total time 4.96916 hours\n",
      "Training at Epoch 63 iteration 800 with loss 0.06980. Total time 4.97722 hours\n",
      "Validation at Epoch 63 with loss:0.71778, MSE: 0.67134 , Pearson Correlation: 0.82546 with p-value: 0.00E+00 , Concordance Index: 0.81939\n",
      "Training at Epoch 64 iteration 0 with loss 0.13265. Total time 4.99305 hours\n",
      "Training at Epoch 64 iteration 100 with loss 0.13879. Total time 5.00083 hours\n",
      "Training at Epoch 64 iteration 200 with loss 0.07920. Total time 5.00888 hours\n",
      "Training at Epoch 64 iteration 300 with loss 0.08196. Total time 5.01666 hours\n",
      "Training at Epoch 64 iteration 400 with loss 0.13261. Total time 5.02472 hours\n",
      "Training at Epoch 64 iteration 500 with loss 0.09035. Total time 5.03222 hours\n",
      "Training at Epoch 64 iteration 600 with loss 0.10702. Total time 5.04 hours\n",
      "Training at Epoch 64 iteration 700 with loss 0.10361. Total time 5.04805 hours\n",
      "Training at Epoch 64 iteration 800 with loss 0.08957. Total time 5.05583 hours\n",
      "Validation at Epoch 64 with loss:0.68609, MSE: 0.66964 , Pearson Correlation: 0.82717 with p-value: 0.00E+00 , Concordance Index: 0.82014\n",
      "Training at Epoch 65 iteration 0 with loss 0.09075. Total time 5.07194 hours\n",
      "Training at Epoch 65 iteration 100 with loss 0.10293. Total time 5.07972 hours\n",
      "Training at Epoch 65 iteration 200 with loss 0.11264. Total time 5.0875 hours\n",
      "Training at Epoch 65 iteration 300 with loss 0.11642. Total time 5.095 hours\n",
      "Training at Epoch 65 iteration 400 with loss 0.08477. Total time 5.10277 hours\n",
      "Training at Epoch 65 iteration 500 with loss 0.09331. Total time 5.11055 hours\n",
      "Training at Epoch 65 iteration 600 with loss 0.08977. Total time 5.11805 hours\n",
      "Training at Epoch 65 iteration 700 with loss 0.10359. Total time 5.12583 hours\n",
      "Training at Epoch 65 iteration 800 with loss 0.12452. Total time 5.13361 hours\n",
      "Validation at Epoch 65 with loss:0.54076, MSE: 0.67080 , Pearson Correlation: 0.82673 with p-value: 0.00E+00 , Concordance Index: 0.82012\n",
      "Training at Epoch 66 iteration 0 with loss 0.09811. Total time 5.14916 hours\n",
      "Training at Epoch 66 iteration 100 with loss 0.08316. Total time 5.15722 hours\n",
      "Training at Epoch 66 iteration 200 with loss 0.08060. Total time 5.165 hours\n",
      "Training at Epoch 66 iteration 300 with loss 0.10455. Total time 5.17305 hours\n",
      "Training at Epoch 66 iteration 400 with loss 0.07624. Total time 5.18083 hours\n",
      "Training at Epoch 66 iteration 500 with loss 0.10611. Total time 5.18861 hours\n",
      "Training at Epoch 66 iteration 600 with loss 0.09545. Total time 5.19666 hours\n",
      "Training at Epoch 66 iteration 700 with loss 0.08277. Total time 5.20472 hours\n",
      "Training at Epoch 66 iteration 800 with loss 0.09809. Total time 5.2125 hours\n",
      "Validation at Epoch 66 with loss:0.74259, MSE: 0.67732 , Pearson Correlation: 0.82804 with p-value: 0.00E+00 , Concordance Index: 0.82054\n",
      "Training at Epoch 67 iteration 0 with loss 0.10601. Total time 5.22833 hours\n",
      "Training at Epoch 67 iteration 100 with loss 0.07140. Total time 5.23638 hours\n",
      "Training at Epoch 67 iteration 200 with loss 0.13293. Total time 5.24444 hours\n",
      "Training at Epoch 67 iteration 300 with loss 0.09554. Total time 5.25277 hours\n",
      "Training at Epoch 67 iteration 400 with loss 0.09816. Total time 5.26083 hours\n",
      "Training at Epoch 67 iteration 500 with loss 0.11788. Total time 5.26888 hours\n",
      "Training at Epoch 67 iteration 600 with loss 0.11605. Total time 5.27694 hours\n",
      "Training at Epoch 67 iteration 700 with loss 0.14679. Total time 5.28472 hours\n",
      "Training at Epoch 67 iteration 800 with loss 0.10203. Total time 5.2925 hours\n",
      "Validation at Epoch 67 with loss:0.66422, MSE: 0.66892 , Pearson Correlation: 0.82595 with p-value: 0.00E+00 , Concordance Index: 0.82016\n",
      "Training at Epoch 68 iteration 0 with loss 0.06869. Total time 5.30888 hours\n",
      "Training at Epoch 68 iteration 100 with loss 0.10851. Total time 5.31666 hours\n",
      "Training at Epoch 68 iteration 200 with loss 0.07638. Total time 5.32472 hours\n",
      "Training at Epoch 68 iteration 300 with loss 0.12339. Total time 5.33277 hours\n",
      "Training at Epoch 68 iteration 400 with loss 0.11701. Total time 5.34083 hours\n",
      "Training at Epoch 68 iteration 500 with loss 0.08669. Total time 5.34888 hours\n",
      "Training at Epoch 68 iteration 600 with loss 0.10209. Total time 5.35694 hours\n",
      "Training at Epoch 68 iteration 700 with loss 0.10733. Total time 5.36472 hours\n",
      "Training at Epoch 68 iteration 800 with loss 0.09583. Total time 5.3725 hours\n",
      "Validation at Epoch 68 with loss:0.73814, MSE: 0.66894 , Pearson Correlation: 0.82722 with p-value: 0.00E+00 , Concordance Index: 0.82013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 69 iteration 0 with loss 0.09355. Total time 5.38833 hours\n",
      "Training at Epoch 69 iteration 100 with loss 0.10197. Total time 5.39611 hours\n",
      "Training at Epoch 69 iteration 200 with loss 0.08747. Total time 5.40416 hours\n",
      "Training at Epoch 69 iteration 300 with loss 0.11351. Total time 5.41194 hours\n",
      "Training at Epoch 69 iteration 400 with loss 0.10161. Total time 5.41972 hours\n",
      "Training at Epoch 69 iteration 500 with loss 0.09117. Total time 5.4275 hours\n",
      "Training at Epoch 69 iteration 600 with loss 0.10690. Total time 5.43527 hours\n",
      "Training at Epoch 69 iteration 700 with loss 0.09163. Total time 5.44333 hours\n",
      "Training at Epoch 69 iteration 800 with loss 0.09281. Total time 5.45111 hours\n",
      "Validation at Epoch 69 with loss:0.73507, MSE: 0.67952 , Pearson Correlation: 0.82648 with p-value: 0.00E+00 , Concordance Index: 0.81975\n",
      "Training at Epoch 70 iteration 0 with loss 0.10630. Total time 5.46666 hours\n",
      "Training at Epoch 70 iteration 100 with loss 0.08476. Total time 5.47444 hours\n",
      "Training at Epoch 70 iteration 200 with loss 0.08215. Total time 5.48222 hours\n",
      "Training at Epoch 70 iteration 300 with loss 0.11006. Total time 5.49 hours\n",
      "Training at Epoch 70 iteration 400 with loss 0.10608. Total time 5.49777 hours\n",
      "Training at Epoch 70 iteration 500 with loss 0.10799. Total time 5.50555 hours\n",
      "Training at Epoch 70 iteration 600 with loss 0.10006. Total time 5.51333 hours\n",
      "Training at Epoch 70 iteration 700 with loss 0.08267. Total time 5.52111 hours\n",
      "Training at Epoch 70 iteration 800 with loss 0.11346. Total time 5.52888 hours\n",
      "Validation at Epoch 70 with loss:0.66840, MSE: 0.68222 , Pearson Correlation: 0.82584 with p-value: 0.00E+00 , Concordance Index: 0.81966\n",
      "Training at Epoch 71 iteration 0 with loss 0.06077. Total time 5.54444 hours\n",
      "Training at Epoch 71 iteration 100 with loss 0.07891. Total time 5.5525 hours\n",
      "Training at Epoch 71 iteration 200 with loss 0.08704. Total time 5.56055 hours\n",
      "Training at Epoch 71 iteration 300 with loss 0.06518. Total time 5.56833 hours\n",
      "Training at Epoch 71 iteration 400 with loss 0.08988. Total time 5.57611 hours\n",
      "Training at Epoch 71 iteration 500 with loss 0.08288. Total time 5.58388 hours\n",
      "Training at Epoch 71 iteration 600 with loss 0.09168. Total time 5.59166 hours\n",
      "Training at Epoch 71 iteration 700 with loss 0.09666. Total time 5.59972 hours\n",
      "Training at Epoch 71 iteration 800 with loss 0.10756. Total time 5.60777 hours\n",
      "Validation at Epoch 71 with loss:0.86398, MSE: 0.68117 , Pearson Correlation: 0.82612 with p-value: 0.00E+00 , Concordance Index: 0.81951\n",
      "Training at Epoch 72 iteration 0 with loss 0.08904. Total time 5.62333 hours\n",
      "Training at Epoch 72 iteration 100 with loss 0.10287. Total time 5.63083 hours\n",
      "Training at Epoch 72 iteration 200 with loss 0.10465. Total time 5.63861 hours\n",
      "Training at Epoch 72 iteration 300 with loss 0.10617. Total time 5.64638 hours\n",
      "Training at Epoch 72 iteration 400 with loss 0.08467. Total time 5.65416 hours\n",
      "Training at Epoch 72 iteration 500 with loss 0.09330. Total time 5.66222 hours\n",
      "Training at Epoch 72 iteration 600 with loss 0.09609. Total time 5.67027 hours\n",
      "Training at Epoch 72 iteration 700 with loss 0.11000. Total time 5.67833 hours\n",
      "Training at Epoch 72 iteration 800 with loss 0.09978. Total time 5.68611 hours\n",
      "Validation at Epoch 72 with loss:0.71137, MSE: 0.67242 , Pearson Correlation: 0.82673 with p-value: 0.00E+00 , Concordance Index: 0.81993\n",
      "Training at Epoch 73 iteration 0 with loss 0.09868. Total time 5.70166 hours\n",
      "Training at Epoch 73 iteration 100 with loss 0.09347. Total time 5.70944 hours\n",
      "Training at Epoch 73 iteration 200 with loss 0.08734. Total time 5.71694 hours\n",
      "Training at Epoch 73 iteration 300 with loss 0.08084. Total time 5.72472 hours\n",
      "Training at Epoch 73 iteration 400 with loss 0.07799. Total time 5.7325 hours\n",
      "Training at Epoch 73 iteration 500 with loss 0.09615. Total time 5.74083 hours\n",
      "Training at Epoch 73 iteration 600 with loss 0.09269. Total time 5.74861 hours\n",
      "Training at Epoch 73 iteration 700 with loss 0.11647. Total time 5.75694 hours\n",
      "Training at Epoch 73 iteration 800 with loss 0.10773. Total time 5.76472 hours\n",
      "Validation at Epoch 73 with loss:0.59397, MSE: 0.67266 , Pearson Correlation: 0.82611 with p-value: 0.00E+00 , Concordance Index: 0.81960\n",
      "Training at Epoch 74 iteration 0 with loss 0.07657. Total time 5.78111 hours\n",
      "Training at Epoch 74 iteration 100 with loss 0.07769. Total time 5.78888 hours\n",
      "Training at Epoch 74 iteration 200 with loss 0.07915. Total time 5.79666 hours\n",
      "Training at Epoch 74 iteration 300 with loss 0.13098. Total time 5.80472 hours\n",
      "Training at Epoch 74 iteration 400 with loss 0.10031. Total time 5.81277 hours\n",
      "Training at Epoch 74 iteration 500 with loss 0.13723. Total time 5.82055 hours\n",
      "Training at Epoch 74 iteration 600 with loss 0.10181. Total time 5.82833 hours\n",
      "Training at Epoch 74 iteration 700 with loss 0.10840. Total time 5.83611 hours\n",
      "Training at Epoch 74 iteration 800 with loss 0.11616. Total time 5.84388 hours\n",
      "Validation at Epoch 74 with loss:0.61798, MSE: 0.68212 , Pearson Correlation: 0.82755 with p-value: 0.00E+00 , Concordance Index: 0.82018\n",
      "Training at Epoch 75 iteration 0 with loss 0.10383. Total time 5.85944 hours\n",
      "Training at Epoch 75 iteration 100 with loss 0.06607. Total time 5.8675 hours\n",
      "Training at Epoch 75 iteration 200 with loss 0.09795. Total time 5.87527 hours\n",
      "Training at Epoch 75 iteration 300 with loss 0.11915. Total time 5.88305 hours\n",
      "Training at Epoch 75 iteration 400 with loss 0.10619. Total time 5.89111 hours\n",
      "Training at Epoch 75 iteration 500 with loss 0.08620. Total time 5.89888 hours\n",
      "Training at Epoch 75 iteration 600 with loss 0.13077. Total time 5.90666 hours\n",
      "Training at Epoch 75 iteration 700 with loss 0.10107. Total time 5.91472 hours\n",
      "Training at Epoch 75 iteration 800 with loss 0.09360. Total time 5.9225 hours\n",
      "Validation at Epoch 75 with loss:0.65290, MSE: 0.67539 , Pearson Correlation: 0.82589 with p-value: 0.00E+00 , Concordance Index: 0.81930\n",
      "Training at Epoch 76 iteration 0 with loss 0.07922. Total time 5.93833 hours\n",
      "Training at Epoch 76 iteration 100 with loss 0.07373. Total time 5.94611 hours\n",
      "Training at Epoch 76 iteration 200 with loss 0.08646. Total time 5.95388 hours\n",
      "Training at Epoch 76 iteration 300 with loss 0.09639. Total time 5.96166 hours\n",
      "Training at Epoch 76 iteration 400 with loss 0.08839. Total time 5.96972 hours\n",
      "Training at Epoch 76 iteration 500 with loss 0.11832. Total time 5.9775 hours\n",
      "Training at Epoch 76 iteration 600 with loss 0.08337. Total time 5.98527 hours\n",
      "Training at Epoch 76 iteration 700 with loss 0.12482. Total time 5.99305 hours\n",
      "Training at Epoch 76 iteration 800 with loss 0.12653. Total time 6.00138 hours\n",
      "Validation at Epoch 76 with loss:0.60473, MSE: 0.67473 , Pearson Correlation: 0.82671 with p-value: 0.00E+00 , Concordance Index: 0.81993\n",
      "Training at Epoch 77 iteration 0 with loss 0.09714. Total time 6.01777 hours\n",
      "Training at Epoch 77 iteration 100 with loss 0.10293. Total time 6.02527 hours\n",
      "Training at Epoch 77 iteration 200 with loss 0.09666. Total time 6.03305 hours\n",
      "Training at Epoch 77 iteration 300 with loss 0.08789. Total time 6.04083 hours\n",
      "Training at Epoch 77 iteration 400 with loss 0.10499. Total time 6.04861 hours\n",
      "Training at Epoch 77 iteration 500 with loss 0.06728. Total time 6.05666 hours\n",
      "Training at Epoch 77 iteration 600 with loss 0.11627. Total time 6.06444 hours\n",
      "Training at Epoch 77 iteration 700 with loss 0.08702. Total time 6.07222 hours\n",
      "Training at Epoch 77 iteration 800 with loss 0.09260. Total time 6.08 hours\n",
      "Validation at Epoch 77 with loss:0.62321, MSE: 0.67187 , Pearson Correlation: 0.82669 with p-value: 0.00E+00 , Concordance Index: 0.81982\n",
      "Training at Epoch 78 iteration 0 with loss 0.09764. Total time 6.09583 hours\n",
      "Training at Epoch 78 iteration 100 with loss 0.08714. Total time 6.10388 hours\n",
      "Training at Epoch 78 iteration 200 with loss 0.08516. Total time 6.11166 hours\n",
      "Training at Epoch 78 iteration 300 with loss 0.12846. Total time 6.11944 hours\n",
      "Training at Epoch 78 iteration 400 with loss 0.07819. Total time 6.12722 hours\n",
      "Training at Epoch 78 iteration 500 with loss 0.10959. Total time 6.13527 hours\n",
      "Training at Epoch 78 iteration 600 with loss 0.08166. Total time 6.14305 hours\n",
      "Training at Epoch 78 iteration 700 with loss 0.07414. Total time 6.15083 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 78 iteration 800 with loss 0.09837. Total time 6.15888 hours\n",
      "Validation at Epoch 78 with loss:0.55997, MSE: 0.67592 , Pearson Correlation: 0.82887 with p-value: 0.00E+00 , Concordance Index: 0.82066\n",
      "Training at Epoch 79 iteration 0 with loss 0.07721. Total time 6.17444 hours\n",
      "Training at Epoch 79 iteration 100 with loss 0.08748. Total time 6.18222 hours\n",
      "Training at Epoch 79 iteration 200 with loss 0.09591. Total time 6.19 hours\n",
      "Training at Epoch 79 iteration 300 with loss 0.08437. Total time 6.19777 hours\n",
      "Training at Epoch 79 iteration 400 with loss 0.09760. Total time 6.20527 hours\n",
      "Training at Epoch 79 iteration 500 with loss 0.08948. Total time 6.21305 hours\n",
      "Training at Epoch 79 iteration 600 with loss 0.08939. Total time 6.22083 hours\n",
      "Training at Epoch 79 iteration 700 with loss 0.10312. Total time 6.22861 hours\n",
      "Training at Epoch 79 iteration 800 with loss 0.08662. Total time 6.23638 hours\n",
      "Validation at Epoch 79 with loss:0.56781, MSE: 0.66761 , Pearson Correlation: 0.82739 with p-value: 0.00E+00 , Concordance Index: 0.82041\n",
      "Training at Epoch 80 iteration 0 with loss 0.09045. Total time 6.25194 hours\n",
      "Training at Epoch 80 iteration 100 with loss 0.08037. Total time 6.25972 hours\n",
      "Training at Epoch 80 iteration 200 with loss 0.10746. Total time 6.2675 hours\n",
      "Training at Epoch 80 iteration 300 with loss 0.09844. Total time 6.27555 hours\n",
      "Training at Epoch 80 iteration 400 with loss 0.08661. Total time 6.28361 hours\n",
      "Training at Epoch 80 iteration 500 with loss 0.09096. Total time 6.29166 hours\n",
      "Training at Epoch 80 iteration 600 with loss 0.07816. Total time 6.29944 hours\n",
      "Training at Epoch 80 iteration 700 with loss 0.08679. Total time 6.30722 hours\n",
      "Training at Epoch 80 iteration 800 with loss 0.08000. Total time 6.315 hours\n",
      "Validation at Epoch 80 with loss:0.80763, MSE: 0.67079 , Pearson Correlation: 0.82643 with p-value: 0.00E+00 , Concordance Index: 0.81988\n",
      "Training at Epoch 81 iteration 0 with loss 0.10079. Total time 6.33055 hours\n",
      "Training at Epoch 81 iteration 100 with loss 0.09291. Total time 6.33861 hours\n",
      "Training at Epoch 81 iteration 200 with loss 0.09007. Total time 6.34666 hours\n",
      "Training at Epoch 81 iteration 300 with loss 0.07545. Total time 6.35472 hours\n",
      "Training at Epoch 81 iteration 400 with loss 0.10548. Total time 6.3625 hours\n",
      "Training at Epoch 81 iteration 500 with loss 0.08951. Total time 6.37027 hours\n",
      "Training at Epoch 81 iteration 600 with loss 0.10371. Total time 6.37805 hours\n",
      "Training at Epoch 81 iteration 700 with loss 0.09215. Total time 6.38583 hours\n",
      "Training at Epoch 81 iteration 800 with loss 0.10102. Total time 6.39361 hours\n",
      "Validation at Epoch 81 with loss:0.75002, MSE: 0.68099 , Pearson Correlation: 0.82644 with p-value: 0.00E+00 , Concordance Index: 0.81950\n",
      "Training at Epoch 82 iteration 0 with loss 0.06575. Total time 6.40944 hours\n",
      "Training at Epoch 82 iteration 100 with loss 0.07347. Total time 6.41722 hours\n",
      "Training at Epoch 82 iteration 200 with loss 0.06549. Total time 6.425 hours\n",
      "Training at Epoch 82 iteration 300 with loss 0.08414. Total time 6.43277 hours\n",
      "Training at Epoch 82 iteration 400 with loss 0.07851. Total time 6.44055 hours\n",
      "Training at Epoch 82 iteration 500 with loss 0.09244. Total time 6.44833 hours\n",
      "Training at Epoch 82 iteration 600 with loss 0.12314. Total time 6.45611 hours\n",
      "Training at Epoch 82 iteration 700 with loss 0.08347. Total time 6.46416 hours\n",
      "Training at Epoch 82 iteration 800 with loss 0.10564. Total time 6.4725 hours\n",
      "Validation at Epoch 82 with loss:0.59314, MSE: 0.67846 , Pearson Correlation: 0.82629 with p-value: 0.00E+00 , Concordance Index: 0.81944\n",
      "Training at Epoch 83 iteration 0 with loss 0.09433. Total time 6.48833 hours\n",
      "Training at Epoch 83 iteration 100 with loss 0.08927. Total time 6.49611 hours\n",
      "Training at Epoch 83 iteration 200 with loss 0.06268. Total time 6.50416 hours\n",
      "Training at Epoch 83 iteration 300 with loss 0.08981. Total time 6.51194 hours\n",
      "Training at Epoch 83 iteration 400 with loss 0.09924. Total time 6.51972 hours\n",
      "Training at Epoch 83 iteration 500 with loss 0.06890. Total time 6.5275 hours\n",
      "Training at Epoch 83 iteration 600 with loss 0.07137. Total time 6.53527 hours\n",
      "Training at Epoch 83 iteration 700 with loss 0.06751. Total time 6.54333 hours\n",
      "Training at Epoch 83 iteration 800 with loss 0.10664. Total time 6.55166 hours\n",
      "Validation at Epoch 83 with loss:0.70899, MSE: 0.66960 , Pearson Correlation: 0.82694 with p-value: 0.00E+00 , Concordance Index: 0.81984\n",
      "Training at Epoch 84 iteration 0 with loss 0.06969. Total time 6.5675 hours\n",
      "Training at Epoch 84 iteration 100 with loss 0.07674. Total time 6.57555 hours\n",
      "Training at Epoch 84 iteration 200 with loss 0.06784. Total time 6.58333 hours\n",
      "Training at Epoch 84 iteration 300 with loss 0.08518. Total time 6.59111 hours\n",
      "Training at Epoch 84 iteration 400 with loss 0.07884. Total time 6.59888 hours\n",
      "Training at Epoch 84 iteration 500 with loss 0.09118. Total time 6.60666 hours\n",
      "Training at Epoch 84 iteration 600 with loss 0.08019. Total time 6.61472 hours\n",
      "Training at Epoch 84 iteration 700 with loss 0.11680. Total time 6.62277 hours\n",
      "Training at Epoch 84 iteration 800 with loss 0.07433. Total time 6.63055 hours\n",
      "Validation at Epoch 84 with loss:0.54719, MSE: 0.67375 , Pearson Correlation: 0.82684 with p-value: 0.00E+00 , Concordance Index: 0.81957\n",
      "Training at Epoch 85 iteration 0 with loss 0.07152. Total time 6.64666 hours\n",
      "Training at Epoch 85 iteration 100 with loss 0.07479. Total time 6.65472 hours\n",
      "Training at Epoch 85 iteration 200 with loss 0.06795. Total time 6.6625 hours\n",
      "Training at Epoch 85 iteration 300 with loss 0.05517. Total time 6.67027 hours\n",
      "Training at Epoch 85 iteration 400 with loss 0.12393. Total time 6.67833 hours\n",
      "Training at Epoch 85 iteration 500 with loss 0.08541. Total time 6.68611 hours\n",
      "Training at Epoch 85 iteration 600 with loss 0.06894. Total time 6.69388 hours\n",
      "Training at Epoch 85 iteration 700 with loss 0.08710. Total time 6.70166 hours\n",
      "Training at Epoch 85 iteration 800 with loss 0.10812. Total time 6.70944 hours\n",
      "Validation at Epoch 85 with loss:0.67906, MSE: 0.67267 , Pearson Correlation: 0.82560 with p-value: 0.00E+00 , Concordance Index: 0.81925\n",
      "Training at Epoch 86 iteration 0 with loss 0.07135. Total time 6.725 hours\n",
      "Training at Epoch 86 iteration 100 with loss 0.08533. Total time 6.73277 hours\n",
      "Training at Epoch 86 iteration 200 with loss 0.05654. Total time 6.74055 hours\n",
      "Training at Epoch 86 iteration 300 with loss 0.10970. Total time 6.74833 hours\n",
      "Training at Epoch 86 iteration 400 with loss 0.09098. Total time 6.75611 hours\n",
      "Training at Epoch 86 iteration 500 with loss 0.08875. Total time 6.76388 hours\n",
      "Training at Epoch 86 iteration 600 with loss 0.09474. Total time 6.77194 hours\n",
      "Training at Epoch 86 iteration 700 with loss 0.08863. Total time 6.78 hours\n",
      "Training at Epoch 86 iteration 800 with loss 0.05444. Total time 6.78777 hours\n",
      "Validation at Epoch 86 with loss:0.57979, MSE: 0.68814 , Pearson Correlation: 0.82650 with p-value: 0.00E+00 , Concordance Index: 0.81986\n",
      "Training at Epoch 87 iteration 0 with loss 0.07034. Total time 6.80388 hours\n",
      "Training at Epoch 87 iteration 100 with loss 0.08503. Total time 6.81166 hours\n",
      "Training at Epoch 87 iteration 200 with loss 0.06333. Total time 6.81944 hours\n",
      "Training at Epoch 87 iteration 300 with loss 0.07395. Total time 6.82694 hours\n",
      "Training at Epoch 87 iteration 400 with loss 0.08330. Total time 6.83472 hours\n",
      "Training at Epoch 87 iteration 500 with loss 0.05896. Total time 6.8425 hours\n",
      "Training at Epoch 87 iteration 600 with loss 0.06489. Total time 6.85027 hours\n",
      "Training at Epoch 87 iteration 700 with loss 0.08617. Total time 6.85833 hours\n",
      "Training at Epoch 87 iteration 800 with loss 0.09231. Total time 6.86666 hours\n",
      "Validation at Epoch 87 with loss:0.71112, MSE: 0.68253 , Pearson Correlation: 0.82669 with p-value: 0.00E+00 , Concordance Index: 0.81975\n",
      "Training at Epoch 88 iteration 0 with loss 0.06700. Total time 6.88277 hours\n",
      "Training at Epoch 88 iteration 100 with loss 0.06807. Total time 6.89083 hours\n",
      "Training at Epoch 88 iteration 200 with loss 0.12276. Total time 6.89861 hours\n",
      "Training at Epoch 88 iteration 300 with loss 0.05938. Total time 6.90666 hours\n",
      "Training at Epoch 88 iteration 400 with loss 0.15073. Total time 6.91444 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 88 iteration 500 with loss 0.10791. Total time 6.9225 hours\n",
      "Training at Epoch 88 iteration 600 with loss 0.09491. Total time 6.93055 hours\n",
      "Training at Epoch 88 iteration 700 with loss 0.09106. Total time 6.93861 hours\n",
      "Training at Epoch 88 iteration 800 with loss 0.08731. Total time 6.94666 hours\n",
      "Validation at Epoch 88 with loss:0.81167, MSE: 0.67792 , Pearson Correlation: 0.82578 with p-value: 0.00E+00 , Concordance Index: 0.81926\n",
      "Training at Epoch 89 iteration 0 with loss 0.06705. Total time 6.96277 hours\n",
      "Training at Epoch 89 iteration 100 with loss 0.09112. Total time 6.97111 hours\n",
      "Training at Epoch 89 iteration 200 with loss 0.07000. Total time 6.97888 hours\n",
      "Training at Epoch 89 iteration 300 with loss 0.07544. Total time 6.98694 hours\n",
      "Training at Epoch 89 iteration 400 with loss 0.07904. Total time 6.995 hours\n",
      "Training at Epoch 89 iteration 500 with loss 0.06344. Total time 7.00277 hours\n",
      "Training at Epoch 89 iteration 600 with loss 0.07890. Total time 7.01055 hours\n",
      "Training at Epoch 89 iteration 700 with loss 0.09753. Total time 7.01833 hours\n",
      "Training at Epoch 89 iteration 800 with loss 0.10980. Total time 7.02611 hours\n",
      "Validation at Epoch 89 with loss:0.71796, MSE: 0.68988 , Pearson Correlation: 0.82538 with p-value: 0.00E+00 , Concordance Index: 0.81959\n",
      "Training at Epoch 90 iteration 0 with loss 0.08334. Total time 7.04194 hours\n",
      "Training at Epoch 90 iteration 100 with loss 0.07179. Total time 7.04972 hours\n",
      "Training at Epoch 90 iteration 200 with loss 0.07746. Total time 7.0575 hours\n",
      "Training at Epoch 90 iteration 300 with loss 0.07722. Total time 7.06527 hours\n",
      "Training at Epoch 90 iteration 400 with loss 0.06794. Total time 7.07277 hours\n",
      "Training at Epoch 90 iteration 500 with loss 0.07790. Total time 7.08055 hours\n",
      "Training at Epoch 90 iteration 600 with loss 0.08977. Total time 7.08833 hours\n",
      "Training at Epoch 90 iteration 700 with loss 0.08104. Total time 7.09583 hours\n",
      "Training at Epoch 90 iteration 800 with loss 0.09325. Total time 7.10361 hours\n",
      "Validation at Epoch 90 with loss:0.65969, MSE: 0.68997 , Pearson Correlation: 0.82650 with p-value: 0.00E+00 , Concordance Index: 0.81975\n",
      "Training at Epoch 91 iteration 0 with loss 0.08565. Total time 7.11916 hours\n",
      "Training at Epoch 91 iteration 100 with loss 0.08722. Total time 7.12694 hours\n",
      "Training at Epoch 91 iteration 200 with loss 0.06507. Total time 7.13444 hours\n",
      "Training at Epoch 91 iteration 300 with loss 0.07092. Total time 7.14222 hours\n",
      "Training at Epoch 91 iteration 400 with loss 0.07766. Total time 7.15 hours\n",
      "Training at Epoch 91 iteration 500 with loss 0.07221. Total time 7.15777 hours\n",
      "Training at Epoch 91 iteration 600 with loss 0.08864. Total time 7.16583 hours\n",
      "Training at Epoch 91 iteration 700 with loss 0.10236. Total time 7.17361 hours\n",
      "Training at Epoch 91 iteration 800 with loss 0.08553. Total time 7.18138 hours\n",
      "Validation at Epoch 91 with loss:0.57401, MSE: 0.66711 , Pearson Correlation: 0.82744 with p-value: 0.00E+00 , Concordance Index: 0.82037\n",
      "Training at Epoch 92 iteration 0 with loss 0.07835. Total time 7.19722 hours\n",
      "Training at Epoch 92 iteration 100 with loss 0.09785. Total time 7.205 hours\n",
      "Training at Epoch 92 iteration 200 with loss 0.06456. Total time 7.21277 hours\n",
      "Training at Epoch 92 iteration 300 with loss 0.07136. Total time 7.22055 hours\n",
      "Training at Epoch 92 iteration 400 with loss 0.07242. Total time 7.22861 hours\n",
      "Training at Epoch 92 iteration 500 with loss 0.08641. Total time 7.23694 hours\n",
      "Training at Epoch 92 iteration 600 with loss 0.08553. Total time 7.245 hours\n",
      "Training at Epoch 92 iteration 700 with loss 0.08236. Total time 7.25305 hours\n",
      "Training at Epoch 92 iteration 800 with loss 0.06978. Total time 7.26111 hours\n",
      "Validation at Epoch 92 with loss:0.70048, MSE: 0.67403 , Pearson Correlation: 0.82733 with p-value: 0.00E+00 , Concordance Index: 0.82021\n",
      "Training at Epoch 93 iteration 0 with loss 0.07541. Total time 7.27722 hours\n",
      "Training at Epoch 93 iteration 100 with loss 0.07412. Total time 7.285 hours\n",
      "Training at Epoch 93 iteration 200 with loss 0.05941. Total time 7.29277 hours\n",
      "Training at Epoch 93 iteration 300 with loss 0.08038. Total time 7.30055 hours\n",
      "Training at Epoch 93 iteration 400 with loss 0.07071. Total time 7.30805 hours\n",
      "Training at Epoch 93 iteration 500 with loss 0.08324. Total time 7.31583 hours\n",
      "Training at Epoch 93 iteration 600 with loss 0.09890. Total time 7.32361 hours\n",
      "Training at Epoch 93 iteration 700 with loss 0.07426. Total time 7.33138 hours\n",
      "Training at Epoch 93 iteration 800 with loss 0.06068. Total time 7.33916 hours\n",
      "Validation at Epoch 93 with loss:0.64041, MSE: 0.68322 , Pearson Correlation: 0.82677 with p-value: 0.00E+00 , Concordance Index: 0.81978\n",
      "Training at Epoch 94 iteration 0 with loss 0.04051. Total time 7.35472 hours\n",
      "Training at Epoch 94 iteration 100 with loss 0.08235. Total time 7.3625 hours\n",
      "Training at Epoch 94 iteration 200 with loss 0.08801. Total time 7.37 hours\n",
      "Training at Epoch 94 iteration 300 with loss 0.07784. Total time 7.37777 hours\n",
      "Training at Epoch 94 iteration 400 with loss 0.08769. Total time 7.38583 hours\n",
      "Training at Epoch 94 iteration 500 with loss 0.10585. Total time 7.39361 hours\n",
      "Training at Epoch 94 iteration 600 with loss 0.06802. Total time 7.40111 hours\n",
      "Training at Epoch 94 iteration 700 with loss 0.08306. Total time 7.40888 hours\n",
      "Training at Epoch 94 iteration 800 with loss 0.07455. Total time 7.41666 hours\n",
      "Validation at Epoch 94 with loss:0.57554, MSE: 0.67485 , Pearson Correlation: 0.82695 with p-value: 0.00E+00 , Concordance Index: 0.81994\n",
      "Training at Epoch 95 iteration 0 with loss 0.07567. Total time 7.43222 hours\n",
      "Training at Epoch 95 iteration 100 with loss 0.06836. Total time 7.44 hours\n",
      "Training at Epoch 95 iteration 200 with loss 0.07975. Total time 7.44805 hours\n",
      "Training at Epoch 95 iteration 300 with loss 0.07150. Total time 7.45555 hours\n",
      "Training at Epoch 95 iteration 400 with loss 0.10853. Total time 7.46361 hours\n",
      "Training at Epoch 95 iteration 500 with loss 0.07476. Total time 7.47138 hours\n",
      "Training at Epoch 95 iteration 600 with loss 0.12056. Total time 7.47916 hours\n",
      "Training at Epoch 95 iteration 700 with loss 0.09672. Total time 7.48694 hours\n",
      "Training at Epoch 95 iteration 800 with loss 0.08721. Total time 7.49472 hours\n",
      "Validation at Epoch 95 with loss:0.64056, MSE: 0.67114 , Pearson Correlation: 0.82621 with p-value: 0.00E+00 , Concordance Index: 0.81965\n",
      "Training at Epoch 96 iteration 0 with loss 0.07347. Total time 7.51027 hours\n",
      "Training at Epoch 96 iteration 100 with loss 0.06118. Total time 7.51805 hours\n",
      "Training at Epoch 96 iteration 200 with loss 0.08396. Total time 7.52555 hours\n",
      "Training at Epoch 96 iteration 300 with loss 0.07139. Total time 7.53333 hours\n",
      "Training at Epoch 96 iteration 400 with loss 0.07241. Total time 7.54111 hours\n",
      "Training at Epoch 96 iteration 500 with loss 0.09323. Total time 7.54888 hours\n",
      "Training at Epoch 96 iteration 600 with loss 0.08163. Total time 7.55666 hours\n",
      "Training at Epoch 96 iteration 700 with loss 0.10892. Total time 7.56444 hours\n",
      "Training at Epoch 96 iteration 800 with loss 0.06926. Total time 7.57222 hours\n",
      "Validation at Epoch 96 with loss:0.73360, MSE: 0.67267 , Pearson Correlation: 0.82768 with p-value: 0.00E+00 , Concordance Index: 0.81992\n",
      "Training at Epoch 97 iteration 0 with loss 0.08063. Total time 7.58777 hours\n",
      "Training at Epoch 97 iteration 100 with loss 0.07185. Total time 7.59527 hours\n",
      "Training at Epoch 97 iteration 200 with loss 0.08196. Total time 7.60305 hours\n",
      "Training at Epoch 97 iteration 300 with loss 0.05256. Total time 7.61083 hours\n",
      "Training at Epoch 97 iteration 400 with loss 0.06352. Total time 7.61861 hours\n",
      "Training at Epoch 97 iteration 500 with loss 0.08709. Total time 7.62638 hours\n",
      "Training at Epoch 97 iteration 600 with loss 0.06884. Total time 7.63416 hours\n",
      "Training at Epoch 97 iteration 700 with loss 0.06891. Total time 7.64166 hours\n",
      "Training at Epoch 97 iteration 800 with loss 0.07842. Total time 7.64972 hours\n",
      "Validation at Epoch 97 with loss:0.94004, MSE: 0.67744 , Pearson Correlation: 0.82577 with p-value: 0.00E+00 , Concordance Index: 0.81918\n",
      "Training at Epoch 98 iteration 0 with loss 0.07184. Total time 7.66527 hours\n",
      "Training at Epoch 98 iteration 100 with loss 0.09727. Total time 7.67305 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 98 iteration 200 with loss 0.08432. Total time 7.68111 hours\n",
      "Training at Epoch 98 iteration 300 with loss 0.07200. Total time 7.68888 hours\n",
      "Training at Epoch 98 iteration 400 with loss 0.07162. Total time 7.69666 hours\n",
      "Training at Epoch 98 iteration 500 with loss 0.07734. Total time 7.70472 hours\n",
      "Training at Epoch 98 iteration 600 with loss 0.06582. Total time 7.71277 hours\n",
      "Training at Epoch 98 iteration 700 with loss 0.06346. Total time 7.72055 hours\n",
      "Training at Epoch 98 iteration 800 with loss 0.09477. Total time 7.72833 hours\n",
      "Validation at Epoch 98 with loss:0.54984, MSE: 0.66809 , Pearson Correlation: 0.82653 with p-value: 0.00E+00 , Concordance Index: 0.81969\n",
      "Training at Epoch 99 iteration 0 with loss 0.09308. Total time 7.74388 hours\n",
      "Training at Epoch 99 iteration 100 with loss 0.05693. Total time 7.75166 hours\n",
      "Training at Epoch 99 iteration 200 with loss 0.08013. Total time 7.75944 hours\n",
      "Training at Epoch 99 iteration 300 with loss 0.05476. Total time 7.76722 hours\n",
      "Training at Epoch 99 iteration 400 with loss 0.10472. Total time 7.775 hours\n",
      "Training at Epoch 99 iteration 500 with loss 0.07843. Total time 7.7825 hours\n",
      "Training at Epoch 99 iteration 600 with loss 0.08799. Total time 7.79027 hours\n",
      "Training at Epoch 99 iteration 700 with loss 0.08027. Total time 7.79805 hours\n",
      "Training at Epoch 99 iteration 800 with loss 0.09160. Total time 7.80583 hours\n",
      "Validation at Epoch 99 with loss:0.80628, MSE: 0.67447 , Pearson Correlation: 0.82696 with p-value: 0.00E+00 , Concordance Index: 0.81986\n",
      "Training at Epoch 100 iteration 0 with loss 0.06075. Total time 7.82138 hours\n",
      "Training at Epoch 100 iteration 100 with loss 0.06405. Total time 7.82916 hours\n",
      "Training at Epoch 100 iteration 200 with loss 0.06380. Total time 7.83694 hours\n",
      "Training at Epoch 100 iteration 300 with loss 0.11291. Total time 7.84444 hours\n",
      "Training at Epoch 100 iteration 400 with loss 0.10672. Total time 7.85222 hours\n",
      "Training at Epoch 100 iteration 500 with loss 0.07608. Total time 7.86027 hours\n",
      "Training at Epoch 100 iteration 600 with loss 0.08233. Total time 7.86805 hours\n",
      "Training at Epoch 100 iteration 700 with loss 0.06152. Total time 7.87583 hours\n",
      "Training at Epoch 100 iteration 800 with loss 0.07306. Total time 7.88361 hours\n",
      "Validation at Epoch 100 with loss:0.66815, MSE: 0.68983 , Pearson Correlation: 0.82644 with p-value: 0.00E+00 , Concordance Index: 0.81987\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.660017450699543 , Pearson Correlation: 0.8314593941804068 with p-value: 0.00E+00 , Concordance Index: 0.8226763261378081\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAELCAYAAAA7h+qnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZw0lEQVR4nO3de5xdZX3v8c83FyQBbRIIFInJgKZWpBZwygH1UCVeEK3hWDzFDhoMGhV9CdVXKzalhZZ46QXFU0BTkMYyCBKhUK5Gbh48SJ1wk2sTIIE0gQzhIjAKEn7nj+cZZ8/s2cnaw77NrO/79dqvvZ9nrb3WsxeL+Wat9axnKSIwM7Nym9TuBpiZWfs5DMzMzGFgZmYOAzMzw2FgZmbAlHY3YKx23XXX6OrqanczzMzGldWrVz8eEbNH1o/bMOjq6qKvr6/dzTAzG1ckrR+t3qeJzMzMYWBmZg4DMzPDYWBmZjgMzMyMNoSBpHWSfi7pdkl9uW6WpFWS1uT3mc1Yd28vdHXBpEnpvbe3GWsxMxt/2nVk8I6I2C8iunP5RODaiJgPXJvLDdXbC4sXw/r1EJHeFy92IJiZQeecJloIrMifVwBHNHoFxx8PL7wwvO6FF1K9mVnZtSMMAvihpNWSluS63SNiE0B+3220L0paIqlPUl9/f39dK92ypb56M7MyaccdyG+NiI2SdgNWSbqv6BcjYjmwHKC7u9tP5TEza5CWHxlExMb8vhm4BDgQeEzSHgD5fXOj17vLLvXVm5mVSUvDQNJOkl45+Bl4N3AXcBmwKM+2CLi00es+/XSYOnV43dSpqd7MrOxafZpod+ASSYPrPj8irpb0M+D7ko4FHgY+1OgV9/Sk9098An75S5g3D5YtG6o3MyuzloZBRDwI/P4o9VuABc1ef08PfO978Oij4AFPzcyGdErX0pYKX3o2MxumdGGQzlCZmVml0oWBmZlVcxiYmZnDwMzMHAZmZobDwMzMKGkYuGupmdlwpQsDdy01M6tWujAwM7NqDgMzM3MYmJmZw8DMzChpGLg3kZnZcKULA/cmMjOrVqow6O2FVavg9tuhqyuVzcysRGHQ2wtLlqSnnAGsX5/KDgQzsxKFwdKlMDAwvG5gINWbmZVdacLg4YfrqzczK5PShMHcufXVm5mVSWnCYNkymD59eN306anezKzsShMGPT2wfDlMm5bK8+alck9Pe9tlZtYJprS7Aa3U0wMXXQTr1qXupWZmlpTmyMDMzGpzGJiZmcPAzMwcBmZmRknDwKOWmpkNV7ow8KilZmbVShcGZmZWzWFgZmbtCQNJkyXdJunyXN5L0i2S1ki6UNIO7WiXmVlZtevI4Hjg3ory14CvR8R84Eng2La0ysyspFoeBpLmAO8Dzs5lAYcCK/MsK4AjmtkG9yYyMxuuHUcG3wD+Angpl3cBnoqIF3N5A7DnaF+UtERSn6S+/v7+Ma3cvYnMzKq1NAwkvR/YHBGrK6tHmXXUf7tHxPKI6I6I7tmzZzeljWZmZdTqUUvfCnxA0uHAjsCrSEcKMyRNyUcHc4CNLW6XmVmptfTIICK+FBFzIqILOAq4LiJ6gOuBI/Nsi4BLW9kuM7Oy65T7DL4IfF7SWtI1hHPa3B4zs1Jp28NtIuIG4Ib8+UHgwHa1xcys7DrlyKCl3LXUzGy40oWBu5aamVUrXRiYmVk1h4GZmTkMzMzMYWBmZpQ0DNybyMxsuNKFgXsTmZlVK10YmJlZNYeBmZk5DMzMzGFgZmY4DMzMjJKGgbuWmpkNV7owcNdSM7NqpQqD3l648kq45x7o6kplMzOrIwwk7S/pYkmPS3pR0gG5/suSDmteExujtxeWLIGBgVRevz6VHQhmZgXDQNLbgJuB3wXOH/G9l4BPNb5pjbV06VAQDBoYSPVmZmVX9Mjgq8A1wBuBz4+YditwQCMb1QwPP1xfvZlZmRQNgwOAsyIigJF9cR4HZje0VU0wd2599WZmZVI0DH4FTK8xbQ/g6cY0p3mWLYPpI37B9Omp3sys7IqGwU3ACZImV9QNHiEcC1zX0FY1QU8PLF8+FAjz5qVyT09722Vm1gmmFJzvJOAnwB3ASlIQLJJ0GvBm4A+a07zG6umBSy+Fu+5K3UvNzCwpdGQQEXcAhwCPAUsBAZ/Nk/8wIu5vTvPMzKwVih4ZEBG3Agsk7QjMAp6KiIHtfM3MzMaBwmEwKCJ+BWxsQlvMzKxNCoWBpL/eziwREX/XgPa0hAeqMzMbruiRwcnbmDb4p3VchIEHqjMzq1b0AvKkkS9gF+AY4C7gdU1so5mZNVnd1wwGRcSTwHcl7QKcARzesFaZmVlLNWII68Fup9slaUdJ/ynpDkl3Szol1+8l6RZJayRdKGmHBrTLzMwKakQYvB/oLzjv88ChEfH7wH7AYZIOAr4GfD0i5gNPku5qNjOzFinam+g7o1TvAOwL/B7wN0WWkwe6ezYXp+ZXAIcCf5rrV5AuWJ9VZJlmZvbyFb1mcCjVo5X+ClgPfIP0B7yQPL7RatJF5zOAB0g3sL2YZ9kA7Fnju0uAJQBzX8Zwo+5aamY2XKEwiIiuRq0wIrYC+0maAVwCvGG02Wp8dzmwHKC7u3tMf9LdtdTMrFrbnoEcEU8BNwAHATMkDQbTHHyHs5lZS9U8MpBUqIfQoIj48fbmkTQb+HVEPCVpGvBO0sXj64EjgQuARcCl9azbzMxenm2dJrqBGqdrRlCeb/L2ZiQ9CGdFvm4wCfh+RFwu6R7gAkmnArcB5xRYlpmZNci2wuAdjV5ZRNwJ7D9K/YPAgY1en5mZFVMzDCLixlY2pJXcm8jMbLi2XUBuF/cmMjOrVnhsIkn7ku4Mfj2w44jJERELGtkwMzNrnaJ3IP8P4EZgHTAfuBOYCcwl3SS2tkntMzOzFih6mujLwMXAG0m9h47NN6K9k9SL6NSmtM7MzFqiaBi8CTiPoa6mkwEi4jpSEHyl8U0zM7NWKRoGU4HnIuIl4AnS/QKD7icNWGdmZuNU0TB4gKHB4+4EFkuaJGkS8DHg0WY0rlnctdTMbLiivYn+A3g7cD7p+sEVwC+ArcDOwOea0bhmcNdSM7NqRUctPbni84/yA2n+GJgOXB0RP2xO88zMrBXG9AzkiLiNNIaQmZlNAIWuGUi6WNIRkqY2u0FmZtZ6RS8g/y7pPoNNks7Ip4nMzGyCKBQGEbEP8Aekew0+CPxE0hpJJ0nau5kNbAb3JjIzG67wQHURsToiTiA9ieyPgJ8BXwTWSPq/TWpfw7k3kZlZtbpHLY2IrRFxZUT8KekoYSPwloa3zMzMWqbu3kSSXgscDfQArwU2Af/U4HaZmVkLFR21dCbwJ8BHSA+wHwAuAT4D/CjCZ+HNzMazokcGj5IGp7sOOAb4QUQMNKtRZmbWWkXD4K+A8yJiUzMbY2Zm7VF0OIp/aHZDWskntczMhvMzkM3MrHxhYGZm1RwGZmbmMDAzM4eBmZlRfAjrhZI+VlGeJ+lmSc9IWilp5+Y1sfHcm8jMbLiiRwZ/BcyuKJ9GGrBuOXAIcHJjm9U87k1kZlataBi8FrgTQNI04HDg8xHxBeAvgf/VnOaZmVkrFA2DHYFf5s9vId2sNvjc4/uBVze4XWZm1kJFw2Ad8Lb8eSGwOiKezuXdgKdH+5KZmY0PRcPg28DJkvqA44BzKqYdDNxTZCGSXiPpekn3Srpb0vG5fpakVfnpaavyKKlmZtYiRR97eTpptNKbgcUR8S8Vk18JnFtwfS8CX4iIN5CGwv6MpH2AE4FrI2I+cG0um5lZixR+uE1E9AK9o9R/so5lbCI9DIeIeEbSvcCepFNPb8+zrQBuID1SsynctdTMbLii9xn8jqQDK8rTJH1F0n9I+uxYViypC9gfuAXYfXB47Py+W43vLJHUJ6mvv79/LKt111Izs1EUvWbwz8CRFeVlwBdIvYi+Lukz9aw036T2A+CEiPhF0e9FxPKI6I6I7tmzZ2//C2ZmVkjRMHgT8BMASZOAjwJfjIg3A6cCS4quUNJUUhD0RsTFufoxSXvk6XsAm4suz8zMXr6iYTAD2JI/7w/MBFbm8g3A3kUWIkmknkj3RsRpFZMuAxblz4uASwu2y8zMGqBoGDwGvC5/fjfwQEQ8kss7k3oJFfFW4CPAoZJuz6/Dga8C75K0BnhXLpuZWYsU7U10GfAVSfuSuph+u2La7wEPFllIRNwE1LqEu6BgW8zMrMGKhsGJpCEp3kMKhi9XTPsAQ0NTjAvuWmpmNlyhMIiI54BP1Jj2loa2qMnctdTMrFrhm84gDRtBGn5iFumC8k8j4olmNMzMzFqncBhIOpV0b8ErKqqfl/SPEXFSw1tmZmYtU/QO5BNIzy04D3gH8Ib8fh7wl5I+17QWmplZ0xU9MvgUcHpE/FlF3f3AjZKeJY1k+s1GN87MzFqj6H0GXcAVNaZdkaePG+5NZGY2XNEw2ALsW2PaGxm6O7njuTeRmVm1omFwCfB3kj6SxxZC0hRJHwb+ljTWkJmZjVNFw+BLwO2kZw0MSHqM9EzkXuAO0sVlMzMbp4redPaMpEOA9wH/k3SfwRPAjcBVET4Lb2Y2ntXzpLMALs8vMzObQIqeJjIzswms5pGBpJeAoqd/IiLqGtqinXxSy8xsuG39Af9biofBuOGupWZm1WqGQUSc3MJ2mJlZG/magZmZOQzMzMxhYGZmlDQM3JvIzGy4UoVBby9cdBE88gh0daWymZnV+djL8ay3F5YsgYGBVF6/PpUBenra1y4zs05QmiODpUuHgmDQwECqNzMru9KEwcMP11dvZlYmpQmDuXPrqzczK5PShMGyZTB9+vC66dNTvZlZ2ZUmDHp6YPly2GmnVJ43L5V98djMrES9iSD94b/uOvjhD2Hduna3xsysc5TmyMDMzGpzGJiZWWvDQNJ3JG2WdFdF3SxJqyStye8zW9kmMzNr/ZHBvwKHjag7Ebg2IuYD1+aymZm1UEvDICJ+DDwxonohsCJ/XgEc0az19/bChRfChg0em8jMrFInXDPYPSI2AeT33WrNKGmJpD5Jff39/XWtZHBsoueeS+XBsYkcCGZmnREGhUXE8ojojoju2bNn1/Vdj01kZlZbJ4TBY5L2AMjvm5uxEo9NZGZWWyeEwWXAovx5EXBpM1bisYnMzGprddfS7wE3A6+XtEHSscBXgXdJWgO8K5cbzmMTmZnV1tLhKCLiwzUmLWj2ugfHIPrkJ9NF5HnzUhB4bCIzsxKOTXT99XDVVR6byMysUidcM2gpqd0tMDPrPKULAzMzq+YwMDMzh4GZmTkMzMwMh4GZmVGyMDjuODjnHNi4EaZMSWUzMyvRfQbHHQdnnTVU3rp1qHzmme1pk5lZpyjNkcHy5fXVm5mVSWnCYOvW+urNzMqkNGFQ685j35FsZlaiMNhpp/rqzczKpDRh8Oyz9dWbmZVJacJg8uT66s3MyqQ0YeALyGZmtZUmDHxkYGZWW2nCwEcGZma1lSYMJtX4pbXqzczKpDR/Cl96qb56M7MyKU0YmJlZbQ4DMzNzGJiZmcPAzMxwGADpQTe9ve1uhZlZ+zgMSPcaHH10GsF0110dDGZWPg6DEbZsGQoGKd2HIPkxmWY2sTkMtiMivQ8+JnMwJPbcs73tMjNrJIfBGG3cOBQM23t1dQ2deurtTeVJk4bXm5m1k8OgBdavHzr1dPTRqRwxvL4Zr3qvfziozMpLMXgeZJzp7u6Ovr6+wvP78ZZm1my77JLet2xJIyLXOxCmNHRqelvmzYNly6Cnp/42SlodEd0j6zvmyEDSYZLul7RW0omNXv44zTwzG0e2bEkvGNuIyEX/Tg2eVWjk0XtHhIGkycAZwHuBfYAPS9qn0euZNq3RSzQza5+jj27csjoiDIADgbUR8WBEvABcACxs9EoGBhwIZmaj6ZQw2BN4pKK8IdcNI2mJpD5Jff39/WNa0cCATxmZmY3UKWEw2uXdqj/ZEbE8Irojonv27Nkva4URQ69Pf/plLcrMbNzrlDDYALymojwH2NiqlZ955vBw2N7L4WFmE02nhMHPgPmS9pK0A3AUcFmb21RTveHRKa/zzktd0qT0vmBB6v5mZuNTI095T2ncosYuIl6U9FngGmAy8J2IuLvNzZpwenrG1i/ZzCa+jggDgIi4Eriy3e0wMyujTjlNZGZmbeQwMDMzh4GZmTkMzMyMcTxqqaR+YP0Yv74r8HgDmzNReLtU8zYZnbdLtfGyTeZFRNVdu+M2DF4OSX2jDeFadt4u1bxNRuftUm28bxOfJjIzM4eBmZmVNwyWt7sBHcrbpZq3yei8XaqN621SymsGZmY2XFmPDMzMrILDwMzMyhcGkg6TdL+ktZJObHd7Gk3SayRdL+leSXdLOj7Xz5K0StKa/D4z10vSN/P2uFPSARXLWpTnXyNpUUX9myX9PH/nm5JGezhRx5E0WdJtki7P5b0k3ZJ/34V5+HQkvSKX1+bpXRXL+FKuv1/Seyrqx+V+JWmGpJWS7sv7zMFl31ck/Vn+f+cuSd+TtGMp9pWIKM2LNDz2A8DewA7AHcA+7W5Xg3/jHsAB+fMrgf8C9gH+Hjgx158IfC1/Phy4ivS0uYOAW3L9LODB/D4zf56Zp/0ncHD+zlXAe9v9uwtum88D5wOX5/L3gaPy528Bn86fjwO+lT8fBVyYP++T95lXAHvlfWnyeN6vgBXAx/PnHYAZZd5XSI/bfQiYVrGPHFOGfaVsRwYHAmsj4sGIeAG4AFjY5jY1VERsiohb8+dngHtJO/hC0v/45Pcj8ueFwHcj+SkwQ9IewHuAVRHxREQ8CawCDsvTXhURN0fa679bsayOJWkO8D7g7FwWcCiwMs8ycpsMbquVwII8/0Lggoh4PiIeAtaS9qlxuV9JehVwCHAOQES8EBFPUfJ9hTS0/zRJU4DpwCZKsK+ULQz2BB6pKG/IdRNSPmTdH7gF2D0iNkEKDGC3PFutbbKt+g2j1He6bwB/AbyUy7sAT0XEi7lc+Tt+89vz9Kfz/PVuq063N9APnJtPn50taSdKvK9ExH8D/wg8TAqBp4HVlGBfKVsYjHa+ckL2rZW0M/AD4ISI+MW2Zh2lLsZQ37EkvR/YHBGrK6tHmTW2M23CbJNsCnAAcFZE7A88RzotVMuE3y75+shC0qmdVwM7Ae8dZdYJt6+ULQw2AK+pKM8BNrapLU0jaSopCHoj4uJc/Vg+bCe/b871tbbJturnjFLfyd4KfEDSOtJh+aGkI4UZ+VQADP8dv/ntefpvAU9Q/7bqdBuADRFxSy6vJIVDmfeVdwIPRUR/RPwauBh4CyXYV8oWBj8D5ueeATuQLvhc1uY2NVQ+X3kOcG9EnFYx6TJgsJfHIuDSivqP5p4iBwFP51MD1wDvljQz/2vp3cA1edozkg7K6/poxbI6UkR8KSLmREQX6b/5dRHRA1wPHJlnG7lNBrfVkXn+yPVH5R4kewHzSRdIx+V+FRGPAo9Ien2uWgDcQ4n3FdLpoYMkTc9tHtwmE39fafcV7Fa/SD0i/ot0RX9pu9vThN/3NtJh553A7fl1OOk85rXAmvw+K88v4Iy8PX4OdFcsazHpwtda4GMV9d3AXfk7/0y+k308vIC3M9SbaG/S/6BrgYuAV+T6HXN5bZ6+d8X3l+bffT8VPWPG634F7Af05f3l30m9gUq9rwCnAPfldv8bqUfQhN9XPByFmZmV7jSRmZmNwmFgZmYOAzMzcxiYmRkOAzMzw2FgE5CkkyVF/jwjlw/Y3vea2J79chtmjTItJJ3chmaZDeMwsInobNJImZBG4fwb0p217bJfbkNVGJDaeXZrm2NWbcr2ZzEbXyJiA8MHSGuofGfq1EijTr4skUb/NGs7HxnYhDN4miiP2vpQrv6XXBeSjqmY94OSfippQNJTki6SNHfE8tZJOk/SYkn3AS+QhsNG0imSbpX0tKTHJV2Xh2oY/O4xwLm5uKaiDV15etVpovzwk5sl/TIv998rhowYnOcGSTdJemde/4DSw1jGwxDR1oEcBjaRbQI+mD9/hXRK5mDgCgBJnyIN6HcPaVyZTwL7AjdKeuWIZb2D9HCcU4DDSMM3QBp++Ouk8e2PIQ3q9mNJb8rTrwBOzZ8/VNGGTaM1WNJh+TvPAn8CfDq36SZJI4c6fi1wOnBa/p2bgJWSXrfNrWI2Cp8msgkrIp6XdFsuPlh5SiYP8f014NyIWFxRfwtp3JhjSSObDpoJvDnS4G6V6/h4xXcnA1cDd+fvHx8R/ZIeyLPcHhFrt9PsU0lPCntv5PHzJd2c2/QFUiAN2hU4JCLW5PluJQXC/wa+vJ31mA3jIwMrq4OBVwG9kqYMvkjXGu4jPQGs0k9HBgFAPk1zvaQtwIvAr4HfAV4/ct7tyQ+WOYD06MTBB6kQ6UlZPwH+cMRX1gwGQZ5vM+nIZC5mdfKRgZXV4NO7flRj+pMjylWndXJ31StJQzgfm+fZSuodtOMY2jSTNDLoaKeQHgXmjah7YpT5nh/juq3kHAZWVlvy+zGk0zojPTOiPNrwvn9MOhr4YKQHoQC/eVrWU2No05N5Pb89yrTfZqjNZg3nMLCJ7vn8Pm1E/f8j/cF/XUSsYGymk44EfhMUkg4lnaZ5qGK+Wm0YJiKek7Qa+JCkkyNia17mPNLTtv7PGNtptl0OA5voHiP9i/ooSXeSnvP7UERskfTnwBmSZgNXkR5mvifp3PwNEXH+dpZ9NXAC8K+SziVdKzgJ+O8R892T3z8jaQXpusKdNe5TOInUm+hySWcCO5N6MD0N/FMdv9usLr6AbBNaRLwEfJx0Pv5HpMcO/lGe9m3gA6SLvf9GCoRTSP9Iur3Asq8BPkd6xvLlpKd9fZT01KvK+e4ATs7rvSm34dU1lnk16R6GGcD3gW8B9wJvi4iOeFauTUx+0pmZmfnIwMzMHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZkB/x/rXetXRC18NwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/r1/title_r1_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r1/model_morgan_cnn_r1_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 320000 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 184097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:24] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:25] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 28 29 30\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [19:59:25] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC=C)CCC235)ccc4O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[N]1=C(C=CC=C1)c1ccc(cc1)C(=O)NC\\C=C\\CN1CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:25] Explicit valence for atom # 33 H, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)[C@@H]1CC[C@H]1c1nccc([H]C(F)F)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:26] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:26] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(F)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(Cl)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:29] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 15 18 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:30] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:31] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2OCOc2cc1Cl)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:31] Explicit valence for atom # 30 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:32] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(Cl)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:34] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CC(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:35] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc2ccccc2c1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:35] Explicit valence for atom # 27 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc(F)cc1-c1noc(n1)-c1ccc(N2CCCCC2C)c(c1)N([O-])=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:36] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:36] Can't kekulize mol.  Unkekulized atoms: 1 2 4 5 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1cocc(CN2CCC(CC2)NC(=O)[C@@](O)([C@@H]2CCC(F)(F)C2)c2ccccc2)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:38] Explicit valence for atom # 18 N, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(C(=O)N2)c2ccc(cn2)[N](C)(=O)=O)CC1)c1cccc(F)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:39] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:39] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccco1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:39] Explicit valence for atom # 2 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC[N]1(CC)CCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:40] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [19:59:40] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:40] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(C)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:41] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [19:59:41] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 8 28 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=C)n1ccc2cc(OCCCN3CCN(CC3)c3cccc4sccc34)ccc2c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:41] Can't kekulize mol.  Unkekulized atoms: 1 2 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)F)cc2)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:42] Can't kekulize mol.  Unkekulized atoms: 6 7 8 9 10 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=O)NCCc1cc2ccccc2n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:43] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccoc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:44] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [19:59:44] Can't kekulize mol.  Unkekulized atoms: 21 22 24 25 26\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccnc(Oc2ccc(cc2)-c2c(C)c(=O)nc(=O)n2C)c1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)noc1C)[nH]c1ccnc(-c3c(C)nnc3-c3ccccc3)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:44] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:45] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5 6 7 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc(Nc2ccc3ncc(nc3c2C#N)N2CCOCC2)ccc1OCC1=C[N](O)=C(C)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cccc2cc(OCCCCN3CCN(CC3)c3cccc4sccc34)c(=O)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:46] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cnc(Oc2ccc(c(C)c2)-c2c(C)c(=O)nc(=O)n2C)c(Cl)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:47] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC1(CCN(CC1)c1ccc[nH]\\c1=N/[N](=C)Nc1ccc(cc1)C(=O)NC1CCNC1)c1ccc(Cl)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:47] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:48] Explicit valence for atom # 19 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1C)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(nc1)C1CCCN1C(=O)c1ccc(N[N]2=CN3C=CC=C(N4CCC(O)(CC4)c4ccc(Cl)cc4)C3=N2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:48] Explicit valence for atom # 29 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:48] Explicit valence for atom # 29 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccsc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:48] Explicit valence for atom # 1 C, 7, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: N[C]12=34[B]567[B]89%10[B]55%11[B]%12%13%14[B]%15%16%17[B]88([B]169[B]2%158[B]=3%12%16[B]475%13)[C]%10%11%14%17c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:50] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:50] Explicit valence for atom # 22 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: FC(F)(F)CCC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1ccc(COc2cc3c(NC([C@@H]4CCCC[C@@H]4C(O)=O)=[N]3Cc3ccc(OC(F)(F)F)cc3F)cc2F)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:51] Can't kekulize mol.  Unkekulized atoms: 20 21 22 23 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[C@H](NC(=O)c1cc(Cn2ccn(C)c2=N)cc(c1F)-c1ccccn1C(F)(F)F)c1ccc(F)c(C)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:52] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CC#N convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:53] Explicit valence for atom # 9 N, 4, is greater than permitted\n",
      "RDKit ERROR: [19:59:54] Explicit valence for atom # 30 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: On1nnc2cc(CC[N]3=NNN=C3)ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:54] Can't kekulize mol.  Unkekulized atoms: 41 42 43 44 45\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN1CCN(Cc2ccc(cc2)C(=O)Nc2ccc(C)c(Nc3nccc(n3)-c3cncc(c3)C3=NN=C(C3)C(=O)c3nccn3)c2)CC1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:54] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC1CCN(CC1)c1cccc2C(N(CCc12)C(=O)C1=NC=C[N](=C1)c1cccc(Cl)c1F)C(=O)Nc1ccc(cc1)C(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:55] Explicit valence for atom # 26 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccccc1-c1noc(n1)-c1ccc(-c2ccccc2C)c(c1)N(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:56] Explicit valence for atom # 33 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cc4ccccc4s1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:56] Can't kekulize mol.  Unkekulized atoms: 8 9 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)nnc1C)[nH]c1ccnc(Cl)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:58] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2ccccc2o1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [19:59:59] Can't kekulize mol.  Unkekulized atoms: 2 3 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1c(-c2ccc(Oc3ncccc3Cl)cc2C)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:00] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:00] Can't kekulize mol.  Unkekulized atoms: 14 16 17 18 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:01] Can't kekulize mol.  Unkekulized atoms: 9 10 11 12 13\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:01] Explicit valence for atom # 22 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[C@@H]1CCC[C@H](NC(=O)c2nnc(c2C)-c2cccc(Cl)c2F)c2cc(ccn2)-c2ccc(Nc3ccncn3)cc2NC1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2ncnc(Oc3cccc(NC(=O)NC4=CC(=[N](N4)c4ccccc4)C(F)(F)F)c3)c2cc1OC convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:02] Can't kekulize mol.  Unkekulized atoms: 16 17 18 19 20 21 22 23 25\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(F)c(NC(=O)Nc2cnn(c2)-c2cccc3nnc(N)c23)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:02] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:03] Can't kekulize mol.  Unkekulized atoms: 1 2 3 17 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCO)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:03] Explicit valence for atom # 29 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccoc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:04] Can't kekulize mol.  Unkekulized atoms: 1 2 27\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)(F)F)c3[nH]ccc23)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:05] Can't kekulize mol.  Unkekulized atoms: 3 4 8\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(c(C)c(=O)nc1=O)-c1ccc(Oc2ncccc2Cl)cc1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:06] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(Cl)c(Cl)c1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:07] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(COc2ccc3NC([C@@H]4[C@@H](C(O)=O)C4(C)C)=[N](Cc4ccc(Br)cc4)c3c2)nc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:08] Explicit valence for atom # 0 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: [H][N]1(CC)CCC[C@H](C1)NC(=O)NCCc1ccc(OC(C)C)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:09] Explicit valence for atom # 17 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)NC3CCNC3)N=C12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:10] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: O[N]1(C\\C=C\\CNC(=O)c2ccc(cc2)-c2ccccn2)CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:11] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:13] Can't kekulize mol.  Unkekulized atoms: 3 20 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(-c2ccc(Oc3ncccc3C(F)F)cc2)c(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:14] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 7 8 9\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:14] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 14 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2[nH]c(nc2[nH]1)-c1ccc(Cn2nc(C)c(CC(O)=O)c2C)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2cc(CCNC(C)=O)nc2c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:15] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(C)C1=CC=[N](C=C1)C1CCCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:15] Explicit valence for atom # 8 C, 5, is greater than permitted\n",
      "RDKit ERROR: [20:00:15] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OCC1O[C@H](SC2=C[C](=O)=NC=C2)C(O)[C@H]([C@H]1O)n1cc(nn1)-c1cc(F)c(F)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(COC[C@H]2C[C@]34CC[C@]2(OC)[C@@H]2Oc5c6c(C[C@H]3[N](C)(CC3CC3)CC[C@@]426)ccc5OC)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:16] Explicit valence for atom # 17 N, 4, is greater than permitted\n",
      "RDKit ERROR: [20:00:16] Can't kekulize mol.  Unkekulized atoms: 18 19 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)N3CCCCC3c3cccnc3)N=C12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:17] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CNc1cc(NC2=CC=C[N](C3CCOCC3)=[C]2=O)nc2c(cnn12)C(=O)N[C@@H]1CCC[C@H](C1)OC convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:18] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16 19 20 21 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:18] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:18] Explicit valence for atom # 23 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)c1cc(nc(C)n1)C1CCCN(C1)C(=O)c1ccc(N[N]2=CN3C=CC=C(N4CCC(O)(CC4)c4ccc(Cl)cc4)C3=N2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:19] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCOCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:19] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: On1ncc2cc(COC[N]3=NNN=C3)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:19] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [20:00:19] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 17 18 19 30 31 32\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:19] Can't kekulize mol.  Unkekulized atoms: 8 10 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(F)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)[C@]3(C)Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:20] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1F)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:21] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 17 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:21] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:21] Explicit valence for atom # 1 B, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCNCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[B]1234[B]567[B]89%10[B]%11%12%13[B]%14%15%16[B]15([B]2%141[B]%11%152=[C]311(CO)[B]8%122[B]4691)[C]7%10%13%16c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:23] Can't kekulize mol.  Unkekulized atoms: 7 9 10 11 12\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:23] Explicit valence for atom # 27 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:24] Can't kekulize mol.  Unkekulized atoms: 9 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:24] Can't kekulize mol.  Unkekulized atoms: 15 16 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2Cl)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:25] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(C)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:28] Can't kekulize mol.  Unkekulized atoms: 17 18 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:28] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(C)cc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:28] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "RDKit ERROR: [20:00:28] Explicit valence for atom # 31 H, 2, is greater than permitted\n",
      "RDKit ERROR: [20:00:28] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Oc1cc(Cc2cc(O)c(O)cc2N([O-])=O)c(cc1O)N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)C1CC[C@H]1c1nc([H]C(F)F)cc(n1)C(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:30] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COc1ccccc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:31] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:31] Can't kekulize mol.  Unkekulized atoms: 11 13 14 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCOCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)CCCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:31] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: FC(F)(F)c1cccc(Nc2ccc3C(CCCN4CCOCC4)[N](=Cc3c2)c2ccccc2)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:32] Can't kekulize mol.  Unkekulized atoms: 12 13 14 16 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3[nH]c(OC)ccc3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:33] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(cc1)C(N)=O)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:33] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCNCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:34] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cccc2nc(CCNC(C)=O)cc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:34] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [20:00:34] Can't kekulize mol.  Unkekulized atoms: 15 17 18 19 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[N]1=CC(N2C(=O)c3c(C2=O)c(NS(=O)(=O)c2ccc(cc2)C(C)(C)C)ccc3Cl)=C(N1)C(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:34] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:35] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cccc2cc(CCNC(C)=O)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cnc3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:35] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 19\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:35] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(Cc2cc(O)c(O)cc2N([O-])=O)cc1O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:35] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(CC(=O)NC[N]3=COC=C3)C(=O)N2CC2CCC2)CC1)c1ccccc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [20:00:36] Can't kekulize mol.  Unkekulized atoms: 13 14 15 16 18 19 21\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [20:00:36] Explicit valence for atom # 8 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2F)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C1CCC(CC1)N(=O)C=C)c1cc(cn2cncc12)-c1ccc(O)cc1 convert to all 0 features\n",
      "encoding protein...\n",
      "unique target sequence: 3756\n",
      "splitting dataset...\n",
      "Done.\n",
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 50.3344. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 1.78170. Total time 0.00694 hours\n",
      "Training at Epoch 1 iteration 200 with loss 1.61313. Total time 0.01416 hours\n",
      "Training at Epoch 1 iteration 300 with loss 1.24685. Total time 0.02138 hours\n",
      "Training at Epoch 1 iteration 400 with loss 1.33094. Total time 0.02833 hours\n",
      "Training at Epoch 1 iteration 500 with loss 1.26012. Total time 0.03527 hours\n",
      "Training at Epoch 1 iteration 600 with loss 1.36044. Total time 0.04222 hours\n",
      "Training at Epoch 1 iteration 700 with loss 1.12687. Total time 0.04916 hours\n",
      "Training at Epoch 1 iteration 800 with loss 1.16547. Total time 0.05638 hours\n",
      "Validation at Epoch 1 with loss:1.11292, MSE: 1.10154 , Pearson Correlation: 0.71159 with p-value: 0.00E+00 , Concordance Index: 0.75098\n",
      "Training at Epoch 2 iteration 0 with loss 0.98217. Total time 0.07027 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.80742. Total time 0.0775 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.84993. Total time 0.08444 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.99459. Total time 0.09166 hours\n",
      "Training at Epoch 2 iteration 400 with loss 1.11005. Total time 0.09861 hours\n",
      "Training at Epoch 2 iteration 500 with loss 1.08046. Total time 0.10583 hours\n",
      "Training at Epoch 2 iteration 600 with loss 1.13538. Total time 0.11277 hours\n",
      "Training at Epoch 2 iteration 700 with loss 1.15382. Total time 0.11972 hours\n",
      "Training at Epoch 2 iteration 800 with loss 0.93221. Total time 0.12694 hours\n",
      "Validation at Epoch 2 with loss:0.83050, MSE: 1.08136 , Pearson Correlation: 0.74539 with p-value: 0.00E+00 , Concordance Index: 0.76775\n",
      "Training at Epoch 3 iteration 0 with loss 0.98364. Total time 0.14111 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.73765. Total time 0.14805 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.79438. Total time 0.15527 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.97735. Total time 0.16222 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.70286. Total time 0.16916 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.91708. Total time 0.17638 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.86166. Total time 0.18333 hours\n",
      "Training at Epoch 3 iteration 700 with loss 0.93665. Total time 0.19027 hours\n",
      "Training at Epoch 3 iteration 800 with loss 0.76705. Total time 0.1975 hours\n",
      "Validation at Epoch 3 with loss:0.75847, MSE: 0.94085 , Pearson Correlation: 0.75505 with p-value: 0.00E+00 , Concordance Index: 0.77260\n",
      "Training at Epoch 4 iteration 0 with loss 0.68120. Total time 0.21166 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.73522. Total time 0.21861 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.71125. Total time 0.22583 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.73400. Total time 0.23277 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.66863. Total time 0.24 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.74687. Total time 0.24694 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.91676. Total time 0.25388 hours\n",
      "Training at Epoch 4 iteration 700 with loss 0.70183. Total time 0.26111 hours\n",
      "Training at Epoch 4 iteration 800 with loss 0.76039. Total time 0.26805 hours\n",
      "Validation at Epoch 4 with loss:0.85307, MSE: 0.90768 , Pearson Correlation: 0.75945 with p-value: 0.00E+00 , Concordance Index: 0.77497\n",
      "Training at Epoch 5 iteration 0 with loss 0.58389. Total time 0.28222 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.76160. Total time 0.28916 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.53324. Total time 0.29611 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.62848. Total time 0.30305 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.71015. Total time 0.31 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.72243. Total time 0.31722 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.66571. Total time 0.32444 hours\n",
      "Training at Epoch 5 iteration 700 with loss 0.75438. Total time 0.33138 hours\n",
      "Training at Epoch 5 iteration 800 with loss 0.75056. Total time 0.33861 hours\n",
      "Validation at Epoch 5 with loss:1.00381, MSE: 0.99547 , Pearson Correlation: 0.76005 with p-value: 0.00E+00 , Concordance Index: 0.77604\n",
      "Training at Epoch 6 iteration 0 with loss 0.68747. Total time 0.3525 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.57310. Total time 0.35972 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.68321. Total time 0.36666 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.69378. Total time 0.37361 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.67773. Total time 0.38055 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.70031. Total time 0.3875 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.54514. Total time 0.39472 hours\n",
      "Training at Epoch 6 iteration 700 with loss 0.70199. Total time 0.40166 hours\n",
      "Training at Epoch 6 iteration 800 with loss 0.62923. Total time 0.40861 hours\n",
      "Validation at Epoch 6 with loss:0.99575, MSE: 0.90510 , Pearson Correlation: 0.76216 with p-value: 0.00E+00 , Concordance Index: 0.77745\n",
      "Training at Epoch 7 iteration 0 with loss 0.66292. Total time 0.42277 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.52937. Total time 0.42972 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.61721. Total time 0.43666 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.52871. Total time 0.44361 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.53911. Total time 0.45083 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.53548. Total time 0.45777 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.60204. Total time 0.46472 hours\n",
      "Training at Epoch 7 iteration 700 with loss 0.76579. Total time 0.47194 hours\n",
      "Training at Epoch 7 iteration 800 with loss 0.59456. Total time 0.47888 hours\n",
      "Validation at Epoch 7 with loss:0.95148, MSE: 0.87908 , Pearson Correlation: 0.77539 with p-value: 0.00E+00 , Concordance Index: 0.78636\n",
      "Training at Epoch 8 iteration 0 with loss 0.48958. Total time 0.49277 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.55533. Total time 0.5 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.54001. Total time 0.50722 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.58204. Total time 0.51416 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.52080. Total time 0.52138 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.56111. Total time 0.52833 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.69652. Total time 0.53527 hours\n",
      "Training at Epoch 8 iteration 700 with loss 0.65478. Total time 0.54222 hours\n",
      "Training at Epoch 8 iteration 800 with loss 0.57114. Total time 0.54916 hours\n",
      "Validation at Epoch 8 with loss:0.74165, MSE: 0.82782 , Pearson Correlation: 0.78625 with p-value: 0.00E+00 , Concordance Index: 0.79255\n",
      "Training at Epoch 9 iteration 0 with loss 0.49367. Total time 0.56333 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.51974. Total time 0.57055 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.52814. Total time 0.57722 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.41896. Total time 0.58416 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.41237. Total time 0.59138 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.35102. Total time 0.59833 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.52110. Total time 0.60555 hours\n",
      "Training at Epoch 9 iteration 700 with loss 0.46792. Total time 0.6125 hours\n",
      "Training at Epoch 9 iteration 800 with loss 0.51416. Total time 0.61944 hours\n",
      "Validation at Epoch 9 with loss:0.79933, MSE: 0.79648 , Pearson Correlation: 0.79551 with p-value: 0.00E+00 , Concordance Index: 0.79857\n",
      "Training at Epoch 10 iteration 0 with loss 0.46736. Total time 0.63361 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.37284. Total time 0.64055 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.40851. Total time 0.6475 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.44253. Total time 0.65472 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 10 iteration 400 with loss 0.45319. Total time 0.66166 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.42442. Total time 0.66861 hours\n",
      "Training at Epoch 10 iteration 600 with loss 0.38381. Total time 0.67555 hours\n",
      "Training at Epoch 10 iteration 700 with loss 0.47266. Total time 0.68277 hours\n",
      "Training at Epoch 10 iteration 800 with loss 0.53978. Total time 0.68972 hours\n",
      "Validation at Epoch 10 with loss:0.76369, MSE: 0.79574 , Pearson Correlation: 0.79972 with p-value: 0.00E+00 , Concordance Index: 0.80149\n",
      "Training at Epoch 11 iteration 0 with loss 0.33218. Total time 0.70388 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.42571. Total time 0.71083 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.50153. Total time 0.71805 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.35532. Total time 0.725 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.44239. Total time 0.73194 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.48814. Total time 0.73916 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.40017. Total time 0.74638 hours\n",
      "Training at Epoch 11 iteration 700 with loss 0.46979. Total time 0.75333 hours\n",
      "Training at Epoch 11 iteration 800 with loss 0.42327. Total time 0.76027 hours\n",
      "Validation at Epoch 11 with loss:0.72123, MSE: 0.77098 , Pearson Correlation: 0.80314 with p-value: 0.00E+00 , Concordance Index: 0.80378\n",
      "Training at Epoch 12 iteration 0 with loss 0.38758. Total time 0.77444 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.33147. Total time 0.78138 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.40413. Total time 0.78861 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.30461. Total time 0.79583 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.29885. Total time 0.80277 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.35899. Total time 0.80972 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.34522. Total time 0.81694 hours\n",
      "Training at Epoch 12 iteration 700 with loss 0.49843. Total time 0.82388 hours\n",
      "Training at Epoch 12 iteration 800 with loss 0.39079. Total time 0.83111 hours\n",
      "Validation at Epoch 12 with loss:0.69008, MSE: 0.75083 , Pearson Correlation: 0.80835 with p-value: 0.00E+00 , Concordance Index: 0.80723\n",
      "Training at Epoch 13 iteration 0 with loss 0.27269. Total time 0.84527 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.40163. Total time 0.85222 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.40442. Total time 0.85944 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.39528. Total time 0.86638 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.33081. Total time 0.87333 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.37385. Total time 0.88055 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.34296. Total time 0.8875 hours\n",
      "Training at Epoch 13 iteration 700 with loss 0.35990. Total time 0.89472 hours\n",
      "Training at Epoch 13 iteration 800 with loss 0.40089. Total time 0.90166 hours\n",
      "Validation at Epoch 13 with loss:0.69654, MSE: 0.74747 , Pearson Correlation: 0.80824 with p-value: 0.00E+00 , Concordance Index: 0.80707\n",
      "Training at Epoch 14 iteration 0 with loss 0.34039. Total time 0.91583 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.32019. Total time 0.92277 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.34585. Total time 0.92972 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.38301. Total time 0.93694 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.31494. Total time 0.94388 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.33129. Total time 0.95083 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.32953. Total time 0.95805 hours\n",
      "Training at Epoch 14 iteration 700 with loss 0.36828. Total time 0.965 hours\n",
      "Training at Epoch 14 iteration 800 with loss 0.39253. Total time 0.97222 hours\n",
      "Validation at Epoch 14 with loss:0.55015, MSE: 0.73672 , Pearson Correlation: 0.81048 with p-value: 0.00E+00 , Concordance Index: 0.80855\n",
      "Training at Epoch 15 iteration 0 with loss 0.29462. Total time 0.98638 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.26444. Total time 0.99361 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.28604. Total time 1.00083 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.33545. Total time 1.00833 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.29113. Total time 1.01555 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.36387. Total time 1.0225 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.31055. Total time 1.02944 hours\n",
      "Training at Epoch 15 iteration 700 with loss 0.33964. Total time 1.03666 hours\n",
      "Training at Epoch 15 iteration 800 with loss 0.32261. Total time 1.04361 hours\n",
      "Validation at Epoch 15 with loss:0.81435, MSE: 0.74600 , Pearson Correlation: 0.81343 with p-value: 0.00E+00 , Concordance Index: 0.81039\n",
      "Training at Epoch 16 iteration 0 with loss 0.34802. Total time 1.05805 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.28280. Total time 1.06527 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.26221. Total time 1.0725 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.32748. Total time 1.07944 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.31960. Total time 1.08666 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.44568. Total time 1.09361 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.26614. Total time 1.10055 hours\n",
      "Training at Epoch 16 iteration 700 with loss 0.36654. Total time 1.10805 hours\n",
      "Training at Epoch 16 iteration 800 with loss 0.30509. Total time 1.115 hours\n",
      "Validation at Epoch 16 with loss:0.57125, MSE: 0.72656 , Pearson Correlation: 0.81347 with p-value: 0.00E+00 , Concordance Index: 0.81053\n",
      "Training at Epoch 17 iteration 0 with loss 0.26680. Total time 1.12944 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.25559. Total time 1.13666 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.27824. Total time 1.14361 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.32124. Total time 1.15055 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.35806. Total time 1.15805 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.36990. Total time 1.16527 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.25047. Total time 1.1725 hours\n",
      "Training at Epoch 17 iteration 700 with loss 0.23978. Total time 1.17944 hours\n",
      "Training at Epoch 17 iteration 800 with loss 0.31556. Total time 1.18638 hours\n",
      "Validation at Epoch 17 with loss:0.86986, MSE: 0.72211 , Pearson Correlation: 0.81605 with p-value: 0.00E+00 , Concordance Index: 0.81240\n",
      "Training at Epoch 18 iteration 0 with loss 0.27658. Total time 1.20027 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.23683. Total time 1.20722 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.26755. Total time 1.21416 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.23048. Total time 1.22111 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.21705. Total time 1.22805 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.28166. Total time 1.235 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.35483. Total time 1.2425 hours\n",
      "Training at Epoch 18 iteration 700 with loss 0.34780. Total time 1.24972 hours\n",
      "Training at Epoch 18 iteration 800 with loss 0.28380. Total time 1.25694 hours\n",
      "Validation at Epoch 18 with loss:0.76713, MSE: 0.72530 , Pearson Correlation: 0.81678 with p-value: 0.00E+00 , Concordance Index: 0.81307\n",
      "Training at Epoch 19 iteration 0 with loss 0.26377. Total time 1.27083 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.34221. Total time 1.27805 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.25631. Total time 1.285 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.23550. Total time 1.29194 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.29694. Total time 1.29888 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.26913. Total time 1.30611 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.27363. Total time 1.31305 hours\n",
      "Training at Epoch 19 iteration 700 with loss 0.26047. Total time 1.32 hours\n",
      "Training at Epoch 19 iteration 800 with loss 0.24748. Total time 1.32694 hours\n",
      "Validation at Epoch 19 with loss:0.61194, MSE: 0.74571 , Pearson Correlation: 0.81532 with p-value: 0.00E+00 , Concordance Index: 0.81240\n",
      "Training at Epoch 20 iteration 0 with loss 0.26874. Total time 1.34083 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 20 iteration 100 with loss 0.23993. Total time 1.34805 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.29715. Total time 1.355 hours\n",
      "Training at Epoch 20 iteration 300 with loss 0.22783. Total time 1.36194 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.24619. Total time 1.36916 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.24008. Total time 1.37611 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.29744. Total time 1.38305 hours\n",
      "Training at Epoch 20 iteration 700 with loss 0.25274. Total time 1.39027 hours\n",
      "Training at Epoch 20 iteration 800 with loss 0.25733. Total time 1.39722 hours\n",
      "Validation at Epoch 20 with loss:0.62337, MSE: 0.71878 , Pearson Correlation: 0.81841 with p-value: 0.00E+00 , Concordance Index: 0.81389\n",
      "Training at Epoch 21 iteration 0 with loss 0.20062. Total time 1.41138 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.30172. Total time 1.41861 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.19574. Total time 1.42583 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.22688. Total time 1.43333 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.26781. Total time 1.44055 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.23287. Total time 1.4475 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.29092. Total time 1.45472 hours\n",
      "Training at Epoch 21 iteration 700 with loss 0.26141. Total time 1.46166 hours\n",
      "Training at Epoch 21 iteration 800 with loss 0.25477. Total time 1.46861 hours\n",
      "Validation at Epoch 21 with loss:0.67549, MSE: 0.72517 , Pearson Correlation: 0.81457 with p-value: 0.00E+00 , Concordance Index: 0.81230\n",
      "Training at Epoch 22 iteration 0 with loss 0.18185. Total time 1.48277 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.19017. Total time 1.48972 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.40872. Total time 1.49666 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.27544. Total time 1.50388 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.21756. Total time 1.51083 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.27630. Total time 1.51777 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.33133. Total time 1.525 hours\n",
      "Training at Epoch 22 iteration 700 with loss 0.30516. Total time 1.53194 hours\n",
      "Training at Epoch 22 iteration 800 with loss 0.31505. Total time 1.53888 hours\n",
      "Validation at Epoch 22 with loss:0.74577, MSE: 0.72175 , Pearson Correlation: 0.81959 with p-value: 0.00E+00 , Concordance Index: 0.81492\n",
      "Training at Epoch 23 iteration 0 with loss 0.22431. Total time 1.55333 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.22998. Total time 1.56027 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.21086. Total time 1.5675 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.24793. Total time 1.57444 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.26379. Total time 1.58138 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.20729. Total time 1.58861 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.24429. Total time 1.59555 hours\n",
      "Training at Epoch 23 iteration 700 with loss 0.24120. Total time 1.6025 hours\n",
      "Training at Epoch 23 iteration 800 with loss 0.27837. Total time 1.60972 hours\n",
      "Validation at Epoch 23 with loss:0.63404, MSE: 0.71907 , Pearson Correlation: 0.81956 with p-value: 0.00E+00 , Concordance Index: 0.81501\n",
      "Training at Epoch 24 iteration 0 with loss 0.18933. Total time 1.62416 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.19064. Total time 1.63138 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.22432. Total time 1.63861 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.17454. Total time 1.64583 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.23860. Total time 1.65277 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.20285. Total time 1.65972 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.23674. Total time 1.66694 hours\n",
      "Training at Epoch 24 iteration 700 with loss 0.23652. Total time 1.67388 hours\n",
      "Training at Epoch 24 iteration 800 with loss 0.29940. Total time 1.68111 hours\n",
      "Validation at Epoch 24 with loss:0.87777, MSE: 0.71601 , Pearson Correlation: 0.81827 with p-value: 0.00E+00 , Concordance Index: 0.81472\n",
      "Training at Epoch 25 iteration 0 with loss 0.18601. Total time 1.695 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.18451. Total time 1.70222 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.19842. Total time 1.70916 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.20359. Total time 1.71638 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.23183. Total time 1.72333 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.27039. Total time 1.73055 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.20920. Total time 1.7375 hours\n",
      "Training at Epoch 25 iteration 700 with loss 0.20799. Total time 1.74444 hours\n",
      "Training at Epoch 25 iteration 800 with loss 0.20220. Total time 1.75166 hours\n",
      "Validation at Epoch 25 with loss:0.70120, MSE: 0.72197 , Pearson Correlation: 0.81815 with p-value: 0.00E+00 , Concordance Index: 0.81484\n",
      "Training at Epoch 26 iteration 0 with loss 0.19114. Total time 1.76555 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.24406. Total time 1.77277 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.19509. Total time 1.77972 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.17118. Total time 1.78666 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.20190. Total time 1.79361 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.25068. Total time 1.80083 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.25692. Total time 1.80777 hours\n",
      "Training at Epoch 26 iteration 700 with loss 0.21668. Total time 1.81472 hours\n",
      "Training at Epoch 26 iteration 800 with loss 0.23020. Total time 1.82166 hours\n",
      "Validation at Epoch 26 with loss:0.74708, MSE: 0.70377 , Pearson Correlation: 0.81916 with p-value: 0.00E+00 , Concordance Index: 0.81540\n",
      "Training at Epoch 27 iteration 0 with loss 0.17380. Total time 1.83583 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.19989. Total time 1.84305 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.13949. Total time 1.85055 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.25405. Total time 1.8575 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.18495. Total time 1.86444 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.23000. Total time 1.87138 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.20095. Total time 1.87833 hours\n",
      "Training at Epoch 27 iteration 700 with loss 0.20046. Total time 1.88527 hours\n",
      "Training at Epoch 27 iteration 800 with loss 0.21253. Total time 1.89222 hours\n",
      "Validation at Epoch 27 with loss:0.60052, MSE: 0.70458 , Pearson Correlation: 0.81963 with p-value: 0.00E+00 , Concordance Index: 0.81537\n",
      "Training at Epoch 28 iteration 0 with loss 0.19308. Total time 1.90638 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.20153. Total time 1.91333 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.20830. Total time 1.92055 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.17305. Total time 1.9275 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.19402. Total time 1.93444 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.26665. Total time 1.94166 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.21262. Total time 1.94916 hours\n",
      "Training at Epoch 28 iteration 700 with loss 0.25853. Total time 1.95638 hours\n",
      "Training at Epoch 28 iteration 800 with loss 0.19789. Total time 1.96333 hours\n",
      "Validation at Epoch 28 with loss:0.66120, MSE: 0.69458 , Pearson Correlation: 0.82257 with p-value: 0.00E+00 , Concordance Index: 0.81663\n",
      "Training at Epoch 29 iteration 0 with loss 0.19534. Total time 1.9775 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.17465. Total time 1.98444 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.20017. Total time 1.99166 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.17860. Total time 1.99888 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.21573. Total time 2.00583 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.26963. Total time 2.01305 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.18253. Total time 2.02 hours\n",
      "Training at Epoch 29 iteration 700 with loss 0.20298. Total time 2.02722 hours\n",
      "Training at Epoch 29 iteration 800 with loss 0.22721. Total time 2.03416 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation at Epoch 29 with loss:0.69647, MSE: 0.70127 , Pearson Correlation: 0.82061 with p-value: 0.00E+00 , Concordance Index: 0.81612\n",
      "Training at Epoch 30 iteration 0 with loss 0.18719. Total time 2.04888 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.24587. Total time 2.05611 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.20496. Total time 2.06305 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.15213. Total time 2.07027 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.21438. Total time 2.07722 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.19607. Total time 2.08444 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.15623. Total time 2.09138 hours\n",
      "Training at Epoch 30 iteration 700 with loss 0.21952. Total time 2.09861 hours\n",
      "Training at Epoch 30 iteration 800 with loss 0.15551. Total time 2.10555 hours\n",
      "Validation at Epoch 30 with loss:0.71944, MSE: 0.71461 , Pearson Correlation: 0.82229 with p-value: 0.00E+00 , Concordance Index: 0.81647\n",
      "Training at Epoch 31 iteration 0 with loss 0.16115. Total time 2.11972 hours\n",
      "Training at Epoch 31 iteration 100 with loss 0.22302. Total time 2.12666 hours\n",
      "Training at Epoch 31 iteration 200 with loss 0.14818. Total time 2.13361 hours\n",
      "Training at Epoch 31 iteration 300 with loss 0.21898. Total time 2.14083 hours\n",
      "Training at Epoch 31 iteration 400 with loss 0.27543. Total time 2.14777 hours\n",
      "Training at Epoch 31 iteration 500 with loss 0.18128. Total time 2.155 hours\n",
      "Training at Epoch 31 iteration 600 with loss 0.23973. Total time 2.16222 hours\n",
      "Training at Epoch 31 iteration 700 with loss 0.19402. Total time 2.16916 hours\n",
      "Training at Epoch 31 iteration 800 with loss 0.19633. Total time 2.17638 hours\n",
      "Validation at Epoch 31 with loss:0.63708, MSE: 0.71529 , Pearson Correlation: 0.82154 with p-value: 0.00E+00 , Concordance Index: 0.81670\n",
      "Training at Epoch 32 iteration 0 with loss 0.19394. Total time 2.19027 hours\n",
      "Training at Epoch 32 iteration 100 with loss 0.20228. Total time 2.1975 hours\n",
      "Training at Epoch 32 iteration 200 with loss 0.19947. Total time 2.20472 hours\n",
      "Training at Epoch 32 iteration 300 with loss 0.19643. Total time 2.21166 hours\n",
      "Training at Epoch 32 iteration 400 with loss 0.17808. Total time 2.21861 hours\n",
      "Training at Epoch 32 iteration 500 with loss 0.18487. Total time 2.22555 hours\n",
      "Training at Epoch 32 iteration 600 with loss 0.14699. Total time 2.2325 hours\n",
      "Training at Epoch 32 iteration 700 with loss 0.22843. Total time 2.23944 hours\n",
      "Training at Epoch 32 iteration 800 with loss 0.18960. Total time 2.24638 hours\n",
      "Validation at Epoch 32 with loss:0.80122, MSE: 0.69387 , Pearson Correlation: 0.82346 with p-value: 0.00E+00 , Concordance Index: 0.81744\n",
      "Training at Epoch 33 iteration 0 with loss 0.17259. Total time 2.26055 hours\n",
      "Training at Epoch 33 iteration 100 with loss 0.17403. Total time 2.2675 hours\n",
      "Training at Epoch 33 iteration 200 with loss 0.24591. Total time 2.27472 hours\n",
      "Training at Epoch 33 iteration 300 with loss 0.16870. Total time 2.28166 hours\n",
      "Training at Epoch 33 iteration 400 with loss 0.17665. Total time 2.28888 hours\n",
      "Training at Epoch 33 iteration 500 with loss 0.31638. Total time 2.29583 hours\n",
      "Training at Epoch 33 iteration 600 with loss 0.20085. Total time 2.30305 hours\n",
      "Training at Epoch 33 iteration 700 with loss 0.17366. Total time 2.31 hours\n",
      "Training at Epoch 33 iteration 800 with loss 0.20705. Total time 2.31694 hours\n",
      "Validation at Epoch 33 with loss:0.69849, MSE: 0.70187 , Pearson Correlation: 0.82296 with p-value: 0.00E+00 , Concordance Index: 0.81774\n",
      "Training at Epoch 34 iteration 0 with loss 0.15040. Total time 2.33111 hours\n",
      "Training at Epoch 34 iteration 100 with loss 0.16467. Total time 2.33833 hours\n",
      "Training at Epoch 34 iteration 200 with loss 0.20142. Total time 2.34527 hours\n",
      "Training at Epoch 34 iteration 300 with loss 0.16372. Total time 2.3525 hours\n",
      "Training at Epoch 34 iteration 400 with loss 0.18940. Total time 2.35944 hours\n",
      "Training at Epoch 34 iteration 500 with loss 0.19293. Total time 2.36638 hours\n",
      "Training at Epoch 34 iteration 600 with loss 0.17959. Total time 2.37333 hours\n",
      "Training at Epoch 34 iteration 700 with loss 0.22175. Total time 2.38027 hours\n",
      "Training at Epoch 34 iteration 800 with loss 0.24593. Total time 2.3875 hours\n",
      "Validation at Epoch 34 with loss:0.61981, MSE: 0.71104 , Pearson Correlation: 0.82258 with p-value: 0.00E+00 , Concordance Index: 0.81736\n",
      "Training at Epoch 35 iteration 0 with loss 0.12741. Total time 2.40166 hours\n",
      "Training at Epoch 35 iteration 100 with loss 0.16430. Total time 2.40888 hours\n",
      "Training at Epoch 35 iteration 200 with loss 0.14015. Total time 2.41583 hours\n",
      "Training at Epoch 35 iteration 300 with loss 0.18013. Total time 2.42277 hours\n",
      "Training at Epoch 35 iteration 400 with loss 0.16327. Total time 2.43 hours\n",
      "Training at Epoch 35 iteration 500 with loss 0.17399. Total time 2.43694 hours\n",
      "Training at Epoch 35 iteration 600 with loss 0.17280. Total time 2.44388 hours\n",
      "Training at Epoch 35 iteration 700 with loss 0.24332. Total time 2.45111 hours\n",
      "Training at Epoch 35 iteration 800 with loss 0.14685. Total time 2.45805 hours\n",
      "Validation at Epoch 35 with loss:0.64112, MSE: 0.69689 , Pearson Correlation: 0.82318 with p-value: 0.00E+00 , Concordance Index: 0.81745\n",
      "Training at Epoch 36 iteration 0 with loss 0.12376. Total time 2.47222 hours\n",
      "Training at Epoch 36 iteration 100 with loss 0.13115. Total time 2.47944 hours\n",
      "Training at Epoch 36 iteration 200 with loss 0.14860. Total time 2.48666 hours\n",
      "Training at Epoch 36 iteration 300 with loss 0.16371. Total time 2.49388 hours\n",
      "Training at Epoch 36 iteration 400 with loss 0.12795. Total time 2.50083 hours\n",
      "Training at Epoch 36 iteration 500 with loss 0.17501. Total time 2.50805 hours\n",
      "Training at Epoch 36 iteration 600 with loss 0.17719. Total time 2.515 hours\n",
      "Training at Epoch 36 iteration 700 with loss 0.16215. Total time 2.52194 hours\n",
      "Training at Epoch 36 iteration 800 with loss 0.16841. Total time 2.52888 hours\n",
      "Validation at Epoch 36 with loss:0.76269, MSE: 0.69550 , Pearson Correlation: 0.82481 with p-value: 0.00E+00 , Concordance Index: 0.81873\n",
      "Training at Epoch 37 iteration 0 with loss 0.12268. Total time 2.54277 hours\n",
      "Training at Epoch 37 iteration 100 with loss 0.14858. Total time 2.55 hours\n",
      "Training at Epoch 37 iteration 200 with loss 0.19124. Total time 2.55722 hours\n",
      "Training at Epoch 37 iteration 300 with loss 0.12743. Total time 2.56416 hours\n",
      "Training at Epoch 37 iteration 400 with loss 0.22466. Total time 2.57138 hours\n",
      "Training at Epoch 37 iteration 500 with loss 0.20113. Total time 2.57833 hours\n",
      "Training at Epoch 37 iteration 600 with loss 0.21984. Total time 2.58527 hours\n",
      "Training at Epoch 37 iteration 700 with loss 0.19361. Total time 2.59222 hours\n",
      "Training at Epoch 37 iteration 800 with loss 0.17330. Total time 2.59916 hours\n",
      "Validation at Epoch 37 with loss:0.68915, MSE: 0.69851 , Pearson Correlation: 0.82457 with p-value: 0.00E+00 , Concordance Index: 0.81888\n",
      "Training at Epoch 38 iteration 0 with loss 0.12989. Total time 2.61333 hours\n",
      "Training at Epoch 38 iteration 100 with loss 0.14430. Total time 2.62055 hours\n",
      "Training at Epoch 38 iteration 200 with loss 0.12751. Total time 2.62777 hours\n",
      "Training at Epoch 38 iteration 300 with loss 0.15509. Total time 2.63527 hours\n",
      "Training at Epoch 38 iteration 400 with loss 0.16844. Total time 2.64222 hours\n",
      "Training at Epoch 38 iteration 500 with loss 0.16248. Total time 2.64944 hours\n",
      "Training at Epoch 38 iteration 600 with loss 0.17526. Total time 2.65638 hours\n",
      "Training at Epoch 38 iteration 700 with loss 0.20600. Total time 2.66333 hours\n",
      "Training at Epoch 38 iteration 800 with loss 0.18108. Total time 2.67027 hours\n",
      "Validation at Epoch 38 with loss:0.67154, MSE: 0.69630 , Pearson Correlation: 0.82371 with p-value: 0.00E+00 , Concordance Index: 0.81802\n",
      "Training at Epoch 39 iteration 0 with loss 0.15378. Total time 2.68416 hours\n",
      "Training at Epoch 39 iteration 100 with loss 0.17524. Total time 2.69111 hours\n",
      "Training at Epoch 39 iteration 200 with loss 0.16120. Total time 2.69805 hours\n",
      "Training at Epoch 39 iteration 300 with loss 0.12005. Total time 2.705 hours\n",
      "Training at Epoch 39 iteration 400 with loss 0.13510. Total time 2.71222 hours\n",
      "Training at Epoch 39 iteration 500 with loss 0.18867. Total time 2.71916 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 39 iteration 600 with loss 0.16957. Total time 2.72638 hours\n",
      "Training at Epoch 39 iteration 700 with loss 0.15701. Total time 2.73333 hours\n",
      "Training at Epoch 39 iteration 800 with loss 0.14286. Total time 2.74027 hours\n",
      "Validation at Epoch 39 with loss:0.58913, MSE: 0.69422 , Pearson Correlation: 0.82240 with p-value: 0.00E+00 , Concordance Index: 0.81740\n",
      "Training at Epoch 40 iteration 0 with loss 0.14048. Total time 2.75472 hours\n",
      "Training at Epoch 40 iteration 100 with loss 0.11675. Total time 2.76222 hours\n",
      "Training at Epoch 40 iteration 200 with loss 0.17912. Total time 2.76916 hours\n",
      "Training at Epoch 40 iteration 300 with loss 0.13456. Total time 2.77638 hours\n",
      "Training at Epoch 40 iteration 400 with loss 0.15815. Total time 2.78333 hours\n",
      "Training at Epoch 40 iteration 500 with loss 0.15949. Total time 2.79055 hours\n",
      "Training at Epoch 40 iteration 600 with loss 0.15933. Total time 2.7975 hours\n",
      "Training at Epoch 40 iteration 700 with loss 0.12281. Total time 2.80472 hours\n",
      "Training at Epoch 40 iteration 800 with loss 0.16018. Total time 2.81166 hours\n",
      "Validation at Epoch 40 with loss:0.81524, MSE: 0.68923 , Pearson Correlation: 0.82341 with p-value: 0.00E+00 , Concordance Index: 0.81816\n",
      "Training at Epoch 41 iteration 0 with loss 0.14457. Total time 2.82583 hours\n",
      "Training at Epoch 41 iteration 100 with loss 0.16384. Total time 2.83277 hours\n",
      "Training at Epoch 41 iteration 200 with loss 0.14636. Total time 2.84 hours\n",
      "Training at Epoch 41 iteration 300 with loss 0.16151. Total time 2.84722 hours\n",
      "Training at Epoch 41 iteration 400 with loss 0.13896. Total time 2.85472 hours\n",
      "Training at Epoch 41 iteration 500 with loss 0.15049. Total time 2.86194 hours\n",
      "Training at Epoch 41 iteration 600 with loss 0.18063. Total time 2.86888 hours\n",
      "Training at Epoch 41 iteration 700 with loss 0.16522. Total time 2.87611 hours\n",
      "Training at Epoch 41 iteration 800 with loss 0.16913. Total time 2.88305 hours\n",
      "Validation at Epoch 41 with loss:0.69912, MSE: 0.69679 , Pearson Correlation: 0.82301 with p-value: 0.00E+00 , Concordance Index: 0.81789\n",
      "Training at Epoch 42 iteration 0 with loss 0.13316. Total time 2.89722 hours\n",
      "Training at Epoch 42 iteration 100 with loss 0.14260. Total time 2.90416 hours\n",
      "Training at Epoch 42 iteration 200 with loss 0.13873. Total time 2.91138 hours\n",
      "Training at Epoch 42 iteration 300 with loss 0.09046. Total time 2.91833 hours\n",
      "Training at Epoch 42 iteration 400 with loss 0.14846. Total time 2.92555 hours\n",
      "Training at Epoch 42 iteration 500 with loss 0.16711. Total time 2.9325 hours\n",
      "Training at Epoch 42 iteration 600 with loss 0.14687. Total time 2.93944 hours\n",
      "Training at Epoch 42 iteration 700 with loss 0.10462. Total time 2.94666 hours\n",
      "Training at Epoch 42 iteration 800 with loss 0.13110. Total time 2.95361 hours\n",
      "Validation at Epoch 42 with loss:0.69299, MSE: 0.68723 , Pearson Correlation: 0.82421 with p-value: 0.00E+00 , Concordance Index: 0.81853\n",
      "Training at Epoch 43 iteration 0 with loss 0.15576. Total time 2.96777 hours\n",
      "Training at Epoch 43 iteration 100 with loss 0.14625. Total time 2.97472 hours\n",
      "Training at Epoch 43 iteration 200 with loss 0.11304. Total time 2.98166 hours\n",
      "Training at Epoch 43 iteration 300 with loss 0.13644. Total time 2.98861 hours\n",
      "Training at Epoch 43 iteration 400 with loss 0.12287. Total time 2.99555 hours\n",
      "Training at Epoch 43 iteration 500 with loss 0.12398. Total time 3.0025 hours\n",
      "Training at Epoch 43 iteration 600 with loss 0.16959. Total time 3.00972 hours\n",
      "Training at Epoch 43 iteration 700 with loss 0.16657. Total time 3.01666 hours\n",
      "Training at Epoch 43 iteration 800 with loss 0.14030. Total time 3.02361 hours\n",
      "Validation at Epoch 43 with loss:0.77435, MSE: 0.69646 , Pearson Correlation: 0.82450 with p-value: 0.00E+00 , Concordance Index: 0.81890\n",
      "Training at Epoch 44 iteration 0 with loss 0.13740. Total time 3.03777 hours\n",
      "Training at Epoch 44 iteration 100 with loss 0.11551. Total time 3.04527 hours\n",
      "Training at Epoch 44 iteration 200 with loss 0.11275. Total time 3.0525 hours\n",
      "Training at Epoch 44 iteration 300 with loss 0.12048. Total time 3.05944 hours\n",
      "Training at Epoch 44 iteration 400 with loss 0.14552. Total time 3.06666 hours\n",
      "Training at Epoch 44 iteration 500 with loss 0.13571. Total time 3.07361 hours\n",
      "Training at Epoch 44 iteration 600 with loss 0.14681. Total time 3.08055 hours\n",
      "Training at Epoch 44 iteration 700 with loss 0.18523. Total time 3.08777 hours\n",
      "Training at Epoch 44 iteration 800 with loss 0.14112. Total time 3.09472 hours\n",
      "Validation at Epoch 44 with loss:0.79402, MSE: 0.69446 , Pearson Correlation: 0.82338 with p-value: 0.00E+00 , Concordance Index: 0.81844\n",
      "Training at Epoch 45 iteration 0 with loss 0.11356. Total time 3.10888 hours\n",
      "Training at Epoch 45 iteration 100 with loss 0.14922. Total time 3.11583 hours\n",
      "Training at Epoch 45 iteration 200 with loss 0.11428. Total time 3.12277 hours\n",
      "Training at Epoch 45 iteration 300 with loss 0.13638. Total time 3.13 hours\n",
      "Training at Epoch 45 iteration 400 with loss 0.11630. Total time 3.13694 hours\n",
      "Training at Epoch 45 iteration 500 with loss 0.13182. Total time 3.14416 hours\n",
      "Training at Epoch 45 iteration 600 with loss 0.13234. Total time 3.15111 hours\n",
      "Training at Epoch 45 iteration 700 with loss 0.18556. Total time 3.15833 hours\n",
      "Training at Epoch 45 iteration 800 with loss 0.13202. Total time 3.16527 hours\n",
      "Validation at Epoch 45 with loss:0.65966, MSE: 0.68653 , Pearson Correlation: 0.82418 with p-value: 0.00E+00 , Concordance Index: 0.81883\n",
      "Training at Epoch 46 iteration 0 with loss 0.14285. Total time 3.17944 hours\n",
      "Training at Epoch 46 iteration 100 with loss 0.14639. Total time 3.18666 hours\n",
      "Training at Epoch 46 iteration 200 with loss 0.11971. Total time 3.19361 hours\n",
      "Training at Epoch 46 iteration 300 with loss 0.17084. Total time 3.20083 hours\n",
      "Training at Epoch 46 iteration 400 with loss 0.13496. Total time 3.20777 hours\n",
      "Training at Epoch 46 iteration 500 with loss 0.15375. Total time 3.215 hours\n",
      "Training at Epoch 46 iteration 600 with loss 0.13407. Total time 3.22194 hours\n",
      "Training at Epoch 46 iteration 700 with loss 0.18389. Total time 3.22888 hours\n",
      "Training at Epoch 46 iteration 800 with loss 0.14424. Total time 3.23611 hours\n",
      "Validation at Epoch 46 with loss:0.64139, MSE: 0.71457 , Pearson Correlation: 0.82461 with p-value: 0.00E+00 , Concordance Index: 0.81912\n",
      "Training at Epoch 47 iteration 0 with loss 0.14388. Total time 3.25027 hours\n",
      "Training at Epoch 47 iteration 100 with loss 0.12564. Total time 3.25722 hours\n",
      "Training at Epoch 47 iteration 200 with loss 0.12101. Total time 3.26444 hours\n",
      "Training at Epoch 47 iteration 300 with loss 0.12578. Total time 3.27138 hours\n",
      "Training at Epoch 47 iteration 400 with loss 0.13540. Total time 3.27861 hours\n",
      "Training at Epoch 47 iteration 500 with loss 0.13110. Total time 3.28555 hours\n",
      "Training at Epoch 47 iteration 600 with loss 0.16906. Total time 3.2925 hours\n",
      "Training at Epoch 47 iteration 700 with loss 0.15799. Total time 3.29972 hours\n",
      "Training at Epoch 47 iteration 800 with loss 0.14898. Total time 3.30666 hours\n",
      "Validation at Epoch 47 with loss:0.69268, MSE: 0.70363 , Pearson Correlation: 0.82367 with p-value: 0.00E+00 , Concordance Index: 0.81827\n",
      "Training at Epoch 48 iteration 0 with loss 0.12751. Total time 3.32083 hours\n",
      "Training at Epoch 48 iteration 100 with loss 0.18659. Total time 3.32777 hours\n",
      "Training at Epoch 48 iteration 200 with loss 0.13189. Total time 3.33472 hours\n",
      "Training at Epoch 48 iteration 300 with loss 0.11710. Total time 3.34194 hours\n",
      "Training at Epoch 48 iteration 400 with loss 0.12074. Total time 3.34888 hours\n",
      "Training at Epoch 48 iteration 500 with loss 0.14070. Total time 3.35611 hours\n",
      "Training at Epoch 48 iteration 600 with loss 0.14370. Total time 3.36305 hours\n",
      "Training at Epoch 48 iteration 700 with loss 0.11687. Total time 3.37027 hours\n",
      "Training at Epoch 48 iteration 800 with loss 0.14491. Total time 3.37722 hours\n",
      "Validation at Epoch 48 with loss:0.62661, MSE: 0.69474 , Pearson Correlation: 0.82518 with p-value: 0.00E+00 , Concordance Index: 0.81938\n",
      "Training at Epoch 49 iteration 0 with loss 0.11697. Total time 3.39138 hours\n",
      "Training at Epoch 49 iteration 100 with loss 0.11301. Total time 3.39833 hours\n",
      "Training at Epoch 49 iteration 200 with loss 0.10633. Total time 3.40555 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 49 iteration 300 with loss 0.18977. Total time 3.4125 hours\n",
      "Training at Epoch 49 iteration 400 with loss 0.11669. Total time 3.41944 hours\n",
      "Training at Epoch 49 iteration 500 with loss 0.13458. Total time 3.42694 hours\n",
      "Training at Epoch 49 iteration 600 with loss 0.10021. Total time 3.43416 hours\n",
      "Training at Epoch 49 iteration 700 with loss 0.16242. Total time 3.44111 hours\n",
      "Training at Epoch 49 iteration 800 with loss 0.13384. Total time 3.44833 hours\n",
      "Validation at Epoch 49 with loss:0.75990, MSE: 0.68842 , Pearson Correlation: 0.82417 with p-value: 0.00E+00 , Concordance Index: 0.81918\n",
      "Training at Epoch 50 iteration 0 with loss 0.13485. Total time 3.46222 hours\n",
      "Training at Epoch 50 iteration 100 with loss 0.11695. Total time 3.46944 hours\n",
      "Training at Epoch 50 iteration 200 with loss 0.10738. Total time 3.47638 hours\n",
      "Training at Epoch 50 iteration 300 with loss 0.10105. Total time 3.48333 hours\n",
      "Training at Epoch 50 iteration 400 with loss 0.13002. Total time 3.49055 hours\n",
      "Training at Epoch 50 iteration 500 with loss 0.14424. Total time 3.4975 hours\n",
      "Training at Epoch 50 iteration 600 with loss 0.14464. Total time 3.50444 hours\n",
      "Training at Epoch 50 iteration 700 with loss 0.13449. Total time 3.51138 hours\n",
      "Training at Epoch 50 iteration 800 with loss 0.14969. Total time 3.51833 hours\n",
      "Validation at Epoch 50 with loss:0.77965, MSE: 0.69307 , Pearson Correlation: 0.82403 with p-value: 0.00E+00 , Concordance Index: 0.81891\n",
      "Training at Epoch 51 iteration 0 with loss 0.12757. Total time 3.5325 hours\n",
      "Training at Epoch 51 iteration 100 with loss 0.12103. Total time 3.53944 hours\n",
      "Training at Epoch 51 iteration 200 with loss 0.11987. Total time 3.54666 hours\n",
      "Training at Epoch 51 iteration 300 with loss 0.12463. Total time 3.55361 hours\n",
      "Training at Epoch 51 iteration 400 with loss 0.14875. Total time 3.56083 hours\n",
      "Training at Epoch 51 iteration 500 with loss 0.11283. Total time 3.56777 hours\n",
      "Training at Epoch 51 iteration 600 with loss 0.13053. Total time 3.575 hours\n",
      "Training at Epoch 51 iteration 700 with loss 0.14096. Total time 3.58194 hours\n",
      "Training at Epoch 51 iteration 800 with loss 0.15483. Total time 3.58888 hours\n",
      "Validation at Epoch 51 with loss:0.69108, MSE: 0.69435 , Pearson Correlation: 0.82409 with p-value: 0.00E+00 , Concordance Index: 0.81994\n",
      "Training at Epoch 52 iteration 0 with loss 0.09905. Total time 3.60305 hours\n",
      "Training at Epoch 52 iteration 100 with loss 0.17422. Total time 3.61027 hours\n",
      "Training at Epoch 52 iteration 200 with loss 0.13144. Total time 3.61722 hours\n",
      "Training at Epoch 52 iteration 300 with loss 0.09672. Total time 3.62416 hours\n",
      "Training at Epoch 52 iteration 400 with loss 0.09831. Total time 3.63111 hours\n",
      "Training at Epoch 52 iteration 500 with loss 0.19314. Total time 3.63833 hours\n",
      "Training at Epoch 52 iteration 600 with loss 0.11753. Total time 3.64527 hours\n",
      "Training at Epoch 52 iteration 700 with loss 0.14705. Total time 3.65277 hours\n",
      "Training at Epoch 52 iteration 800 with loss 0.12390. Total time 3.66 hours\n",
      "Validation at Epoch 52 with loss:0.63235, MSE: 0.69097 , Pearson Correlation: 0.82415 with p-value: 0.00E+00 , Concordance Index: 0.81944\n",
      "Training at Epoch 53 iteration 0 with loss 0.13720. Total time 3.67416 hours\n",
      "Training at Epoch 53 iteration 100 with loss 0.11545. Total time 3.68111 hours\n",
      "Training at Epoch 53 iteration 200 with loss 0.12188. Total time 3.68833 hours\n",
      "Training at Epoch 53 iteration 300 with loss 0.11338. Total time 3.69555 hours\n",
      "Training at Epoch 53 iteration 400 with loss 0.13258. Total time 3.7025 hours\n",
      "Training at Epoch 53 iteration 500 with loss 0.11874. Total time 3.70944 hours\n",
      "Training at Epoch 53 iteration 600 with loss 0.12496. Total time 3.71638 hours\n",
      "Training at Epoch 53 iteration 700 with loss 0.17235. Total time 3.72333 hours\n",
      "Training at Epoch 53 iteration 800 with loss 0.17163. Total time 3.73055 hours\n",
      "Validation at Epoch 53 with loss:0.76687, MSE: 0.69681 , Pearson Correlation: 0.82477 with p-value: 0.00E+00 , Concordance Index: 0.81957\n",
      "Training at Epoch 54 iteration 0 with loss 0.12890. Total time 3.74472 hours\n",
      "Training at Epoch 54 iteration 100 with loss 0.14293. Total time 3.75166 hours\n",
      "Training at Epoch 54 iteration 200 with loss 0.12933. Total time 3.75861 hours\n",
      "Training at Epoch 54 iteration 300 with loss 0.12585. Total time 3.76583 hours\n",
      "Training at Epoch 54 iteration 400 with loss 0.11504. Total time 3.77277 hours\n",
      "Training at Epoch 54 iteration 500 with loss 0.09337. Total time 3.77972 hours\n",
      "Training at Epoch 54 iteration 600 with loss 0.13488. Total time 3.78694 hours\n",
      "Training at Epoch 54 iteration 700 with loss 0.12297. Total time 3.79388 hours\n",
      "Training at Epoch 54 iteration 800 with loss 0.15894. Total time 3.80083 hours\n",
      "Validation at Epoch 54 with loss:0.70072, MSE: 0.69943 , Pearson Correlation: 0.82425 with p-value: 0.00E+00 , Concordance Index: 0.81956\n",
      "Training at Epoch 55 iteration 0 with loss 0.09187. Total time 3.815 hours\n",
      "Training at Epoch 55 iteration 100 with loss 0.11946. Total time 3.82222 hours\n",
      "Training at Epoch 55 iteration 200 with loss 0.13205. Total time 3.82916 hours\n",
      "Training at Epoch 55 iteration 300 with loss 0.14404. Total time 3.83611 hours\n",
      "Training at Epoch 55 iteration 400 with loss 0.11849. Total time 3.84305 hours\n",
      "Training at Epoch 55 iteration 500 with loss 0.09340. Total time 3.85027 hours\n",
      "Training at Epoch 55 iteration 600 with loss 0.11448. Total time 3.85722 hours\n",
      "Training at Epoch 55 iteration 700 with loss 0.10349. Total time 3.86416 hours\n",
      "Training at Epoch 55 iteration 800 with loss 0.11729. Total time 3.87111 hours\n",
      "Validation at Epoch 55 with loss:0.70917, MSE: 0.68034 , Pearson Correlation: 0.82713 with p-value: 0.00E+00 , Concordance Index: 0.82071\n",
      "Training at Epoch 56 iteration 0 with loss 0.12363. Total time 3.88527 hours\n",
      "Training at Epoch 56 iteration 100 with loss 0.11423. Total time 3.89222 hours\n",
      "Training at Epoch 56 iteration 200 with loss 0.10901. Total time 3.89944 hours\n",
      "Training at Epoch 56 iteration 300 with loss 0.13128. Total time 3.90638 hours\n",
      "Training at Epoch 56 iteration 400 with loss 0.11807. Total time 3.91333 hours\n",
      "Training at Epoch 56 iteration 500 with loss 0.12707. Total time 3.92027 hours\n",
      "Training at Epoch 56 iteration 600 with loss 0.09923. Total time 3.92722 hours\n",
      "Training at Epoch 56 iteration 700 with loss 0.11825. Total time 3.93444 hours\n",
      "Training at Epoch 56 iteration 800 with loss 0.12454. Total time 3.94138 hours\n",
      "Validation at Epoch 56 with loss:0.67694, MSE: 0.70322 , Pearson Correlation: 0.82583 with p-value: 0.00E+00 , Concordance Index: 0.81996\n",
      "Training at Epoch 57 iteration 0 with loss 0.07399. Total time 3.95555 hours\n",
      "Training at Epoch 57 iteration 100 with loss 0.14742. Total time 3.9625 hours\n",
      "Training at Epoch 57 iteration 200 with loss 0.09833. Total time 3.96944 hours\n",
      "Training at Epoch 57 iteration 300 with loss 0.13767. Total time 3.97638 hours\n",
      "Training at Epoch 57 iteration 400 with loss 0.11226. Total time 3.98361 hours\n",
      "Training at Epoch 57 iteration 500 with loss 0.09080. Total time 3.99055 hours\n",
      "Training at Epoch 57 iteration 600 with loss 0.14097. Total time 3.9975 hours\n",
      "Training at Epoch 57 iteration 700 with loss 0.14472. Total time 4.00472 hours\n",
      "Training at Epoch 57 iteration 800 with loss 0.10092. Total time 4.01166 hours\n",
      "Validation at Epoch 57 with loss:0.57970, MSE: 0.68805 , Pearson Correlation: 0.82598 with p-value: 0.00E+00 , Concordance Index: 0.81991\n",
      "Training at Epoch 58 iteration 0 with loss 0.12338. Total time 4.02583 hours\n",
      "Training at Epoch 58 iteration 100 with loss 0.11547. Total time 4.03277 hours\n",
      "Training at Epoch 58 iteration 200 with loss 0.09810. Total time 4.04 hours\n",
      "Training at Epoch 58 iteration 300 with loss 0.15144. Total time 4.04694 hours\n",
      "Training at Epoch 58 iteration 400 with loss 0.14894. Total time 4.05388 hours\n",
      "Training at Epoch 58 iteration 500 with loss 0.15063. Total time 4.06111 hours\n",
      "Training at Epoch 58 iteration 600 with loss 0.11251. Total time 4.06805 hours\n",
      "Training at Epoch 58 iteration 700 with loss 0.09269. Total time 4.075 hours\n",
      "Training at Epoch 58 iteration 800 with loss 0.14513. Total time 4.08222 hours\n",
      "Validation at Epoch 58 with loss:0.60269, MSE: 0.68708 , Pearson Correlation: 0.82689 with p-value: 0.00E+00 , Concordance Index: 0.82061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 59 iteration 0 with loss 0.12623. Total time 4.09638 hours\n",
      "Training at Epoch 59 iteration 100 with loss 0.10061. Total time 4.10333 hours\n",
      "Training at Epoch 59 iteration 200 with loss 0.10355. Total time 4.11055 hours\n",
      "Training at Epoch 59 iteration 300 with loss 0.11538. Total time 4.1175 hours\n",
      "Training at Epoch 59 iteration 400 with loss 0.10590. Total time 4.12444 hours\n",
      "Training at Epoch 59 iteration 500 with loss 0.10627. Total time 4.13166 hours\n",
      "Training at Epoch 59 iteration 600 with loss 0.11723. Total time 4.13861 hours\n",
      "Training at Epoch 59 iteration 700 with loss 0.10915. Total time 4.14555 hours\n",
      "Training at Epoch 59 iteration 800 with loss 0.13988. Total time 4.15277 hours\n",
      "Validation at Epoch 59 with loss:0.60100, MSE: 0.68187 , Pearson Correlation: 0.82645 with p-value: 0.00E+00 , Concordance Index: 0.82052\n",
      "Training at Epoch 60 iteration 0 with loss 0.12984. Total time 4.16694 hours\n",
      "Training at Epoch 60 iteration 100 with loss 0.08092. Total time 4.17388 hours\n",
      "Training at Epoch 60 iteration 200 with loss 0.07459. Total time 4.18111 hours\n",
      "Training at Epoch 60 iteration 300 with loss 0.12352. Total time 4.18805 hours\n",
      "Training at Epoch 60 iteration 400 with loss 0.12546. Total time 4.195 hours\n",
      "Training at Epoch 60 iteration 500 with loss 0.12725. Total time 4.20222 hours\n",
      "Training at Epoch 60 iteration 600 with loss 0.12952. Total time 4.20916 hours\n",
      "Training at Epoch 60 iteration 700 with loss 0.11960. Total time 4.21638 hours\n",
      "Training at Epoch 60 iteration 800 with loss 0.11929. Total time 4.22333 hours\n",
      "Validation at Epoch 60 with loss:0.59469, MSE: 0.70788 , Pearson Correlation: 0.82420 with p-value: 0.00E+00 , Concordance Index: 0.81956\n",
      "Training at Epoch 61 iteration 0 with loss 0.10364. Total time 4.2375 hours\n",
      "Training at Epoch 61 iteration 100 with loss 0.08595. Total time 4.24472 hours\n",
      "Training at Epoch 61 iteration 200 with loss 0.09769. Total time 4.25166 hours\n",
      "Training at Epoch 61 iteration 300 with loss 0.10702. Total time 4.25861 hours\n",
      "Training at Epoch 61 iteration 400 with loss 0.11947. Total time 4.26555 hours\n",
      "Training at Epoch 61 iteration 500 with loss 0.14381. Total time 4.2725 hours\n",
      "Training at Epoch 61 iteration 600 with loss 0.15082. Total time 4.27944 hours\n",
      "Training at Epoch 61 iteration 700 with loss 0.14178. Total time 4.28638 hours\n",
      "Training at Epoch 61 iteration 800 with loss 0.10794. Total time 4.29361 hours\n",
      "Validation at Epoch 61 with loss:0.66124, MSE: 0.70328 , Pearson Correlation: 0.82555 with p-value: 0.00E+00 , Concordance Index: 0.81973\n",
      "Training at Epoch 62 iteration 0 with loss 0.10014. Total time 4.30777 hours\n",
      "Training at Epoch 62 iteration 100 with loss 0.09089. Total time 4.31472 hours\n",
      "Training at Epoch 62 iteration 200 with loss 0.11003. Total time 4.32166 hours\n",
      "Training at Epoch 62 iteration 300 with loss 0.12012. Total time 4.32888 hours\n",
      "Training at Epoch 62 iteration 400 with loss 0.10415. Total time 4.33583 hours\n",
      "Training at Epoch 62 iteration 500 with loss 0.10958. Total time 4.34305 hours\n",
      "Training at Epoch 62 iteration 600 with loss 0.12214. Total time 4.35 hours\n",
      "Training at Epoch 62 iteration 700 with loss 0.09941. Total time 4.35694 hours\n",
      "Training at Epoch 62 iteration 800 with loss 0.12938. Total time 4.36416 hours\n",
      "Validation at Epoch 62 with loss:0.82133, MSE: 0.71059 , Pearson Correlation: 0.82382 with p-value: 0.00E+00 , Concordance Index: 0.81932\n",
      "Training at Epoch 63 iteration 0 with loss 0.09110. Total time 4.37833 hours\n",
      "Training at Epoch 63 iteration 100 with loss 0.11215. Total time 4.38527 hours\n",
      "Training at Epoch 63 iteration 200 with loss 0.10364. Total time 4.39222 hours\n",
      "Training at Epoch 63 iteration 300 with loss 0.13616. Total time 4.39916 hours\n",
      "Training at Epoch 63 iteration 400 with loss 0.12211. Total time 4.40638 hours\n",
      "Training at Epoch 63 iteration 500 with loss 0.13859. Total time 4.41333 hours\n",
      "Training at Epoch 63 iteration 600 with loss 0.13988. Total time 4.42027 hours\n",
      "Training at Epoch 63 iteration 700 with loss 0.10968. Total time 4.42722 hours\n",
      "Training at Epoch 63 iteration 800 with loss 0.09751. Total time 4.43444 hours\n",
      "Validation at Epoch 63 with loss:0.62051, MSE: 0.69877 , Pearson Correlation: 0.82440 with p-value: 0.00E+00 , Concordance Index: 0.81976\n",
      "Training at Epoch 64 iteration 0 with loss 0.11073. Total time 4.44861 hours\n",
      "Training at Epoch 64 iteration 100 with loss 0.09976. Total time 4.45555 hours\n",
      "Training at Epoch 64 iteration 200 with loss 0.11141. Total time 4.46277 hours\n",
      "Training at Epoch 64 iteration 300 with loss 0.11602. Total time 4.47027 hours\n",
      "Training at Epoch 64 iteration 400 with loss 0.09607. Total time 4.4775 hours\n",
      "Training at Epoch 64 iteration 500 with loss 0.13572. Total time 4.48444 hours\n",
      "Training at Epoch 64 iteration 600 with loss 0.12265. Total time 4.49138 hours\n",
      "Training at Epoch 64 iteration 700 with loss 0.08940. Total time 4.49833 hours\n",
      "Training at Epoch 64 iteration 800 with loss 0.10256. Total time 4.50527 hours\n",
      "Validation at Epoch 64 with loss:0.68990, MSE: 0.68745 , Pearson Correlation: 0.82545 with p-value: 0.00E+00 , Concordance Index: 0.82045\n",
      "Training at Epoch 65 iteration 0 with loss 0.09687. Total time 4.51944 hours\n",
      "Training at Epoch 65 iteration 100 with loss 0.09229. Total time 4.52638 hours\n",
      "Training at Epoch 65 iteration 200 with loss 0.10128. Total time 4.53388 hours\n",
      "Training at Epoch 65 iteration 300 with loss 0.10179. Total time 4.54083 hours\n",
      "Training at Epoch 65 iteration 400 with loss 0.12116. Total time 4.54777 hours\n",
      "Training at Epoch 65 iteration 500 with loss 0.09592. Total time 4.55472 hours\n",
      "Training at Epoch 65 iteration 600 with loss 0.09366. Total time 4.56194 hours\n",
      "Training at Epoch 65 iteration 700 with loss 0.11229. Total time 4.56888 hours\n",
      "Training at Epoch 65 iteration 800 with loss 0.12794. Total time 4.57611 hours\n",
      "Validation at Epoch 65 with loss:0.67801, MSE: 0.69941 , Pearson Correlation: 0.82374 with p-value: 0.00E+00 , Concordance Index: 0.81963\n",
      "Training at Epoch 66 iteration 0 with loss 0.11456. Total time 4.59 hours\n",
      "Training at Epoch 66 iteration 100 with loss 0.09907. Total time 4.59722 hours\n",
      "Training at Epoch 66 iteration 200 with loss 0.10555. Total time 4.60416 hours\n",
      "Training at Epoch 66 iteration 300 with loss 0.07356. Total time 4.61111 hours\n",
      "Training at Epoch 66 iteration 400 with loss 0.21144. Total time 4.61805 hours\n",
      "Training at Epoch 66 iteration 500 with loss 0.09874. Total time 4.625 hours\n",
      "Training at Epoch 66 iteration 600 with loss 0.08496. Total time 4.63194 hours\n",
      "Training at Epoch 66 iteration 700 with loss 0.10037. Total time 4.63888 hours\n",
      "Training at Epoch 66 iteration 800 with loss 0.14068. Total time 4.64583 hours\n",
      "Validation at Epoch 66 with loss:0.85842, MSE: 0.70101 , Pearson Correlation: 0.82373 with p-value: 0.00E+00 , Concordance Index: 0.81970\n",
      "Training at Epoch 67 iteration 0 with loss 0.09102. Total time 4.66 hours\n",
      "Training at Epoch 67 iteration 100 with loss 0.10477. Total time 4.66694 hours\n",
      "Training at Epoch 67 iteration 200 with loss 0.13300. Total time 4.67388 hours\n",
      "Training at Epoch 67 iteration 300 with loss 0.13820. Total time 4.68083 hours\n",
      "Training at Epoch 67 iteration 400 with loss 0.10086. Total time 4.68805 hours\n",
      "Training at Epoch 67 iteration 500 with loss 0.08393. Total time 4.695 hours\n",
      "Training at Epoch 67 iteration 600 with loss 0.11218. Total time 4.70194 hours\n",
      "Training at Epoch 67 iteration 700 with loss 0.10232. Total time 4.70916 hours\n",
      "Training at Epoch 67 iteration 800 with loss 0.10554. Total time 4.71611 hours\n",
      "Validation at Epoch 67 with loss:0.68737, MSE: 0.70412 , Pearson Correlation: 0.82388 with p-value: 0.00E+00 , Concordance Index: 0.81945\n",
      "Training at Epoch 68 iteration 0 with loss 0.08605. Total time 4.73055 hours\n",
      "Training at Epoch 68 iteration 100 with loss 0.10356. Total time 4.7375 hours\n",
      "Training at Epoch 68 iteration 200 with loss 0.08332. Total time 4.74472 hours\n",
      "Training at Epoch 68 iteration 300 with loss 0.11066. Total time 4.75166 hours\n",
      "Training at Epoch 68 iteration 400 with loss 0.10679. Total time 4.75888 hours\n",
      "Training at Epoch 68 iteration 500 with loss 0.08197. Total time 4.76583 hours\n",
      "Training at Epoch 68 iteration 600 with loss 0.11797. Total time 4.77305 hours\n",
      "Training at Epoch 68 iteration 700 with loss 0.10329. Total time 4.78 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 68 iteration 800 with loss 0.12004. Total time 4.78722 hours\n",
      "Validation at Epoch 68 with loss:0.64717, MSE: 0.69702 , Pearson Correlation: 0.82391 with p-value: 0.00E+00 , Concordance Index: 0.81942\n",
      "Training at Epoch 69 iteration 0 with loss 0.07987. Total time 4.80138 hours\n",
      "Training at Epoch 69 iteration 100 with loss 0.08353. Total time 4.80833 hours\n",
      "Training at Epoch 69 iteration 200 with loss 0.11346. Total time 4.81527 hours\n",
      "Training at Epoch 69 iteration 300 with loss 0.09636. Total time 4.8225 hours\n",
      "Training at Epoch 69 iteration 400 with loss 0.11476. Total time 4.82944 hours\n",
      "Training at Epoch 69 iteration 500 with loss 0.10117. Total time 4.83666 hours\n",
      "Training at Epoch 69 iteration 600 with loss 0.09615. Total time 4.84361 hours\n",
      "Training at Epoch 69 iteration 700 with loss 0.13452. Total time 4.85055 hours\n",
      "Training at Epoch 69 iteration 800 with loss 0.11134. Total time 4.8575 hours\n",
      "Validation at Epoch 69 with loss:0.70964, MSE: 0.68744 , Pearson Correlation: 0.82463 with p-value: 0.00E+00 , Concordance Index: 0.81934\n",
      "Training at Epoch 70 iteration 0 with loss 0.10039. Total time 4.87194 hours\n",
      "Training at Epoch 70 iteration 100 with loss 0.12678. Total time 4.87888 hours\n",
      "Training at Epoch 70 iteration 200 with loss 0.07709. Total time 4.88611 hours\n",
      "Training at Epoch 70 iteration 300 with loss 0.10699. Total time 4.89305 hours\n",
      "Training at Epoch 70 iteration 400 with loss 0.10012. Total time 4.90027 hours\n",
      "Training at Epoch 70 iteration 500 with loss 0.10609. Total time 4.90722 hours\n",
      "Training at Epoch 70 iteration 600 with loss 0.12964. Total time 4.91444 hours\n",
      "Training at Epoch 70 iteration 700 with loss 0.16724. Total time 4.92138 hours\n",
      "Training at Epoch 70 iteration 800 with loss 0.08817. Total time 4.92833 hours\n",
      "Validation at Epoch 70 with loss:0.59582, MSE: 0.69876 , Pearson Correlation: 0.82471 with p-value: 0.00E+00 , Concordance Index: 0.81958\n",
      "Training at Epoch 71 iteration 0 with loss 0.13462. Total time 4.9425 hours\n",
      "Training at Epoch 71 iteration 100 with loss 0.07748. Total time 4.94972 hours\n",
      "Training at Epoch 71 iteration 200 with loss 0.11574. Total time 4.95694 hours\n",
      "Training at Epoch 71 iteration 300 with loss 0.08132. Total time 4.96388 hours\n",
      "Training at Epoch 71 iteration 400 with loss 0.10576. Total time 4.97111 hours\n",
      "Training at Epoch 71 iteration 500 with loss 0.08514. Total time 4.97833 hours\n",
      "Training at Epoch 71 iteration 600 with loss 0.08999. Total time 4.98527 hours\n",
      "Training at Epoch 71 iteration 700 with loss 0.12411. Total time 4.9925 hours\n",
      "Training at Epoch 71 iteration 800 with loss 0.09762. Total time 4.99972 hours\n",
      "Validation at Epoch 71 with loss:0.53348, MSE: 0.69504 , Pearson Correlation: 0.82400 with p-value: 0.00E+00 , Concordance Index: 0.81929\n",
      "Training at Epoch 72 iteration 0 with loss 0.09805. Total time 5.01361 hours\n",
      "Training at Epoch 72 iteration 100 with loss 0.10722. Total time 5.02055 hours\n",
      "Training at Epoch 72 iteration 200 with loss 0.11972. Total time 5.02777 hours\n",
      "Training at Epoch 72 iteration 300 with loss 0.08723. Total time 5.03472 hours\n",
      "Training at Epoch 72 iteration 400 with loss 0.07378. Total time 5.04166 hours\n",
      "Training at Epoch 72 iteration 500 with loss 0.10575. Total time 5.04888 hours\n",
      "Training at Epoch 72 iteration 600 with loss 0.08927. Total time 5.05583 hours\n",
      "Training at Epoch 72 iteration 700 with loss 0.14872. Total time 5.06277 hours\n",
      "Training at Epoch 72 iteration 800 with loss 0.11893. Total time 5.06972 hours\n",
      "Validation at Epoch 72 with loss:0.71266, MSE: 0.69154 , Pearson Correlation: 0.82370 with p-value: 0.00E+00 , Concordance Index: 0.81957\n",
      "Training at Epoch 73 iteration 0 with loss 0.06432. Total time 5.08388 hours\n",
      "Training at Epoch 73 iteration 100 with loss 0.07653. Total time 5.09083 hours\n",
      "Training at Epoch 73 iteration 200 with loss 0.13146. Total time 5.09805 hours\n",
      "Training at Epoch 73 iteration 300 with loss 0.12407. Total time 5.105 hours\n",
      "Training at Epoch 73 iteration 400 with loss 0.10661. Total time 5.11222 hours\n",
      "Training at Epoch 73 iteration 500 with loss 0.10585. Total time 5.11916 hours\n",
      "Training at Epoch 73 iteration 600 with loss 0.09267. Total time 5.12638 hours\n",
      "Training at Epoch 73 iteration 700 with loss 0.13396. Total time 5.13333 hours\n",
      "Training at Epoch 73 iteration 800 with loss 0.10575. Total time 5.14027 hours\n",
      "Validation at Epoch 73 with loss:0.73034, MSE: 0.69748 , Pearson Correlation: 0.82359 with p-value: 0.00E+00 , Concordance Index: 0.81934\n",
      "Training at Epoch 74 iteration 0 with loss 0.09159. Total time 5.15444 hours\n",
      "Training at Epoch 74 iteration 100 with loss 0.07211. Total time 5.16138 hours\n",
      "Training at Epoch 74 iteration 200 with loss 0.09324. Total time 5.16833 hours\n",
      "Training at Epoch 74 iteration 300 with loss 0.10610. Total time 5.17555 hours\n",
      "Training at Epoch 74 iteration 400 with loss 0.07639. Total time 5.1825 hours\n",
      "Training at Epoch 74 iteration 500 with loss 0.11016. Total time 5.18944 hours\n",
      "Training at Epoch 74 iteration 600 with loss 0.10991. Total time 5.19666 hours\n",
      "Training at Epoch 74 iteration 700 with loss 0.09034. Total time 5.20361 hours\n",
      "Training at Epoch 74 iteration 800 with loss 0.11378. Total time 5.21055 hours\n",
      "Validation at Epoch 74 with loss:0.68318, MSE: 0.70485 , Pearson Correlation: 0.82330 with p-value: 0.00E+00 , Concordance Index: 0.81928\n",
      "Training at Epoch 75 iteration 0 with loss 0.09234. Total time 5.22472 hours\n",
      "Training at Epoch 75 iteration 100 with loss 0.10337. Total time 5.23166 hours\n",
      "Training at Epoch 75 iteration 200 with loss 0.08362. Total time 5.23888 hours\n",
      "Training at Epoch 75 iteration 300 with loss 0.09656. Total time 5.24583 hours\n",
      "Training at Epoch 75 iteration 400 with loss 0.08079. Total time 5.25277 hours\n",
      "Training at Epoch 75 iteration 500 with loss 0.11589. Total time 5.25972 hours\n",
      "Training at Epoch 75 iteration 600 with loss 0.12693. Total time 5.26666 hours\n",
      "Training at Epoch 75 iteration 700 with loss 0.10123. Total time 5.27361 hours\n",
      "Training at Epoch 75 iteration 800 with loss 0.16473. Total time 5.28055 hours\n",
      "Validation at Epoch 75 with loss:0.75855, MSE: 0.69084 , Pearson Correlation: 0.82404 with p-value: 0.00E+00 , Concordance Index: 0.81995\n",
      "Training at Epoch 76 iteration 0 with loss 0.11021. Total time 5.29472 hours\n",
      "Training at Epoch 76 iteration 100 with loss 0.10189. Total time 5.30166 hours\n",
      "Training at Epoch 76 iteration 200 with loss 0.08612. Total time 5.30888 hours\n",
      "Training at Epoch 76 iteration 300 with loss 0.09430. Total time 5.31583 hours\n",
      "Training at Epoch 76 iteration 400 with loss 0.07449. Total time 5.32277 hours\n",
      "Training at Epoch 76 iteration 500 with loss 0.07807. Total time 5.32972 hours\n",
      "Training at Epoch 76 iteration 600 with loss 0.10412. Total time 5.33666 hours\n",
      "Training at Epoch 76 iteration 700 with loss 0.10792. Total time 5.34388 hours\n",
      "Training at Epoch 76 iteration 800 with loss 0.11894. Total time 5.35083 hours\n",
      "Validation at Epoch 76 with loss:0.82867, MSE: 0.69983 , Pearson Correlation: 0.82492 with p-value: 0.00E+00 , Concordance Index: 0.82014\n",
      "Training at Epoch 77 iteration 0 with loss 0.10373. Total time 5.36472 hours\n",
      "Training at Epoch 77 iteration 100 with loss 0.07942. Total time 5.37166 hours\n",
      "Training at Epoch 77 iteration 200 with loss 0.09247. Total time 5.37861 hours\n",
      "Training at Epoch 77 iteration 300 with loss 0.09607. Total time 5.38555 hours\n",
      "Training at Epoch 77 iteration 400 with loss 0.10843. Total time 5.3925 hours\n",
      "Training at Epoch 77 iteration 500 with loss 0.08082. Total time 5.39944 hours\n",
      "Training at Epoch 77 iteration 600 with loss 0.09164. Total time 5.40638 hours\n",
      "Training at Epoch 77 iteration 700 with loss 0.09104. Total time 5.41333 hours\n",
      "Training at Epoch 77 iteration 800 with loss 0.08342. Total time 5.42027 hours\n",
      "Validation at Epoch 77 with loss:0.74815, MSE: 0.68878 , Pearson Correlation: 0.82467 with p-value: 0.00E+00 , Concordance Index: 0.81991\n",
      "Training at Epoch 78 iteration 0 with loss 0.11198. Total time 5.43416 hours\n",
      "Training at Epoch 78 iteration 100 with loss 0.09064. Total time 5.44111 hours\n",
      "Training at Epoch 78 iteration 200 with loss 0.09746. Total time 5.44805 hours\n",
      "Training at Epoch 78 iteration 300 with loss 0.08897. Total time 5.45527 hours\n",
      "Training at Epoch 78 iteration 400 with loss 0.09773. Total time 5.46222 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 78 iteration 500 with loss 0.10930. Total time 5.46916 hours\n",
      "Training at Epoch 78 iteration 600 with loss 0.08915. Total time 5.47638 hours\n",
      "Training at Epoch 78 iteration 700 with loss 0.09484. Total time 5.48333 hours\n",
      "Training at Epoch 78 iteration 800 with loss 0.09277. Total time 5.49027 hours\n",
      "Validation at Epoch 78 with loss:0.73980, MSE: 0.69099 , Pearson Correlation: 0.82418 with p-value: 0.00E+00 , Concordance Index: 0.81970\n",
      "Training at Epoch 79 iteration 0 with loss 0.08354. Total time 5.50444 hours\n",
      "Training at Epoch 79 iteration 100 with loss 0.09461. Total time 5.51138 hours\n",
      "Training at Epoch 79 iteration 200 with loss 0.07619. Total time 5.51833 hours\n",
      "Training at Epoch 79 iteration 300 with loss 0.09610. Total time 5.52527 hours\n",
      "Training at Epoch 79 iteration 400 with loss 0.08981. Total time 5.5325 hours\n",
      "Training at Epoch 79 iteration 500 with loss 0.06399. Total time 5.53944 hours\n",
      "Training at Epoch 79 iteration 600 with loss 0.07113. Total time 5.54638 hours\n",
      "Training at Epoch 79 iteration 700 with loss 0.09743. Total time 5.55333 hours\n",
      "Training at Epoch 79 iteration 800 with loss 0.09974. Total time 5.56027 hours\n",
      "Validation at Epoch 79 with loss:0.66015, MSE: 0.70469 , Pearson Correlation: 0.82371 with p-value: 0.00E+00 , Concordance Index: 0.81973\n",
      "Training at Epoch 80 iteration 0 with loss 0.07797. Total time 5.57444 hours\n",
      "Training at Epoch 80 iteration 100 with loss 0.09171. Total time 5.58166 hours\n",
      "Training at Epoch 80 iteration 200 with loss 0.08179. Total time 5.58861 hours\n",
      "Training at Epoch 80 iteration 300 with loss 0.10599. Total time 5.59555 hours\n",
      "Training at Epoch 80 iteration 400 with loss 0.07879. Total time 5.60277 hours\n",
      "Training at Epoch 80 iteration 500 with loss 0.16474. Total time 5.60972 hours\n",
      "Training at Epoch 80 iteration 600 with loss 0.13765. Total time 5.61666 hours\n",
      "Training at Epoch 80 iteration 700 with loss 0.11753. Total time 5.62388 hours\n",
      "Training at Epoch 80 iteration 800 with loss 0.12613. Total time 5.63083 hours\n",
      "Validation at Epoch 80 with loss:0.59691, MSE: 0.69626 , Pearson Correlation: 0.82486 with p-value: 0.00E+00 , Concordance Index: 0.82004\n",
      "Training at Epoch 81 iteration 0 with loss 0.07941. Total time 5.64472 hours\n",
      "Training at Epoch 81 iteration 100 with loss 0.11524. Total time 5.65166 hours\n",
      "Training at Epoch 81 iteration 200 with loss 0.10357. Total time 5.65888 hours\n",
      "Training at Epoch 81 iteration 300 with loss 0.06325. Total time 5.66583 hours\n",
      "Training at Epoch 81 iteration 400 with loss 0.08731. Total time 5.67277 hours\n",
      "Training at Epoch 81 iteration 500 with loss 0.08290. Total time 5.67972 hours\n",
      "Training at Epoch 81 iteration 600 with loss 0.10741. Total time 5.68666 hours\n",
      "Training at Epoch 81 iteration 700 with loss 0.06523. Total time 5.69361 hours\n",
      "Training at Epoch 81 iteration 800 with loss 0.09194. Total time 5.70055 hours\n",
      "Validation at Epoch 81 with loss:0.54265, MSE: 0.68818 , Pearson Correlation: 0.82524 with p-value: 0.00E+00 , Concordance Index: 0.81998\n",
      "Training at Epoch 82 iteration 0 with loss 0.10082. Total time 5.71472 hours\n",
      "Training at Epoch 82 iteration 100 with loss 0.08603. Total time 5.72166 hours\n",
      "Training at Epoch 82 iteration 200 with loss 0.10159. Total time 5.72861 hours\n",
      "Training at Epoch 82 iteration 300 with loss 0.07390. Total time 5.73555 hours\n",
      "Training at Epoch 82 iteration 400 with loss 0.08351. Total time 5.7425 hours\n",
      "Training at Epoch 82 iteration 500 with loss 0.10011. Total time 5.74944 hours\n",
      "Training at Epoch 82 iteration 600 with loss 0.08596. Total time 5.75666 hours\n",
      "Training at Epoch 82 iteration 700 with loss 0.08840. Total time 5.76361 hours\n",
      "Training at Epoch 82 iteration 800 with loss 0.08988. Total time 5.77055 hours\n",
      "Validation at Epoch 82 with loss:0.72088, MSE: 0.70242 , Pearson Correlation: 0.82349 with p-value: 0.00E+00 , Concordance Index: 0.81916\n",
      "Training at Epoch 83 iteration 0 with loss 0.09056. Total time 5.78444 hours\n",
      "Training at Epoch 83 iteration 100 with loss 0.07370. Total time 5.79166 hours\n",
      "Training at Epoch 83 iteration 200 with loss 0.08245. Total time 5.79861 hours\n",
      "Training at Epoch 83 iteration 300 with loss 0.06226. Total time 5.80555 hours\n",
      "Training at Epoch 83 iteration 400 with loss 0.07931. Total time 5.8125 hours\n",
      "Training at Epoch 83 iteration 500 with loss 0.11165. Total time 5.81972 hours\n",
      "Training at Epoch 83 iteration 600 with loss 0.09079. Total time 5.82666 hours\n",
      "Training at Epoch 83 iteration 700 with loss 0.09050. Total time 5.83361 hours\n",
      "Training at Epoch 83 iteration 800 with loss 0.07315. Total time 5.84083 hours\n",
      "Validation at Epoch 83 with loss:0.76326, MSE: 0.69059 , Pearson Correlation: 0.82448 with p-value: 0.00E+00 , Concordance Index: 0.81971\n",
      "Training at Epoch 84 iteration 0 with loss 0.07303. Total time 5.855 hours\n",
      "Training at Epoch 84 iteration 100 with loss 0.09058. Total time 5.86194 hours\n",
      "Training at Epoch 84 iteration 200 with loss 0.06488. Total time 5.86916 hours\n",
      "Training at Epoch 84 iteration 300 with loss 0.06631. Total time 5.87611 hours\n",
      "Training at Epoch 84 iteration 400 with loss 0.08833. Total time 5.88305 hours\n",
      "Training at Epoch 84 iteration 500 with loss 0.09536. Total time 5.89 hours\n",
      "Training at Epoch 84 iteration 600 with loss 0.08056. Total time 5.89694 hours\n",
      "Training at Epoch 84 iteration 700 with loss 0.08528. Total time 5.90388 hours\n",
      "Training at Epoch 84 iteration 800 with loss 0.11755. Total time 5.91111 hours\n",
      "Validation at Epoch 84 with loss:0.79959, MSE: 0.69510 , Pearson Correlation: 0.82523 with p-value: 0.00E+00 , Concordance Index: 0.82003\n",
      "Training at Epoch 85 iteration 0 with loss 0.05198. Total time 5.92527 hours\n",
      "Training at Epoch 85 iteration 100 with loss 0.09247. Total time 5.93222 hours\n",
      "Training at Epoch 85 iteration 200 with loss 0.07744. Total time 5.93916 hours\n",
      "Training at Epoch 85 iteration 300 with loss 0.06572. Total time 5.94611 hours\n",
      "Training at Epoch 85 iteration 400 with loss 0.07621. Total time 5.95333 hours\n",
      "Training at Epoch 85 iteration 500 with loss 0.06322. Total time 5.96027 hours\n",
      "Training at Epoch 85 iteration 600 with loss 0.07282. Total time 5.96722 hours\n",
      "Training at Epoch 85 iteration 700 with loss 0.11197. Total time 5.97416 hours\n",
      "Training at Epoch 85 iteration 800 with loss 0.08309. Total time 5.98111 hours\n",
      "Validation at Epoch 85 with loss:0.66684, MSE: 0.69832 , Pearson Correlation: 0.82429 with p-value: 0.00E+00 , Concordance Index: 0.81980\n",
      "Training at Epoch 86 iteration 0 with loss 0.07552. Total time 5.99527 hours\n",
      "Training at Epoch 86 iteration 100 with loss 0.06974. Total time 6.00222 hours\n",
      "Training at Epoch 86 iteration 200 with loss 0.07517. Total time 6.00916 hours\n",
      "Training at Epoch 86 iteration 300 with loss 0.08160. Total time 6.01638 hours\n",
      "Training at Epoch 86 iteration 400 with loss 0.06201. Total time 6.02333 hours\n",
      "Training at Epoch 86 iteration 500 with loss 0.08577. Total time 6.03027 hours\n",
      "Training at Epoch 86 iteration 600 with loss 0.08775. Total time 6.03722 hours\n",
      "Training at Epoch 86 iteration 700 with loss 0.12053. Total time 6.04472 hours\n",
      "Training at Epoch 86 iteration 800 with loss 0.09132. Total time 6.05194 hours\n",
      "Validation at Epoch 86 with loss:0.96369, MSE: 0.70039 , Pearson Correlation: 0.82239 with p-value: 0.00E+00 , Concordance Index: 0.81901\n",
      "Training at Epoch 87 iteration 0 with loss 0.05793. Total time 6.06611 hours\n",
      "Training at Epoch 87 iteration 100 with loss 0.12753. Total time 6.07305 hours\n",
      "Training at Epoch 87 iteration 200 with loss 0.07558. Total time 6.08 hours\n",
      "Training at Epoch 87 iteration 300 with loss 0.09898. Total time 6.08694 hours\n",
      "Training at Epoch 87 iteration 400 with loss 0.06807. Total time 6.09388 hours\n",
      "Training at Epoch 87 iteration 500 with loss 0.08764. Total time 6.10083 hours\n",
      "Training at Epoch 87 iteration 600 with loss 0.07851. Total time 6.10777 hours\n",
      "Training at Epoch 87 iteration 700 with loss 0.06050. Total time 6.11472 hours\n",
      "Training at Epoch 87 iteration 800 with loss 0.08337. Total time 6.12194 hours\n",
      "Validation at Epoch 87 with loss:0.86221, MSE: 0.69343 , Pearson Correlation: 0.82393 with p-value: 0.00E+00 , Concordance Index: 0.81991\n",
      "Training at Epoch 88 iteration 0 with loss 0.07016. Total time 6.13583 hours\n",
      "Training at Epoch 88 iteration 100 with loss 0.05448. Total time 6.14305 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 88 iteration 200 with loss 0.08009. Total time 6.15 hours\n",
      "Training at Epoch 88 iteration 300 with loss 0.07090. Total time 6.15722 hours\n",
      "Training at Epoch 88 iteration 400 with loss 0.08870. Total time 6.16416 hours\n",
      "Training at Epoch 88 iteration 500 with loss 0.11310. Total time 6.17111 hours\n",
      "Training at Epoch 88 iteration 600 with loss 0.10558. Total time 6.17833 hours\n",
      "Training at Epoch 88 iteration 700 with loss 0.10913. Total time 6.18527 hours\n",
      "Training at Epoch 88 iteration 800 with loss 0.08220. Total time 6.19222 hours\n",
      "Validation at Epoch 88 with loss:0.73736, MSE: 0.69949 , Pearson Correlation: 0.82369 with p-value: 0.00E+00 , Concordance Index: 0.81958\n",
      "Training at Epoch 89 iteration 0 with loss 0.10929. Total time 6.20638 hours\n",
      "Training at Epoch 89 iteration 100 with loss 0.07407. Total time 6.21333 hours\n",
      "Training at Epoch 89 iteration 200 with loss 0.06984. Total time 6.22055 hours\n",
      "Training at Epoch 89 iteration 300 with loss 0.08507. Total time 6.2275 hours\n",
      "Training at Epoch 89 iteration 400 with loss 0.08520. Total time 6.23444 hours\n",
      "Training at Epoch 89 iteration 500 with loss 0.07917. Total time 6.24138 hours\n",
      "Training at Epoch 89 iteration 600 with loss 0.07853. Total time 6.24861 hours\n",
      "Training at Epoch 89 iteration 700 with loss 0.11078. Total time 6.25555 hours\n",
      "Training at Epoch 89 iteration 800 with loss 0.10266. Total time 6.26277 hours\n",
      "Validation at Epoch 89 with loss:0.59975, MSE: 0.69633 , Pearson Correlation: 0.82452 with p-value: 0.00E+00 , Concordance Index: 0.82032\n",
      "Training at Epoch 90 iteration 0 with loss 0.09341. Total time 6.27666 hours\n",
      "Training at Epoch 90 iteration 100 with loss 0.08939. Total time 6.28388 hours\n",
      "Training at Epoch 90 iteration 200 with loss 0.08763. Total time 6.29083 hours\n",
      "Training at Epoch 90 iteration 300 with loss 0.08951. Total time 6.29777 hours\n",
      "Training at Epoch 90 iteration 400 with loss 0.10948. Total time 6.305 hours\n",
      "Training at Epoch 90 iteration 500 with loss 0.10948. Total time 6.31194 hours\n",
      "Training at Epoch 90 iteration 600 with loss 0.09223. Total time 6.31916 hours\n",
      "Training at Epoch 90 iteration 700 with loss 0.07611. Total time 6.32611 hours\n",
      "Training at Epoch 90 iteration 800 with loss 0.09478. Total time 6.33305 hours\n",
      "Validation at Epoch 90 with loss:0.62207, MSE: 0.69216 , Pearson Correlation: 0.82492 with p-value: 0.00E+00 , Concordance Index: 0.82006\n",
      "Training at Epoch 91 iteration 0 with loss 0.05425. Total time 6.34722 hours\n",
      "Training at Epoch 91 iteration 100 with loss 0.08142. Total time 6.35416 hours\n",
      "Training at Epoch 91 iteration 200 with loss 0.07847. Total time 6.36111 hours\n",
      "Training at Epoch 91 iteration 300 with loss 0.08504. Total time 6.36833 hours\n",
      "Training at Epoch 91 iteration 400 with loss 0.10368. Total time 6.37527 hours\n",
      "Training at Epoch 91 iteration 500 with loss 0.07989. Total time 6.38222 hours\n",
      "Training at Epoch 91 iteration 600 with loss 0.09943. Total time 6.38916 hours\n",
      "Training at Epoch 91 iteration 700 with loss 0.06970. Total time 6.39611 hours\n",
      "Training at Epoch 91 iteration 800 with loss 0.08086. Total time 6.40305 hours\n",
      "Validation at Epoch 91 with loss:0.75894, MSE: 0.70606 , Pearson Correlation: 0.82404 with p-value: 0.00E+00 , Concordance Index: 0.82003\n",
      "Training at Epoch 92 iteration 0 with loss 0.07685. Total time 6.41722 hours\n",
      "Training at Epoch 92 iteration 100 with loss 0.06262. Total time 6.42444 hours\n",
      "Training at Epoch 92 iteration 200 with loss 0.05948. Total time 6.43138 hours\n",
      "Training at Epoch 92 iteration 300 with loss 0.08436. Total time 6.43833 hours\n",
      "Training at Epoch 92 iteration 400 with loss 0.07543. Total time 6.44555 hours\n",
      "Training at Epoch 92 iteration 500 with loss 0.07746. Total time 6.4525 hours\n",
      "Training at Epoch 92 iteration 600 with loss 0.10030. Total time 6.45972 hours\n",
      "Training at Epoch 92 iteration 700 with loss 0.11652. Total time 6.46666 hours\n",
      "Training at Epoch 92 iteration 800 with loss 0.10726. Total time 6.47361 hours\n",
      "Validation at Epoch 92 with loss:0.81804, MSE: 0.69407 , Pearson Correlation: 0.82479 with p-value: 0.00E+00 , Concordance Index: 0.82004\n",
      "Training at Epoch 93 iteration 0 with loss 0.06383. Total time 6.48805 hours\n",
      "Training at Epoch 93 iteration 100 with loss 0.07597. Total time 6.495 hours\n",
      "Training at Epoch 93 iteration 200 with loss 0.10433. Total time 6.50194 hours\n",
      "Training at Epoch 93 iteration 300 with loss 0.07072. Total time 6.50888 hours\n",
      "Training at Epoch 93 iteration 400 with loss 0.06659. Total time 6.51583 hours\n",
      "Training at Epoch 93 iteration 500 with loss 0.10642. Total time 6.52277 hours\n",
      "Training at Epoch 93 iteration 600 with loss 0.09210. Total time 6.52972 hours\n",
      "Training at Epoch 93 iteration 700 with loss 0.07515. Total time 6.53666 hours\n",
      "Training at Epoch 93 iteration 800 with loss 0.09228. Total time 6.54388 hours\n",
      "Validation at Epoch 93 with loss:0.68909, MSE: 0.69606 , Pearson Correlation: 0.82389 with p-value: 0.00E+00 , Concordance Index: 0.81945\n",
      "Training at Epoch 94 iteration 0 with loss 0.09152. Total time 6.55805 hours\n",
      "Training at Epoch 94 iteration 100 with loss 0.07348. Total time 6.565 hours\n",
      "Training at Epoch 94 iteration 200 with loss 0.11743. Total time 6.57194 hours\n",
      "Training at Epoch 94 iteration 300 with loss 0.04661. Total time 6.57888 hours\n",
      "Training at Epoch 94 iteration 400 with loss 0.07358. Total time 6.58583 hours\n",
      "Training at Epoch 94 iteration 500 with loss 0.08950. Total time 6.59277 hours\n",
      "Training at Epoch 94 iteration 600 with loss 0.06998. Total time 6.59972 hours\n",
      "Training at Epoch 94 iteration 700 with loss 0.09793. Total time 6.60694 hours\n",
      "Training at Epoch 94 iteration 800 with loss 0.09505. Total time 6.61388 hours\n",
      "Validation at Epoch 94 with loss:0.75511, MSE: 0.71215 , Pearson Correlation: 0.82373 with p-value: 0.00E+00 , Concordance Index: 0.81939\n",
      "Training at Epoch 95 iteration 0 with loss 0.07154. Total time 6.62805 hours\n",
      "Training at Epoch 95 iteration 100 with loss 0.07485. Total time 6.635 hours\n",
      "Training at Epoch 95 iteration 200 with loss 0.10272. Total time 6.64222 hours\n",
      "Training at Epoch 95 iteration 300 with loss 0.07096. Total time 6.64916 hours\n",
      "Training at Epoch 95 iteration 400 with loss 0.09640. Total time 6.65611 hours\n",
      "Training at Epoch 95 iteration 500 with loss 0.08164. Total time 6.66305 hours\n",
      "Training at Epoch 95 iteration 600 with loss 0.11002. Total time 6.67 hours\n",
      "Training at Epoch 95 iteration 700 with loss 0.08513. Total time 6.67694 hours\n",
      "Training at Epoch 95 iteration 800 with loss 0.10439. Total time 6.68388 hours\n",
      "Validation at Epoch 95 with loss:0.72858, MSE: 0.69509 , Pearson Correlation: 0.82448 with p-value: 0.00E+00 , Concordance Index: 0.81987\n",
      "Training at Epoch 96 iteration 0 with loss 0.06645. Total time 6.69805 hours\n",
      "Training at Epoch 96 iteration 100 with loss 0.06981. Total time 6.705 hours\n",
      "Training at Epoch 96 iteration 200 with loss 0.06411. Total time 6.71194 hours\n",
      "Training at Epoch 96 iteration 300 with loss 0.11410. Total time 6.71888 hours\n",
      "Training at Epoch 96 iteration 400 with loss 0.09448. Total time 6.72611 hours\n",
      "Training at Epoch 96 iteration 500 with loss 0.06650. Total time 6.73305 hours\n",
      "Training at Epoch 96 iteration 600 with loss 0.09338. Total time 6.74027 hours\n",
      "Training at Epoch 96 iteration 700 with loss 0.07427. Total time 6.74722 hours\n",
      "Training at Epoch 96 iteration 800 with loss 0.06960. Total time 6.75416 hours\n",
      "Validation at Epoch 96 with loss:0.54904, MSE: 0.69447 , Pearson Correlation: 0.82411 with p-value: 0.00E+00 , Concordance Index: 0.81976\n",
      "Training at Epoch 97 iteration 0 with loss 0.05525. Total time 6.76833 hours\n",
      "Training at Epoch 97 iteration 100 with loss 0.10376. Total time 6.77527 hours\n",
      "Training at Epoch 97 iteration 200 with loss 0.06634. Total time 6.7825 hours\n",
      "Training at Epoch 97 iteration 300 with loss 0.12582. Total time 6.78944 hours\n",
      "Training at Epoch 97 iteration 400 with loss 0.06420. Total time 6.79638 hours\n",
      "Training at Epoch 97 iteration 500 with loss 0.07093. Total time 6.80333 hours\n",
      "Training at Epoch 97 iteration 600 with loss 0.10319. Total time 6.81027 hours\n",
      "Training at Epoch 97 iteration 700 with loss 0.09424. Total time 6.81722 hours\n",
      "Training at Epoch 97 iteration 800 with loss 0.09134. Total time 6.82416 hours\n",
      "Validation at Epoch 97 with loss:0.59569, MSE: 0.69222 , Pearson Correlation: 0.82364 with p-value: 0.00E+00 , Concordance Index: 0.81967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 98 iteration 0 with loss 0.07495. Total time 6.83805 hours\n",
      "Training at Epoch 98 iteration 100 with loss 0.06633. Total time 6.84527 hours\n",
      "Training at Epoch 98 iteration 200 with loss 0.06791. Total time 6.85222 hours\n",
      "Training at Epoch 98 iteration 300 with loss 0.11301. Total time 6.85916 hours\n",
      "Training at Epoch 98 iteration 400 with loss 0.06413. Total time 6.86638 hours\n",
      "Training at Epoch 98 iteration 500 with loss 0.07372. Total time 6.87333 hours\n",
      "Training at Epoch 98 iteration 600 with loss 0.06693. Total time 6.88027 hours\n",
      "Training at Epoch 98 iteration 700 with loss 0.07064. Total time 6.88722 hours\n",
      "Training at Epoch 98 iteration 800 with loss 0.11075. Total time 6.89444 hours\n",
      "Validation at Epoch 98 with loss:0.67127, MSE: 0.69238 , Pearson Correlation: 0.82246 with p-value: 0.00E+00 , Concordance Index: 0.81927\n",
      "Training at Epoch 99 iteration 0 with loss 0.08298. Total time 6.90833 hours\n",
      "Training at Epoch 99 iteration 100 with loss 0.07024. Total time 6.91555 hours\n",
      "Training at Epoch 99 iteration 200 with loss 0.06951. Total time 6.92277 hours\n",
      "Training at Epoch 99 iteration 300 with loss 0.06398. Total time 6.92972 hours\n",
      "Training at Epoch 99 iteration 400 with loss 0.07943. Total time 6.93666 hours\n",
      "Training at Epoch 99 iteration 500 with loss 0.07635. Total time 6.94361 hours\n",
      "Training at Epoch 99 iteration 600 with loss 0.07297. Total time 6.95083 hours\n",
      "Training at Epoch 99 iteration 700 with loss 0.07452. Total time 6.95777 hours\n",
      "Training at Epoch 99 iteration 800 with loss 0.07147. Total time 6.96472 hours\n",
      "Validation at Epoch 99 with loss:0.79277, MSE: 0.69503 , Pearson Correlation: 0.82415 with p-value: 0.00E+00 , Concordance Index: 0.81996\n",
      "Training at Epoch 100 iteration 0 with loss 0.06977. Total time 6.97861 hours\n",
      "Training at Epoch 100 iteration 100 with loss 0.07486. Total time 6.98555 hours\n",
      "Training at Epoch 100 iteration 200 with loss 0.06306. Total time 6.9925 hours\n",
      "Training at Epoch 100 iteration 300 with loss 0.09439. Total time 6.99944 hours\n",
      "Training at Epoch 100 iteration 400 with loss 0.06998. Total time 7.00666 hours\n",
      "Training at Epoch 100 iteration 500 with loss 0.07228. Total time 7.01388 hours\n",
      "Training at Epoch 100 iteration 600 with loss 0.06832. Total time 7.02083 hours\n",
      "Training at Epoch 100 iteration 700 with loss 0.08409. Total time 7.02805 hours\n",
      "Training at Epoch 100 iteration 800 with loss 0.07730. Total time 7.035 hours\n",
      "Validation at Epoch 100 with loss:0.71343, MSE: 0.71223 , Pearson Correlation: 0.82297 with p-value: 0.00E+00 , Concordance Index: 0.81943\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.6812174369414099 , Pearson Correlation: 0.8254388568851166 with p-value: 0.00E+00 , Concordance Index: 0.8187782163409539\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/r2/title_r2_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r2/model_morgan_cnn_r2_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 320000 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 184101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:49] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2OCOc2cc1Cl)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:49] Explicit valence for atom # 19 C, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(C)[C@@H]1N(C)c2cc(ccc2C[C@@H](CO)NC1=O)[C]1234[B]567[B]89%10[B]%11%12%13[B]585[B]%118%11[B]%12%12%14[B]9%139[B]16%10[B]2%129[C]38%14[B]475%11 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:50] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: O[N]1=C(C=CC=C1)c1ccc(cc1)C(=O)NC\\C=C\\CN1CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:51] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COc1ccccc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:51] Explicit valence for atom # 29 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:51] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:04:52] Explicit valence for atom # 27 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccnc(Oc2ccc(cc2)-c2c(C)c(=O)nc(=O)n2C)c1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(F)cc1-c1noc(n1)-c1ccc(N2CCCCC2C)c(c1)N([O-])=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:52] Can't kekulize mol.  Unkekulized atoms: 8 9 11 12 13\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)nnc1C)[nH]c1ccnc(Cl)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:52] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(C)cc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:53] Can't kekulize mol.  Unkekulized atoms: 18 19 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:53] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(COc2ccc3NC(C4[C@@H](C(O)=O)C4(C)C)=[N](Cc4ccc(Br)cc4)c3c2)nc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:55] Can't kekulize mol.  Unkekulized atoms: 41 42 43 44 45\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:04:55] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 17 18 19 30 31 32\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN1CCN(Cc2ccc(cc2)C(=O)Nc2ccc(C)c(Nc3nccc(n3)-c3cncc(c3)C3=NN=C(C3)C(=O)c3nccn3)c2)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)[C@]3(C)Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:56] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:56] Explicit valence for atom # 14 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:04:56] Explicit valence for atom # 1 B, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(CC(=O)NC[N]3=COC=C3)C(=O)N2CC2CCC2)CC1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[B]1234[B]567[B]89%10[B]55%11[B]88%12[B]%13%14%15[B]11([B]2%132[B]365[C]%118%142c2ccc(O)cc2)[B]9%12%15=[C]47%101 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:57] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 8 28 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=C)n1ccc2cc(OCCCN3CCN(CC3)c3cccc4sccc34)ccc2c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:57] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CC(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:58] Can't kekulize mol.  Unkekulized atoms: 1 2 3 17 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCO)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:59] Can't kekulize mol.  Unkekulized atoms: 9 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:59] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCNCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:04:59] Can't kekulize mol.  Unkekulized atoms: 7 9 10 11 12\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:04:59] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccco1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:02] Can't kekulize mol.  Unkekulized atoms: 11 13 14 15 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:02] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5 6 7 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCCN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cccc2cc(OCCCCN3CCN(CC3)c3cccc4sccc34)c(=O)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:02] Explicit valence for atom # 2 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:02] Explicit valence for atom # 30 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC[N]1(CC)CCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=N)c1ccc(CNC(=O)[C@H](CCC2CCNCC2)NC(=O)[C@@H](CCCC2=CC=[N](O)C=C2)NS(=O)(=O)Cc2ccccc2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:03] Explicit valence for atom # 18 N, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C)[C@]1(CC[C@]2(CN(C(=O)N2)c2ccc(cn2)[N](C)(=O)=O)CC1)c1cccc(F)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:04] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(Cl)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:06] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:06] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1Cl)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:09] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:09] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2ncnc(Oc3cccc(NC(=O)NC4=CC(=[N](N4)c4ccccc4)C(F)(F)F)c3)c2cc1OC convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1CCN(CC1)c1cccc2C(N(CCc12)C(=O)C1=NC=C[N](=C1)c1cccc(Cl)c1F)C(=O)Nc1ccc(cc1)C(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:11] Can't kekulize mol.  Unkekulized atoms: 14 16 17 18 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:11] Explicit valence for atom # 9 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: On1nnc2cc(CC[N]3=NNN=C3)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:12] Explicit valence for atom # 13 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Oc1cc(Cc2cc(O)c(O)cc2N([O-])=O)c(cc1O)N([O-])=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:13] Can't kekulize mol.  Unkekulized atoms: 21 22 24 25 26\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cc2c(cc1-c1c(C)noc1C)[nH]c1ccnc(-c3c(C)nnc3-c3ccccc3)c21 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:14] Explicit valence for atom # 33 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:14] Can't kekulize mol.  Unkekulized atoms: 1 2 3 18 20\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:14] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16 19 20 21 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cc4ccccc4s1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:16] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:17] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccoc1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:17] Can't kekulize mol.  Unkekulized atoms: 1 2 3 20 22\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:17] Explicit valence for atom # 13 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCP(O)(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC1(CCN(CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)NCCc3cccnc3)N=C12)c1ccc(Cl)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:18] Explicit valence for atom # 29 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccsc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:18] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc2ccccc2c1)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:18] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cnc3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:19] Can't kekulize mol.  Unkekulized atoms: 6 7 8 9 10 11 12 13 14\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=O)NCCc1cc2ccccc2n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:20] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:20] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 7 8 9\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1cc2ccccc2o1)C5 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2[nH]c(nc2[nH]1)-c1ccc(Cn2nc(C)c(CC(O)=O)c2C)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:20] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(C)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:21] Can't kekulize mol.  Unkekulized atoms: 15 16 20\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:21] Explicit valence for atom # 19 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2Cl)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(nc1)C1CCCN1C(=O)c1ccc(N[N]2=CN3C=CC=C(N4CCC(O)(CC4)c4ccc(Cl)cc4)C3=N2)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:22] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 16 17 19\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(C)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:22] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:23] Can't kekulize mol.  Unkekulized atoms: 1 2 4 5 31\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:23] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1cocc(CN2CCC(CC2)NC(=O)[C@@](O)([C@@H]2CCC(F)(F)C2)c2ccccc2)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(cc1)C(N)=O)C5 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:24] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(C)C1=CC=[N](C=C1)C1CCCN(C1)C(=O)c1ccc(Nc2nc3c(cccn3n2)C2=CCN(CC2)C(=O)CCC(F)(F)F)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:25] Explicit valence for atom # 1 B, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[B]1234[B]567[B]89%10[B]%11%12%13[B]%14%15%16[B]15([B]2%141[B]%11%152=[C]311(CO)[B]8%122[B]4691)[C]7%10%13%16c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:25] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:25] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CC#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(Nc2ccc3ncc(nc3c2C#N)N2CCOCC2)ccc1OCC1=C[N](O)=C(C)C=C1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:27] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:27] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1F)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:28] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:28] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 15 18 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCC(O)=O)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1CN(CCN1CCCOc1ccc2nc(=O)ccc2c1)c1cccc2sccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:28] Can't kekulize mol.  Unkekulized atoms: 3 4 8\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(c(C)c(=O)nc1=O)-c1ccc(Oc2ncccc2Cl)cc1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:29] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccccc1C)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:29] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:29] Explicit valence for atom # 1 C, 7, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCNCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: N[C]12=34[B]567[B]89%10[B]55%11[B]%12%13%14[B]%15%16%17[B]88([B]169[B]2%158[B]=3%12%16[B]475%13)[C]%10%11%14%17c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:30] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:30] Can't kekulize mol.  Unkekulized atoms: 1 2 3 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(C)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1nc2n(CCN(CCCC#N)CCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:30] Can't kekulize mol.  Unkekulized atoms: 13 14 18\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cnc(Oc2ccc(c(C)c2)-c2c(C)c(=O)nc(=O)n2C)c(Cl)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:32] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Oc1ccc(Cc2cc(O)c(O)cc2N([O-])=O)cc1O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:32] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:32] Explicit valence for atom # 17 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)N3CCCCC3c3cccnc3)N=C12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:33] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:34] Can't kekulize mol.  Unkekulized atoms: 11 13 14 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: FC(F)(F)CCC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)CCCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:34] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cccc2cc(CCNC(C)=O)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:35] Can't kekulize mol.  Unkekulized atoms: 8 10 11 12 13\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:35] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC(=O)CN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: On1ncc2cc(COC[N]3=NNN=C3)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:36] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc(COC[C@H]2C[C@]34CC[C@]2(OC)[C@@H]2Oc5c6c(C[C@H]3[N](C)(CC3CC3)CC[C@@]426)ccc5OC)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:36] Explicit valence for atom # 8 C, 5, is greater than permitted\n",
      "RDKit ERROR: [03:05:36] Explicit valence for atom # 31 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OCC1O[C@H](SC2=C[C](=O)=NC=C2)C(O)[C@H]([C@H]1O)n1cc(nn1)-c1cc(F)c(F)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(F)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:36] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC1CC1)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:37] Explicit valence for atom # 26 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:37] Can't kekulize mol.  Unkekulized atoms: 2 3 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccccc1-c1noc(n1)-c1ccc(-c2ccccc2C)c(c1)N(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1c(-c2ccc(Oc3ncccc3Cl)cc2C)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:38] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CNc1cc(NC2=CC=C[N](C3CCOCC3)=[C]2=O)nc2c(cnn12)C(=O)N[C@@H]1CCC[C@H](C1)OC convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:38] Can't kekulize mol.  Unkekulized atoms: 17 18 22\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1cc(Oc2ncccc2C(F)F)ccc1-c1c(C)c(=O)nc(=O)n1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:39] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 17 18 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:40] Can't kekulize mol.  Unkekulized atoms: 12 13 14 16 19 20 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2)-c2nc3[nH]c(OC)ccc3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:40] Explicit valence for atom # 8 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CN(C1CCC(CC1)N(=O)C=C)c1cc(cn2cncc12)-c1ccc(O)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:41] Explicit valence for atom # 16 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1CCCN(CCNC(=O)c2ccc(N[N]3=CN4C=CC=C(N5CCC(O)(CC5)c5ccc(Cl)cc5)C4=N3)cc2)C1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:41] Explicit valence for atom # 31 H, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)C1CC[C@H]1c1nc([H]C(F)F)cc(n1)C(F)F convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:42] non-ring atom 14 marked aromatic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(O)(CS(=O)(=O)c1ccc(F)cc1)[c](=O):c:n-c1ccc(C#N)c(c1)C(F)(F)F convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:43] Can't kekulize mol.  Unkekulized atoms: 3 20 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCn1c(-c2ccc(Oc3ncccc3C(F)F)cc2)c(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:43] Can't kekulize mol.  Unkekulized atoms: 1 2 3 14 16\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Nc1nc2n(CCOCCP(O)(O)=O)c[nH]c2c(=O)[nH]1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:44] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 8 9 29 30 31\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC(=O)n1cccc2cc(OCCCN3CCN(CC3)c3cccc4sccc34)ccc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:46] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 16 17 18 28 29 30\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCO[C@]12Cc3c(nc4ccccc34)C3Oc4c5c(CC1N(CC=C)CCC235)ccc4O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:47] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:47] Can't kekulize mol.  Unkekulized atoms: 20 21 22 23 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1cccc(F)c1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](NC(=O)c1cc(Cn2ccn(C)c2=N)cc(c1F)-c1ccccn1C(F)(F)F)c1ccc(F)c(C)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:47] Explicit valence for atom # 24 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: FC(F)(F)c1cccc(Nc2ccc3C(CCCN4CCOCC4)[N](=Cc3c2)c2ccccc2)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:48] Explicit valence for atom # 14 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:48] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OC1(CCN(CC1)c1ccc[nH]\\c1=N/[N](=C)Nc1ccc(cc1)C(=O)NC1CCNC1)c1ccc(Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OP(O)(=O)CCOCCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:48] Explicit valence for atom # 29 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:48] Can't kekulize mol.  Unkekulized atoms: 1 2 23\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccoc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)F)cc2)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:49] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6 7 8 15 16\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [03:05:49] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:49] Can't kekulize mol.  Unkekulized atoms: 13 14 15 16 18 19 21\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1cccc2nc(CCNC(C)=O)cc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1ccc(COc2cc3c(NC([C@@H]4CCCC[C@@H]4C(O)=O)=[N]3Cc3ccc(OC(F)(F)F)cc3F)cc2F)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1nn(Cc2ccc(cc2F)-c2nc3c[nH]cc(C)c3[nH]2)c(CC)c1CC(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:49] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:49] Can't kekulize mol.  Unkekulized atoms: 1 2 27\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: C[N]1=CC(N2C(=O)c3c(C2=O)c(NS(=O)(=O)c2ccc(cc2)C(C)(C)C)ccc3Cl)=C(N1)C(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3C(F)(F)F)c3[nH]ccc23)n(C)c(=O)nc1=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:50] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CC1=C(C(C)=[N](C)C=N1)c1ccc(Oc2nccc3N(CCc23)C2CCCCO2)cc1C convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:50] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCn1c[nH]c2c1nc[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:52] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: O[N]1(C\\C=C\\CNC(=O)c2ccc(cc2)-c2ccccn2)CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:53] Explicit valence for atom # 21 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1ccc(COc2ccc3NC([C@@H]4[C@@H](C(O)=O)C4(C)C)=[N](Cc4ccc(Br)cc4)c3c2)nc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:53] Can't kekulize mol.  Unkekulized atoms: 10 12 13 14 15\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)CN(CCn1c[nH]c2c1nc(N)[nH]c2=O)CCP(O)(O)=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:53] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:54] Can't kekulize mol.  Unkekulized atoms: 16 17 18 19 20 21 22 23 25\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COc1ccc2C[C@@H]3[C@]45CC[C@](OC)([C@@H]6Oc1c2[C@]46CC[N]3(C)CC1CC1)[C@@H](COCc1ccc(Cl)c(Cl)c1)C5 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(F)c(NC(=O)Nc2cnn(c2)-c2cccc3nnc(N)c23)c1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:54] Explicit valence for atom # 27 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)c1cccn2nc(Nc3ccc(cc3)C(=O)[N]34CC5COCC(C3)N45)nc12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:55] Can't kekulize mol.  Unkekulized atoms: 15 17 18 19 20\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: OP(O)(=O)CCN(CCCC#N)CCn1c[nH]c2c1nc[nH]c2=O convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:56] Explicit valence for atom # 17 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCC(=CC1)C1=CC=CN2C=[N](Nc3ccc(cc3)C(=O)NC3CCNC3)N=C12 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:58] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13 23 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: COC(=O)Nc1ccc2-c3cnc(n3)[C@H](CCC[C@@H](C)C(=O)Nc2c1)NC(=O)c1nnn(c1C)-c1c(F)ccc(Cl)c1F convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:59] Explicit valence for atom # 0 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: [H][N]1(CC)CCC[C@H](C1)NC(=O)NCCc1ccc(OC(C)C)cc1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:59] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [03:05:59] Explicit valence for atom # 33 H, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: CO[C@]12CC[C@@]3(C[C@@H]1COCc1ccc(Cl)cc1)[C@H]1Cc4ccc(O)c5O[C@@H]2[C@]3(CC[N]1(C)CC1CC1)c45 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](c1ccc(nc1)C(F)(F)F)n1nc(C#N)c2c1nc([nH]c2=O)[C@@H]1CC[C@H]1c1nccc([H]C(F)F)n1 convert to all 0 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:05:59] Can't kekulize mol.  Unkekulized atoms: 1 2 24\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit not found this smiles for morgan: Cc1c(-c2ccc(Oc3ncccc3OC(F)F)cc2)n(C)c(=O)nc1=O convert to all 0 features\n",
      "encoding protein...\n",
      "unique target sequence: 3764\n",
      "splitting dataset...\n",
      "Done.\n",
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 50.3137. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 1.88903. Total time 0.00694 hours\n",
      "Training at Epoch 1 iteration 200 with loss 1.55984. Total time 0.01444 hours\n",
      "Training at Epoch 1 iteration 300 with loss 1.27928. Total time 0.02138 hours\n",
      "Training at Epoch 1 iteration 400 with loss 1.56585. Total time 0.02861 hours\n",
      "Training at Epoch 1 iteration 500 with loss 1.25565. Total time 0.03583 hours\n",
      "Training at Epoch 1 iteration 600 with loss 1.39307. Total time 0.04305 hours\n",
      "Training at Epoch 1 iteration 700 with loss 1.13823. Total time 0.05 hours\n",
      "Training at Epoch 1 iteration 800 with loss 1.21270. Total time 0.05722 hours\n",
      "Validation at Epoch 1 with loss:1.23915, MSE: 1.23650 , Pearson Correlation: 0.70897 with p-value: 0.00E+00 , Concordance Index: 0.75056\n",
      "Training at Epoch 2 iteration 0 with loss 1.14998. Total time 0.07138 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.81883. Total time 0.07861 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.92832. Total time 0.08555 hours\n",
      "Training at Epoch 2 iteration 300 with loss 1.05093. Total time 0.09277 hours\n",
      "Training at Epoch 2 iteration 400 with loss 1.04129. Total time 0.09972 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.89779. Total time 0.10694 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.96223. Total time 0.11388 hours\n",
      "Training at Epoch 2 iteration 700 with loss 1.01101. Total time 0.12111 hours\n",
      "Training at Epoch 2 iteration 800 with loss 0.85162. Total time 0.12805 hours\n",
      "Validation at Epoch 2 with loss:0.96165, MSE: 0.95383 , Pearson Correlation: 0.74178 with p-value: 0.00E+00 , Concordance Index: 0.76594\n",
      "Training at Epoch 3 iteration 0 with loss 0.95905. Total time 0.1425 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.74593. Total time 0.14972 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.87429. Total time 0.15666 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.76735. Total time 0.16361 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.79742. Total time 0.17083 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.72173. Total time 0.17777 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.76415. Total time 0.185 hours\n",
      "Training at Epoch 3 iteration 700 with loss 0.83367. Total time 0.19194 hours\n",
      "Training at Epoch 3 iteration 800 with loss 1.07433. Total time 0.19888 hours\n",
      "Validation at Epoch 3 with loss:0.87826, MSE: 0.99226 , Pearson Correlation: 0.75129 with p-value: 0.00E+00 , Concordance Index: 0.77114\n",
      "Training at Epoch 4 iteration 0 with loss 0.66741. Total time 0.21333 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.69709. Total time 0.22027 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.77631. Total time 0.22722 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.81369. Total time 0.23444 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.91000. Total time 0.24166 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.84206. Total time 0.24861 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.70276. Total time 0.25583 hours\n",
      "Training at Epoch 4 iteration 700 with loss 0.87439. Total time 0.26277 hours\n",
      "Training at Epoch 4 iteration 800 with loss 0.88298. Total time 0.27 hours\n",
      "Validation at Epoch 4 with loss:0.81094, MSE: 0.90065 , Pearson Correlation: 0.75857 with p-value: 0.00E+00 , Concordance Index: 0.77502\n",
      "Training at Epoch 5 iteration 0 with loss 0.63628. Total time 0.28416 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.63881. Total time 0.29138 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.69150. Total time 0.29833 hours\n",
      "Training at Epoch 5 iteration 300 with loss 1.04486. Total time 0.30555 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.73967. Total time 0.3125 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.71734. Total time 0.31972 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.78471. Total time 0.32694 hours\n",
      "Training at Epoch 5 iteration 700 with loss 0.63287. Total time 0.33388 hours\n",
      "Training at Epoch 5 iteration 800 with loss 0.76470. Total time 0.34111 hours\n",
      "Validation at Epoch 5 with loss:1.00985, MSE: 0.91336 , Pearson Correlation: 0.75863 with p-value: 0.00E+00 , Concordance Index: 0.77495\n",
      "Training at Epoch 6 iteration 0 with loss 0.68563. Total time 0.35555 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.71620. Total time 0.36277 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.62097. Total time 0.37 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.71345. Total time 0.37722 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.63341. Total time 0.38416 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.68485. Total time 0.39138 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.83804. Total time 0.39833 hours\n",
      "Training at Epoch 6 iteration 700 with loss 0.70721. Total time 0.40555 hours\n",
      "Training at Epoch 6 iteration 800 with loss 0.64451. Total time 0.4125 hours\n",
      "Validation at Epoch 6 with loss:0.86300, MSE: 0.90825 , Pearson Correlation: 0.75862 with p-value: 0.00E+00 , Concordance Index: 0.77499\n",
      "Training at Epoch 7 iteration 0 with loss 0.55582. Total time 0.42694 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.48786. Total time 0.43388 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.73470. Total time 0.44111 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.71873. Total time 0.44805 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.71910. Total time 0.45527 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.59673. Total time 0.46222 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.56436. Total time 0.46916 hours\n",
      "Training at Epoch 7 iteration 700 with loss 0.64228. Total time 0.47638 hours\n",
      "Training at Epoch 7 iteration 800 with loss 0.71199. Total time 0.48361 hours\n",
      "Validation at Epoch 7 with loss:0.77329, MSE: 0.92721 , Pearson Correlation: 0.76089 with p-value: 0.00E+00 , Concordance Index: 0.77727\n",
      "Training at Epoch 8 iteration 0 with loss 0.50084. Total time 0.49777 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.57888. Total time 0.505 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.54811. Total time 0.51194 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.58368. Total time 0.51916 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.67627. Total time 0.52611 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.61184. Total time 0.53305 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.69725. Total time 0.54027 hours\n",
      "Training at Epoch 8 iteration 700 with loss 0.60191. Total time 0.54722 hours\n",
      "Training at Epoch 8 iteration 800 with loss 0.52864. Total time 0.55416 hours\n",
      "Validation at Epoch 8 with loss:0.75184, MSE: 0.87192 , Pearson Correlation: 0.77180 with p-value: 0.00E+00 , Concordance Index: 0.78305\n",
      "Training at Epoch 9 iteration 0 with loss 0.52568. Total time 0.56833 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.60655. Total time 0.57555 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.63437. Total time 0.5825 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.55906. Total time 0.58944 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.53414. Total time 0.59638 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.53046. Total time 0.60333 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.44785. Total time 0.61027 hours\n",
      "Training at Epoch 9 iteration 700 with loss 0.54222. Total time 0.6175 hours\n",
      "Training at Epoch 9 iteration 800 with loss 0.62397. Total time 0.62472 hours\n",
      "Validation at Epoch 9 with loss:0.87539, MSE: 0.87406 , Pearson Correlation: 0.77869 with p-value: 0.00E+00 , Concordance Index: 0.78857\n",
      "Training at Epoch 10 iteration 0 with loss 0.41792. Total time 0.63888 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.47397. Total time 0.64583 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.44750. Total time 0.65305 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.48518. Total time 0.66 hours\n",
      "Training at Epoch 10 iteration 400 with loss 0.42277. Total time 0.66694 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.47786. Total time 0.67416 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 10 iteration 600 with loss 0.44568. Total time 0.68111 hours\n",
      "Training at Epoch 10 iteration 700 with loss 0.55719. Total time 0.68805 hours\n",
      "Training at Epoch 10 iteration 800 with loss 0.43794. Total time 0.695 hours\n",
      "Validation at Epoch 10 with loss:0.88844, MSE: 0.83650 , Pearson Correlation: 0.78464 with p-value: 0.00E+00 , Concordance Index: 0.79213\n",
      "Training at Epoch 11 iteration 0 with loss 0.43623. Total time 0.70916 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.41873. Total time 0.71638 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.51566. Total time 0.72333 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.42305. Total time 0.73027 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.49683. Total time 0.73722 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.49488. Total time 0.74444 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.51665. Total time 0.75138 hours\n",
      "Training at Epoch 11 iteration 700 with loss 0.49556. Total time 0.75861 hours\n",
      "Training at Epoch 11 iteration 800 with loss 0.54270. Total time 0.76583 hours\n",
      "Validation at Epoch 11 with loss:0.79795, MSE: 0.82046 , Pearson Correlation: 0.79199 with p-value: 0.00E+00 , Concordance Index: 0.79705\n",
      "Training at Epoch 12 iteration 0 with loss 0.37536. Total time 0.78 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.36950. Total time 0.78722 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.37119. Total time 0.79416 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.40942. Total time 0.80111 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.43211. Total time 0.80805 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.44569. Total time 0.81527 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.41680. Total time 0.8225 hours\n",
      "Training at Epoch 12 iteration 700 with loss 0.48256. Total time 0.83 hours\n",
      "Training at Epoch 12 iteration 800 with loss 0.51341. Total time 0.83694 hours\n",
      "Validation at Epoch 12 with loss:0.80363, MSE: 0.79246 , Pearson Correlation: 0.79292 with p-value: 0.00E+00 , Concordance Index: 0.79769\n",
      "Training at Epoch 13 iteration 0 with loss 0.35174. Total time 0.85111 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.30648. Total time 0.85833 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.37571. Total time 0.86527 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.40937. Total time 0.8725 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.43145. Total time 0.87944 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.38322. Total time 0.88638 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.40798. Total time 0.89361 hours\n",
      "Training at Epoch 13 iteration 700 with loss 0.40187. Total time 0.90055 hours\n",
      "Training at Epoch 13 iteration 800 with loss 0.50022. Total time 0.90777 hours\n",
      "Validation at Epoch 13 with loss:0.70604, MSE: 0.76995 , Pearson Correlation: 0.79988 with p-value: 0.00E+00 , Concordance Index: 0.80129\n",
      "Training at Epoch 14 iteration 0 with loss 0.34988. Total time 0.92194 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.32286. Total time 0.92888 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.35457. Total time 0.93611 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.29506. Total time 0.94305 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.39127. Total time 0.95027 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.45865. Total time 0.95722 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.35282. Total time 0.96416 hours\n",
      "Training at Epoch 14 iteration 700 with loss 0.31391. Total time 0.97138 hours\n",
      "Training at Epoch 14 iteration 800 with loss 0.32697. Total time 0.97833 hours\n",
      "Validation at Epoch 14 with loss:0.72348, MSE: 0.75066 , Pearson Correlation: 0.80466 with p-value: 0.00E+00 , Concordance Index: 0.80464\n",
      "Training at Epoch 15 iteration 0 with loss 0.30408. Total time 0.9925 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.24251. Total time 0.99944 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.31637. Total time 1.00666 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.31410. Total time 1.01361 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.35816. Total time 1.02083 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.46075. Total time 1.02777 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.36989. Total time 1.035 hours\n",
      "Training at Epoch 15 iteration 700 with loss 0.30125. Total time 1.04194 hours\n",
      "Training at Epoch 15 iteration 800 with loss 0.33676. Total time 1.04916 hours\n",
      "Validation at Epoch 15 with loss:0.88224, MSE: 0.75828 , Pearson Correlation: 0.80377 with p-value: 0.00E+00 , Concordance Index: 0.80390\n",
      "Training at Epoch 16 iteration 0 with loss 0.31673. Total time 1.06361 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.30700. Total time 1.07055 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.30507. Total time 1.0775 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.31816. Total time 1.08472 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.30325. Total time 1.09166 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.30424. Total time 1.09861 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.28727. Total time 1.10583 hours\n",
      "Training at Epoch 16 iteration 700 with loss 0.37096. Total time 1.11277 hours\n",
      "Training at Epoch 16 iteration 800 with loss 0.29985. Total time 1.11972 hours\n",
      "Validation at Epoch 16 with loss:0.82692, MSE: 0.74381 , Pearson Correlation: 0.80570 with p-value: 0.00E+00 , Concordance Index: 0.80520\n",
      "Training at Epoch 17 iteration 0 with loss 0.37000. Total time 1.13416 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.35266. Total time 1.14111 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.34362. Total time 1.14805 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.25152. Total time 1.15527 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.34269. Total time 1.1625 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.29912. Total time 1.16944 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.28046. Total time 1.17638 hours\n",
      "Training at Epoch 17 iteration 700 with loss 0.25902. Total time 1.18361 hours\n",
      "Training at Epoch 17 iteration 800 with loss 0.31237. Total time 1.19055 hours\n",
      "Validation at Epoch 17 with loss:0.81122, MSE: 0.74121 , Pearson Correlation: 0.80687 with p-value: 0.00E+00 , Concordance Index: 0.80570\n",
      "Training at Epoch 18 iteration 0 with loss 0.24389. Total time 1.20472 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.27431. Total time 1.21166 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.35126. Total time 1.21916 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.27861. Total time 1.22638 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.32473. Total time 1.23388 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.31091. Total time 1.24111 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.29437. Total time 1.24805 hours\n",
      "Training at Epoch 18 iteration 700 with loss 0.36946. Total time 1.25527 hours\n",
      "Training at Epoch 18 iteration 800 with loss 0.33101. Total time 1.26222 hours\n",
      "Validation at Epoch 18 with loss:0.82599, MSE: 0.73764 , Pearson Correlation: 0.80952 with p-value: 0.00E+00 , Concordance Index: 0.80806\n",
      "Training at Epoch 19 iteration 0 with loss 0.25189. Total time 1.27638 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.22914. Total time 1.28361 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.27593. Total time 1.29055 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.20338. Total time 1.2975 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.30206. Total time 1.30472 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.31493. Total time 1.31166 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.31938. Total time 1.31861 hours\n",
      "Training at Epoch 19 iteration 700 with loss 0.26846. Total time 1.32555 hours\n",
      "Training at Epoch 19 iteration 800 with loss 0.30396. Total time 1.33277 hours\n",
      "Validation at Epoch 19 with loss:0.71628, MSE: 0.73724 , Pearson Correlation: 0.81143 with p-value: 0.00E+00 , Concordance Index: 0.80936\n",
      "Training at Epoch 20 iteration 0 with loss 0.23136. Total time 1.34694 hours\n",
      "Training at Epoch 20 iteration 100 with loss 0.24546. Total time 1.35388 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.24221. Total time 1.36083 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 20 iteration 300 with loss 0.26163. Total time 1.36805 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.22605. Total time 1.375 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.25540. Total time 1.38194 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.24936. Total time 1.38888 hours\n",
      "Training at Epoch 20 iteration 700 with loss 0.20819. Total time 1.39611 hours\n",
      "Training at Epoch 20 iteration 800 with loss 0.27245. Total time 1.40305 hours\n",
      "Validation at Epoch 20 with loss:1.05491, MSE: 0.77216 , Pearson Correlation: 0.81227 with p-value: 0.00E+00 , Concordance Index: 0.80999\n",
      "Training at Epoch 21 iteration 0 with loss 0.23637. Total time 1.41722 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.24831. Total time 1.42416 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.21259. Total time 1.43111 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.23026. Total time 1.43833 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.22779. Total time 1.44527 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.23364. Total time 1.45222 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.25752. Total time 1.45944 hours\n",
      "Training at Epoch 21 iteration 700 with loss 0.32034. Total time 1.46638 hours\n",
      "Training at Epoch 21 iteration 800 with loss 0.26648. Total time 1.47333 hours\n",
      "Validation at Epoch 21 with loss:0.53729, MSE: 0.71859 , Pearson Correlation: 0.81416 with p-value: 0.00E+00 , Concordance Index: 0.81057\n",
      "Training at Epoch 22 iteration 0 with loss 0.24166. Total time 1.4875 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.28015. Total time 1.49472 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.25957. Total time 1.50166 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.23349. Total time 1.50861 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.27221. Total time 1.51583 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.27536. Total time 1.52277 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.32041. Total time 1.53 hours\n",
      "Training at Epoch 22 iteration 700 with loss 0.22969. Total time 1.53694 hours\n",
      "Training at Epoch 22 iteration 800 with loss 0.27327. Total time 1.54388 hours\n",
      "Validation at Epoch 22 with loss:0.77773, MSE: 0.72713 , Pearson Correlation: 0.81274 with p-value: 0.00E+00 , Concordance Index: 0.80986\n",
      "Training at Epoch 23 iteration 0 with loss 0.23163. Total time 1.55833 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.25215. Total time 1.56527 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.22411. Total time 1.5725 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.20962. Total time 1.57944 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.20375. Total time 1.58638 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.20397. Total time 1.59361 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.27659. Total time 1.60055 hours\n",
      "Training at Epoch 23 iteration 700 with loss 0.24412. Total time 1.6075 hours\n",
      "Training at Epoch 23 iteration 800 with loss 0.31762. Total time 1.61472 hours\n",
      "Validation at Epoch 23 with loss:0.59662, MSE: 0.73988 , Pearson Correlation: 0.81526 with p-value: 0.00E+00 , Concordance Index: 0.81138\n",
      "Training at Epoch 24 iteration 0 with loss 0.22856. Total time 1.62888 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.22044. Total time 1.63583 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.21813. Total time 1.64305 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.24378. Total time 1.65 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.21050. Total time 1.65722 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.17130. Total time 1.66416 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.24735. Total time 1.67111 hours\n",
      "Training at Epoch 24 iteration 700 with loss 0.22998. Total time 1.67805 hours\n",
      "Training at Epoch 24 iteration 800 with loss 0.22772. Total time 1.68527 hours\n",
      "Validation at Epoch 24 with loss:0.59483, MSE: 0.72297 , Pearson Correlation: 0.81495 with p-value: 0.00E+00 , Concordance Index: 0.81155\n",
      "Training at Epoch 25 iteration 0 with loss 0.16312. Total time 1.69944 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.22893. Total time 1.70638 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.22469. Total time 1.71333 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.20954. Total time 1.72055 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.21807. Total time 1.7275 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.23397. Total time 1.73472 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.27249. Total time 1.74166 hours\n",
      "Training at Epoch 25 iteration 700 with loss 0.23211. Total time 1.74861 hours\n",
      "Training at Epoch 25 iteration 800 with loss 0.20515. Total time 1.75583 hours\n",
      "Validation at Epoch 25 with loss:0.68726, MSE: 0.71334 , Pearson Correlation: 0.81544 with p-value: 0.00E+00 , Concordance Index: 0.81206\n",
      "Training at Epoch 26 iteration 0 with loss 0.18677. Total time 1.77 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.16724. Total time 1.77694 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.21472. Total time 1.78388 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.17878. Total time 1.79083 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.20087. Total time 1.79777 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.19692. Total time 1.805 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.22134. Total time 1.81194 hours\n",
      "Training at Epoch 26 iteration 700 with loss 0.20540. Total time 1.81888 hours\n",
      "Training at Epoch 26 iteration 800 with loss 0.19757. Total time 1.82611 hours\n",
      "Validation at Epoch 26 with loss:0.77386, MSE: 0.71162 , Pearson Correlation: 0.81723 with p-value: 0.00E+00 , Concordance Index: 0.81268\n",
      "Training at Epoch 27 iteration 0 with loss 0.17010. Total time 1.84027 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.17008. Total time 1.84722 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.22619. Total time 1.85416 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.16089. Total time 1.86111 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.18082. Total time 1.86833 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.24308. Total time 1.87527 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.19733. Total time 1.88222 hours\n",
      "Training at Epoch 27 iteration 700 with loss 0.19884. Total time 1.88916 hours\n",
      "Training at Epoch 27 iteration 800 with loss 0.23038. Total time 1.89638 hours\n",
      "Validation at Epoch 27 with loss:0.65955, MSE: 0.72492 , Pearson Correlation: 0.81626 with p-value: 0.00E+00 , Concordance Index: 0.81194\n",
      "Training at Epoch 28 iteration 0 with loss 0.14305. Total time 1.91055 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.20649. Total time 1.9175 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.15223. Total time 1.92472 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.20181. Total time 1.93166 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.20118. Total time 1.93888 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.18718. Total time 1.94583 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.19892. Total time 1.95305 hours\n",
      "Training at Epoch 28 iteration 700 with loss 0.22618. Total time 1.96 hours\n",
      "Training at Epoch 28 iteration 800 with loss 0.24674. Total time 1.96722 hours\n",
      "Validation at Epoch 28 with loss:0.73134, MSE: 0.70402 , Pearson Correlation: 0.81815 with p-value: 0.00E+00 , Concordance Index: 0.81368\n",
      "Training at Epoch 29 iteration 0 with loss 0.15416. Total time 1.98138 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.15984. Total time 1.98861 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.23160. Total time 1.99611 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.22748. Total time 2.00333 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.22903. Total time 2.01055 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.20224. Total time 2.01805 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.17579. Total time 2.02527 hours\n",
      "Training at Epoch 29 iteration 700 with loss 0.18450. Total time 2.0325 hours\n",
      "Training at Epoch 29 iteration 800 with loss 0.24047. Total time 2.03972 hours\n",
      "Validation at Epoch 29 with loss:0.55474, MSE: 0.71847 , Pearson Correlation: 0.81705 with p-value: 0.00E+00 , Concordance Index: 0.81326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 30 iteration 0 with loss 0.15913. Total time 2.05388 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.15762. Total time 2.06083 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.19225. Total time 2.06805 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.22945. Total time 2.075 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.22593. Total time 2.08222 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.20590. Total time 2.08916 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.20905. Total time 2.09611 hours\n",
      "Training at Epoch 30 iteration 700 with loss 0.18760. Total time 2.10333 hours\n",
      "Training at Epoch 30 iteration 800 with loss 0.21268. Total time 2.11027 hours\n",
      "Validation at Epoch 30 with loss:0.71445, MSE: 0.72890 , Pearson Correlation: 0.81778 with p-value: 0.00E+00 , Concordance Index: 0.81349\n",
      "Training at Epoch 31 iteration 0 with loss 0.16116. Total time 2.12444 hours\n",
      "Training at Epoch 31 iteration 100 with loss 0.16428. Total time 2.13166 hours\n",
      "Training at Epoch 31 iteration 200 with loss 0.16231. Total time 2.13861 hours\n",
      "Training at Epoch 31 iteration 300 with loss 0.18291. Total time 2.14555 hours\n",
      "Training at Epoch 31 iteration 400 with loss 0.24449. Total time 2.1525 hours\n",
      "Training at Epoch 31 iteration 500 with loss 0.21227. Total time 2.15972 hours\n",
      "Training at Epoch 31 iteration 600 with loss 0.15817. Total time 2.16666 hours\n",
      "Training at Epoch 31 iteration 700 with loss 0.14515. Total time 2.17361 hours\n",
      "Training at Epoch 31 iteration 800 with loss 0.20203. Total time 2.18055 hours\n",
      "Validation at Epoch 31 with loss:0.72318, MSE: 0.69661 , Pearson Correlation: 0.81923 with p-value: 0.00E+00 , Concordance Index: 0.81462\n",
      "Training at Epoch 32 iteration 0 with loss 0.15962. Total time 2.19472 hours\n",
      "Training at Epoch 32 iteration 100 with loss 0.14949. Total time 2.20166 hours\n",
      "Training at Epoch 32 iteration 200 with loss 0.19243. Total time 2.20861 hours\n",
      "Training at Epoch 32 iteration 300 with loss 0.13490. Total time 2.21555 hours\n",
      "Training at Epoch 32 iteration 400 with loss 0.16885. Total time 2.22277 hours\n",
      "Training at Epoch 32 iteration 500 with loss 0.19024. Total time 2.22972 hours\n",
      "Training at Epoch 32 iteration 600 with loss 0.21350. Total time 2.23666 hours\n",
      "Training at Epoch 32 iteration 700 with loss 0.15086. Total time 2.24361 hours\n",
      "Training at Epoch 32 iteration 800 with loss 0.20131. Total time 2.25083 hours\n",
      "Validation at Epoch 32 with loss:0.79546, MSE: 0.70547 , Pearson Correlation: 0.81732 with p-value: 0.00E+00 , Concordance Index: 0.81367\n",
      "Training at Epoch 33 iteration 0 with loss 0.14015. Total time 2.26472 hours\n",
      "Training at Epoch 33 iteration 100 with loss 0.19330. Total time 2.27194 hours\n",
      "Training at Epoch 33 iteration 200 with loss 0.16870. Total time 2.27888 hours\n",
      "Training at Epoch 33 iteration 300 with loss 0.18621. Total time 2.28583 hours\n",
      "Training at Epoch 33 iteration 400 with loss 0.23728. Total time 2.29277 hours\n",
      "Training at Epoch 33 iteration 500 with loss 0.19622. Total time 2.29972 hours\n",
      "Training at Epoch 33 iteration 600 with loss 0.18803. Total time 2.30666 hours\n",
      "Training at Epoch 33 iteration 700 with loss 0.16365. Total time 2.31361 hours\n",
      "Training at Epoch 33 iteration 800 with loss 0.20048. Total time 2.32055 hours\n",
      "Validation at Epoch 33 with loss:0.74972, MSE: 0.71820 , Pearson Correlation: 0.81719 with p-value: 0.00E+00 , Concordance Index: 0.81339\n",
      "Training at Epoch 34 iteration 0 with loss 0.17023. Total time 2.33472 hours\n",
      "Training at Epoch 34 iteration 100 with loss 0.12700. Total time 2.34194 hours\n",
      "Training at Epoch 34 iteration 200 with loss 0.14594. Total time 2.34888 hours\n",
      "Training at Epoch 34 iteration 300 with loss 0.18702. Total time 2.35583 hours\n",
      "Training at Epoch 34 iteration 400 with loss 0.14173. Total time 2.36305 hours\n",
      "Training at Epoch 34 iteration 500 with loss 0.18485. Total time 2.37 hours\n",
      "Training at Epoch 34 iteration 600 with loss 0.19789. Total time 2.37722 hours\n",
      "Training at Epoch 34 iteration 700 with loss 0.18244. Total time 2.38416 hours\n",
      "Training at Epoch 34 iteration 800 with loss 0.16339. Total time 2.39111 hours\n",
      "Validation at Epoch 34 with loss:0.74880, MSE: 0.70324 , Pearson Correlation: 0.81715 with p-value: 0.00E+00 , Concordance Index: 0.81438\n",
      "Training at Epoch 35 iteration 0 with loss 0.14946. Total time 2.40527 hours\n",
      "Training at Epoch 35 iteration 100 with loss 0.14982. Total time 2.41222 hours\n",
      "Training at Epoch 35 iteration 200 with loss 0.15104. Total time 2.41944 hours\n",
      "Training at Epoch 35 iteration 300 with loss 0.16687. Total time 2.42638 hours\n",
      "Training at Epoch 35 iteration 400 with loss 0.12436. Total time 2.43361 hours\n",
      "Training at Epoch 35 iteration 500 with loss 0.19001. Total time 2.44055 hours\n",
      "Training at Epoch 35 iteration 600 with loss 0.14242. Total time 2.4475 hours\n",
      "Training at Epoch 35 iteration 700 with loss 0.17678. Total time 2.45472 hours\n",
      "Training at Epoch 35 iteration 800 with loss 0.18389. Total time 2.46166 hours\n",
      "Validation at Epoch 35 with loss:0.84944, MSE: 0.69768 , Pearson Correlation: 0.81919 with p-value: 0.00E+00 , Concordance Index: 0.81474\n",
      "Training at Epoch 36 iteration 0 with loss 0.12732. Total time 2.47583 hours\n",
      "Training at Epoch 36 iteration 100 with loss 0.14667. Total time 2.48277 hours\n",
      "Training at Epoch 36 iteration 200 with loss 0.13267. Total time 2.48972 hours\n",
      "Training at Epoch 36 iteration 300 with loss 0.11983. Total time 2.49694 hours\n",
      "Training at Epoch 36 iteration 400 with loss 0.18403. Total time 2.50388 hours\n",
      "Training at Epoch 36 iteration 500 with loss 0.21348. Total time 2.51083 hours\n",
      "Training at Epoch 36 iteration 600 with loss 0.15898. Total time 2.51805 hours\n",
      "Training at Epoch 36 iteration 700 with loss 0.20036. Total time 2.525 hours\n",
      "Training at Epoch 36 iteration 800 with loss 0.14863. Total time 2.53194 hours\n",
      "Validation at Epoch 36 with loss:0.88672, MSE: 0.72609 , Pearson Correlation: 0.81767 with p-value: 0.00E+00 , Concordance Index: 0.81408\n",
      "Training at Epoch 37 iteration 0 with loss 0.14451. Total time 2.54611 hours\n",
      "Training at Epoch 37 iteration 100 with loss 0.25135. Total time 2.55305 hours\n",
      "Training at Epoch 37 iteration 200 with loss 0.11349. Total time 2.56027 hours\n",
      "Training at Epoch 37 iteration 300 with loss 0.16225. Total time 2.56722 hours\n",
      "Training at Epoch 37 iteration 400 with loss 0.13690. Total time 2.57416 hours\n",
      "Training at Epoch 37 iteration 500 with loss 0.14708. Total time 2.58138 hours\n",
      "Training at Epoch 37 iteration 600 with loss 0.16782. Total time 2.58833 hours\n",
      "Training at Epoch 37 iteration 700 with loss 0.18398. Total time 2.59555 hours\n",
      "Training at Epoch 37 iteration 800 with loss 0.16064. Total time 2.6025 hours\n",
      "Validation at Epoch 37 with loss:0.68864, MSE: 0.69998 , Pearson Correlation: 0.81830 with p-value: 0.00E+00 , Concordance Index: 0.81442\n",
      "Training at Epoch 38 iteration 0 with loss 0.13413. Total time 2.61694 hours\n",
      "Training at Epoch 38 iteration 100 with loss 0.12969. Total time 2.62388 hours\n",
      "Training at Epoch 38 iteration 200 with loss 0.17040. Total time 2.63111 hours\n",
      "Training at Epoch 38 iteration 300 with loss 0.14677. Total time 2.63805 hours\n",
      "Training at Epoch 38 iteration 400 with loss 0.13253. Total time 2.64527 hours\n",
      "Training at Epoch 38 iteration 500 with loss 0.19069. Total time 2.65222 hours\n",
      "Training at Epoch 38 iteration 600 with loss 0.20754. Total time 2.65944 hours\n",
      "Training at Epoch 38 iteration 700 with loss 0.14663. Total time 2.66638 hours\n",
      "Training at Epoch 38 iteration 800 with loss 0.15976. Total time 2.67333 hours\n",
      "Validation at Epoch 38 with loss:0.64668, MSE: 0.71438 , Pearson Correlation: 0.81910 with p-value: 0.00E+00 , Concordance Index: 0.81504\n",
      "Training at Epoch 39 iteration 0 with loss 0.15300. Total time 2.6875 hours\n",
      "Training at Epoch 39 iteration 100 with loss 0.14118. Total time 2.69472 hours\n",
      "Training at Epoch 39 iteration 200 with loss 0.15281. Total time 2.70166 hours\n",
      "Training at Epoch 39 iteration 300 with loss 0.12363. Total time 2.70888 hours\n",
      "Training at Epoch 39 iteration 400 with loss 0.13695. Total time 2.71583 hours\n",
      "Training at Epoch 39 iteration 500 with loss 0.18581. Total time 2.72305 hours\n",
      "Training at Epoch 39 iteration 600 with loss 0.15807. Total time 2.73 hours\n",
      "Training at Epoch 39 iteration 700 with loss 0.15199. Total time 2.73694 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 39 iteration 800 with loss 0.16350. Total time 2.74416 hours\n",
      "Validation at Epoch 39 with loss:0.64657, MSE: 0.71103 , Pearson Correlation: 0.81800 with p-value: 0.00E+00 , Concordance Index: 0.81386\n",
      "Training at Epoch 40 iteration 0 with loss 0.16534. Total time 2.75833 hours\n",
      "Training at Epoch 40 iteration 100 with loss 0.14211. Total time 2.76527 hours\n",
      "Training at Epoch 40 iteration 200 with loss 0.13950. Total time 2.7725 hours\n",
      "Training at Epoch 40 iteration 300 with loss 0.19743. Total time 2.77944 hours\n",
      "Training at Epoch 40 iteration 400 with loss 0.13918. Total time 2.78666 hours\n",
      "Training at Epoch 40 iteration 500 with loss 0.13969. Total time 2.79361 hours\n",
      "Training at Epoch 40 iteration 600 with loss 0.21661. Total time 2.80055 hours\n",
      "Training at Epoch 40 iteration 700 with loss 0.19133. Total time 2.80777 hours\n",
      "Training at Epoch 40 iteration 800 with loss 0.13858. Total time 2.81472 hours\n",
      "Validation at Epoch 40 with loss:0.76943, MSE: 0.72121 , Pearson Correlation: 0.81854 with p-value: 0.00E+00 , Concordance Index: 0.81454\n",
      "Training at Epoch 41 iteration 0 with loss 0.11516. Total time 2.82944 hours\n",
      "Training at Epoch 41 iteration 100 with loss 0.15546. Total time 2.83666 hours\n",
      "Training at Epoch 41 iteration 200 with loss 0.13383. Total time 2.84388 hours\n",
      "Training at Epoch 41 iteration 300 with loss 0.17099. Total time 2.85111 hours\n",
      "Training at Epoch 41 iteration 400 with loss 0.13300. Total time 2.85805 hours\n",
      "Training at Epoch 41 iteration 500 with loss 0.16747. Total time 2.865 hours\n",
      "Training at Epoch 41 iteration 600 with loss 0.13258. Total time 2.87222 hours\n",
      "Training at Epoch 41 iteration 700 with loss 0.18072. Total time 2.87916 hours\n",
      "Training at Epoch 41 iteration 800 with loss 0.11474. Total time 2.88611 hours\n",
      "Validation at Epoch 41 with loss:0.72032, MSE: 0.70696 , Pearson Correlation: 0.81892 with p-value: 0.00E+00 , Concordance Index: 0.81480\n",
      "Training at Epoch 42 iteration 0 with loss 0.14109. Total time 2.90027 hours\n",
      "Training at Epoch 42 iteration 100 with loss 0.13084. Total time 2.90722 hours\n",
      "Training at Epoch 42 iteration 200 with loss 0.18257. Total time 2.91416 hours\n",
      "Training at Epoch 42 iteration 300 with loss 0.12045. Total time 2.92111 hours\n",
      "Training at Epoch 42 iteration 400 with loss 0.12984. Total time 2.92805 hours\n",
      "Training at Epoch 42 iteration 500 with loss 0.15112. Total time 2.93527 hours\n",
      "Training at Epoch 42 iteration 600 with loss 0.13096. Total time 2.94222 hours\n",
      "Training at Epoch 42 iteration 700 with loss 0.14799. Total time 2.94916 hours\n",
      "Training at Epoch 42 iteration 800 with loss 0.17754. Total time 2.95611 hours\n",
      "Validation at Epoch 42 with loss:0.75647, MSE: 0.71249 , Pearson Correlation: 0.81944 with p-value: 0.00E+00 , Concordance Index: 0.81543\n",
      "Training at Epoch 43 iteration 0 with loss 0.14036. Total time 2.97027 hours\n",
      "Training at Epoch 43 iteration 100 with loss 0.10082. Total time 2.97722 hours\n",
      "Training at Epoch 43 iteration 200 with loss 0.15370. Total time 2.98444 hours\n",
      "Training at Epoch 43 iteration 300 with loss 0.16138. Total time 2.99166 hours\n",
      "Training at Epoch 43 iteration 400 with loss 0.14666. Total time 2.99861 hours\n",
      "Training at Epoch 43 iteration 500 with loss 0.13394. Total time 3.00583 hours\n",
      "Training at Epoch 43 iteration 600 with loss 0.14807. Total time 3.01333 hours\n",
      "Training at Epoch 43 iteration 700 with loss 0.11815. Total time 3.02055 hours\n",
      "Training at Epoch 43 iteration 800 with loss 0.18231. Total time 3.0275 hours\n",
      "Validation at Epoch 43 with loss:0.75091, MSE: 0.71518 , Pearson Correlation: 0.81916 with p-value: 0.00E+00 , Concordance Index: 0.81489\n",
      "Training at Epoch 44 iteration 0 with loss 0.09855. Total time 3.04166 hours\n",
      "Training at Epoch 44 iteration 100 with loss 0.11813. Total time 3.04888 hours\n",
      "Training at Epoch 44 iteration 200 with loss 0.10240. Total time 3.05583 hours\n",
      "Training at Epoch 44 iteration 300 with loss 0.14382. Total time 3.06277 hours\n",
      "Training at Epoch 44 iteration 400 with loss 0.09076. Total time 3.07 hours\n",
      "Training at Epoch 44 iteration 500 with loss 0.14481. Total time 3.07694 hours\n",
      "Training at Epoch 44 iteration 600 with loss 0.16972. Total time 3.08388 hours\n",
      "Training at Epoch 44 iteration 700 with loss 0.15624. Total time 3.09111 hours\n",
      "Training at Epoch 44 iteration 800 with loss 0.18038. Total time 3.09805 hours\n",
      "Validation at Epoch 44 with loss:0.55228, MSE: 0.70576 , Pearson Correlation: 0.81933 with p-value: 0.00E+00 , Concordance Index: 0.81522\n",
      "Training at Epoch 45 iteration 0 with loss 0.10086. Total time 3.1125 hours\n",
      "Training at Epoch 45 iteration 100 with loss 0.11876. Total time 3.11944 hours\n",
      "Training at Epoch 45 iteration 200 with loss 0.14152. Total time 3.12666 hours\n",
      "Training at Epoch 45 iteration 300 with loss 0.15528. Total time 3.13361 hours\n",
      "Training at Epoch 45 iteration 400 with loss 0.14910. Total time 3.14055 hours\n",
      "Training at Epoch 45 iteration 500 with loss 0.14731. Total time 3.14777 hours\n",
      "Training at Epoch 45 iteration 600 with loss 0.15526. Total time 3.155 hours\n",
      "Training at Epoch 45 iteration 700 with loss 0.14810. Total time 3.16194 hours\n",
      "Training at Epoch 45 iteration 800 with loss 0.14136. Total time 3.16916 hours\n",
      "Validation at Epoch 45 with loss:0.75199, MSE: 0.71554 , Pearson Correlation: 0.81922 with p-value: 0.00E+00 , Concordance Index: 0.81549\n",
      "Training at Epoch 46 iteration 0 with loss 0.10166. Total time 3.18305 hours\n",
      "Training at Epoch 46 iteration 100 with loss 0.11278. Total time 3.19027 hours\n",
      "Training at Epoch 46 iteration 200 with loss 0.13482. Total time 3.19722 hours\n",
      "Training at Epoch 46 iteration 300 with loss 0.13754. Total time 3.20444 hours\n",
      "Training at Epoch 46 iteration 400 with loss 0.15793. Total time 3.21138 hours\n",
      "Training at Epoch 46 iteration 500 with loss 0.13174. Total time 3.21861 hours\n",
      "Training at Epoch 46 iteration 600 with loss 0.12147. Total time 3.22583 hours\n",
      "Training at Epoch 46 iteration 700 with loss 0.19067. Total time 3.23333 hours\n",
      "Training at Epoch 46 iteration 800 with loss 0.15446. Total time 3.24055 hours\n",
      "Validation at Epoch 46 with loss:0.61733, MSE: 0.70380 , Pearson Correlation: 0.81966 with p-value: 0.00E+00 , Concordance Index: 0.81531\n",
      "Training at Epoch 47 iteration 0 with loss 0.14404. Total time 3.25527 hours\n",
      "Training at Epoch 47 iteration 100 with loss 0.14900. Total time 3.2625 hours\n",
      "Training at Epoch 47 iteration 200 with loss 0.11206. Total time 3.26972 hours\n",
      "Training at Epoch 47 iteration 300 with loss 0.13853. Total time 3.27666 hours\n",
      "Training at Epoch 47 iteration 400 with loss 0.15912. Total time 3.28388 hours\n",
      "Training at Epoch 47 iteration 500 with loss 0.10806. Total time 3.29083 hours\n",
      "Training at Epoch 47 iteration 600 with loss 0.15081. Total time 3.29805 hours\n",
      "Training at Epoch 47 iteration 700 with loss 0.12823. Total time 3.305 hours\n",
      "Training at Epoch 47 iteration 800 with loss 0.15817. Total time 3.31194 hours\n",
      "Validation at Epoch 47 with loss:0.62487, MSE: 0.69819 , Pearson Correlation: 0.81943 with p-value: 0.00E+00 , Concordance Index: 0.81554\n",
      "Training at Epoch 48 iteration 0 with loss 0.14768. Total time 3.32638 hours\n",
      "Training at Epoch 48 iteration 100 with loss 0.15558. Total time 3.33333 hours\n",
      "Training at Epoch 48 iteration 200 with loss 0.13148. Total time 3.34027 hours\n",
      "Training at Epoch 48 iteration 300 with loss 0.13524. Total time 3.3475 hours\n",
      "Training at Epoch 48 iteration 400 with loss 0.12323. Total time 3.35444 hours\n",
      "Training at Epoch 48 iteration 500 with loss 0.11439. Total time 3.36138 hours\n",
      "Training at Epoch 48 iteration 600 with loss 0.14456. Total time 3.36861 hours\n",
      "Training at Epoch 48 iteration 700 with loss 0.11900. Total time 3.37555 hours\n",
      "Training at Epoch 48 iteration 800 with loss 0.15031. Total time 3.3825 hours\n",
      "Validation at Epoch 48 with loss:0.66139, MSE: 0.70748 , Pearson Correlation: 0.81839 with p-value: 0.00E+00 , Concordance Index: 0.81517\n",
      "Training at Epoch 49 iteration 0 with loss 0.09680. Total time 3.39666 hours\n",
      "Training at Epoch 49 iteration 100 with loss 0.10648. Total time 3.40388 hours\n",
      "Training at Epoch 49 iteration 200 with loss 0.12902. Total time 3.41083 hours\n",
      "Training at Epoch 49 iteration 300 with loss 0.13516. Total time 3.41777 hours\n",
      "Training at Epoch 49 iteration 400 with loss 0.13169. Total time 3.425 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 49 iteration 500 with loss 0.12470. Total time 3.43194 hours\n",
      "Training at Epoch 49 iteration 600 with loss 0.13792. Total time 3.43916 hours\n",
      "Training at Epoch 49 iteration 700 with loss 0.10700. Total time 3.44611 hours\n",
      "Training at Epoch 49 iteration 800 with loss 0.13885. Total time 3.45305 hours\n",
      "Validation at Epoch 49 with loss:0.73087, MSE: 0.70183 , Pearson Correlation: 0.82118 with p-value: 0.00E+00 , Concordance Index: 0.81671\n",
      "Training at Epoch 50 iteration 0 with loss 0.13200. Total time 3.4675 hours\n",
      "Training at Epoch 50 iteration 100 with loss 0.13646. Total time 3.47444 hours\n",
      "Training at Epoch 50 iteration 200 with loss 0.15613. Total time 3.48166 hours\n",
      "Training at Epoch 50 iteration 300 with loss 0.09134. Total time 3.48861 hours\n",
      "Training at Epoch 50 iteration 400 with loss 0.12361. Total time 3.49555 hours\n",
      "Training at Epoch 50 iteration 500 with loss 0.13311. Total time 3.50277 hours\n",
      "Training at Epoch 50 iteration 600 with loss 0.15705. Total time 3.50972 hours\n",
      "Training at Epoch 50 iteration 700 with loss 0.13966. Total time 3.51694 hours\n",
      "Training at Epoch 50 iteration 800 with loss 0.14265. Total time 3.52388 hours\n",
      "Validation at Epoch 50 with loss:0.64715, MSE: 0.71247 , Pearson Correlation: 0.81999 with p-value: 0.00E+00 , Concordance Index: 0.81563\n",
      "Training at Epoch 51 iteration 0 with loss 0.13818. Total time 3.53833 hours\n",
      "Training at Epoch 51 iteration 100 with loss 0.11472. Total time 3.54555 hours\n",
      "Training at Epoch 51 iteration 200 with loss 0.11986. Total time 3.55305 hours\n",
      "Training at Epoch 51 iteration 300 with loss 0.11092. Total time 3.56 hours\n",
      "Training at Epoch 51 iteration 400 with loss 0.15074. Total time 3.56722 hours\n",
      "Training at Epoch 51 iteration 500 with loss 0.15351. Total time 3.57444 hours\n",
      "Training at Epoch 51 iteration 600 with loss 0.15093. Total time 3.58138 hours\n",
      "Training at Epoch 51 iteration 700 with loss 0.11106. Total time 3.58861 hours\n",
      "Training at Epoch 51 iteration 800 with loss 0.09570. Total time 3.59555 hours\n",
      "Validation at Epoch 51 with loss:0.74280, MSE: 0.71362 , Pearson Correlation: 0.81907 with p-value: 0.00E+00 , Concordance Index: 0.81547\n",
      "Training at Epoch 52 iteration 0 with loss 0.10411. Total time 3.60972 hours\n",
      "Training at Epoch 52 iteration 100 with loss 0.11783. Total time 3.61666 hours\n",
      "Training at Epoch 52 iteration 200 with loss 0.10952. Total time 3.62361 hours\n",
      "Training at Epoch 52 iteration 300 with loss 0.10787. Total time 3.63083 hours\n",
      "Training at Epoch 52 iteration 400 with loss 0.17954. Total time 3.63777 hours\n",
      "Training at Epoch 52 iteration 500 with loss 0.15120. Total time 3.64472 hours\n",
      "Training at Epoch 52 iteration 600 with loss 0.10931. Total time 3.65194 hours\n",
      "Training at Epoch 52 iteration 700 with loss 0.13466. Total time 3.65888 hours\n",
      "Training at Epoch 52 iteration 800 with loss 0.14448. Total time 3.66611 hours\n",
      "Validation at Epoch 52 with loss:0.76453, MSE: 0.71917 , Pearson Correlation: 0.81950 with p-value: 0.00E+00 , Concordance Index: 0.81552\n",
      "Training at Epoch 53 iteration 0 with loss 0.12647. Total time 3.68027 hours\n",
      "Training at Epoch 53 iteration 100 with loss 0.15766. Total time 3.68722 hours\n",
      "Training at Epoch 53 iteration 200 with loss 0.11048. Total time 3.69416 hours\n",
      "Training at Epoch 53 iteration 300 with loss 0.12648. Total time 3.70138 hours\n",
      "Training at Epoch 53 iteration 400 with loss 0.15959. Total time 3.70833 hours\n",
      "Training at Epoch 53 iteration 500 with loss 0.11977. Total time 3.71555 hours\n",
      "Training at Epoch 53 iteration 600 with loss 0.14003. Total time 3.7225 hours\n",
      "Training at Epoch 53 iteration 700 with loss 0.15213. Total time 3.72944 hours\n",
      "Training at Epoch 53 iteration 800 with loss 0.10279. Total time 3.73666 hours\n",
      "Validation at Epoch 53 with loss:0.73879, MSE: 0.70389 , Pearson Correlation: 0.81824 with p-value: 0.00E+00 , Concordance Index: 0.81558\n",
      "Training at Epoch 54 iteration 0 with loss 0.10884. Total time 3.75083 hours\n",
      "Training at Epoch 54 iteration 100 with loss 0.09625. Total time 3.75777 hours\n",
      "Training at Epoch 54 iteration 200 with loss 0.08694. Total time 3.765 hours\n",
      "Training at Epoch 54 iteration 300 with loss 0.15607. Total time 3.77194 hours\n",
      "Training at Epoch 54 iteration 400 with loss 0.13308. Total time 3.77916 hours\n",
      "Training at Epoch 54 iteration 500 with loss 0.09281. Total time 3.78611 hours\n",
      "Training at Epoch 54 iteration 600 with loss 0.15077. Total time 3.79305 hours\n",
      "Training at Epoch 54 iteration 700 with loss 0.11904. Total time 3.8 hours\n",
      "Training at Epoch 54 iteration 800 with loss 0.12661. Total time 3.80694 hours\n",
      "Validation at Epoch 54 with loss:0.78523, MSE: 0.71407 , Pearson Correlation: 0.81890 with p-value: 0.00E+00 , Concordance Index: 0.81570\n",
      "Training at Epoch 55 iteration 0 with loss 0.11623. Total time 3.82111 hours\n",
      "Training at Epoch 55 iteration 100 with loss 0.09895. Total time 3.82833 hours\n",
      "Training at Epoch 55 iteration 200 with loss 0.14367. Total time 3.83527 hours\n",
      "Training at Epoch 55 iteration 300 with loss 0.10078. Total time 3.84222 hours\n",
      "Training at Epoch 55 iteration 400 with loss 0.13078. Total time 3.84916 hours\n",
      "Training at Epoch 55 iteration 500 with loss 0.13433. Total time 3.85611 hours\n",
      "Training at Epoch 55 iteration 600 with loss 0.13124. Total time 3.86305 hours\n",
      "Training at Epoch 55 iteration 700 with loss 0.12503. Total time 3.87027 hours\n",
      "Training at Epoch 55 iteration 800 with loss 0.15673. Total time 3.87722 hours\n",
      "Validation at Epoch 55 with loss:0.70859, MSE: 0.70571 , Pearson Correlation: 0.82018 with p-value: 0.00E+00 , Concordance Index: 0.81610\n",
      "Training at Epoch 56 iteration 0 with loss 0.10124. Total time 3.89138 hours\n",
      "Training at Epoch 56 iteration 100 with loss 0.11166. Total time 3.89833 hours\n",
      "Training at Epoch 56 iteration 200 with loss 0.10496. Total time 3.90527 hours\n",
      "Training at Epoch 56 iteration 300 with loss 0.09785. Total time 3.91222 hours\n",
      "Training at Epoch 56 iteration 400 with loss 0.11547. Total time 3.91916 hours\n",
      "Training at Epoch 56 iteration 500 with loss 0.11799. Total time 3.92638 hours\n",
      "Training at Epoch 56 iteration 600 with loss 0.11025. Total time 3.93333 hours\n",
      "Training at Epoch 56 iteration 700 with loss 0.14925. Total time 3.94027 hours\n",
      "Training at Epoch 56 iteration 800 with loss 0.13005. Total time 3.9475 hours\n",
      "Validation at Epoch 56 with loss:0.85050, MSE: 0.70420 , Pearson Correlation: 0.81985 with p-value: 0.00E+00 , Concordance Index: 0.81627\n",
      "Training at Epoch 57 iteration 0 with loss 0.10051. Total time 3.96166 hours\n",
      "Training at Epoch 57 iteration 100 with loss 0.09627. Total time 3.96861 hours\n",
      "Training at Epoch 57 iteration 200 with loss 0.15563. Total time 3.97555 hours\n",
      "Training at Epoch 57 iteration 300 with loss 0.10660. Total time 3.98277 hours\n",
      "Training at Epoch 57 iteration 400 with loss 0.13556. Total time 3.98972 hours\n",
      "Training at Epoch 57 iteration 500 with loss 0.12496. Total time 3.99666 hours\n",
      "Training at Epoch 57 iteration 600 with loss 0.14209. Total time 4.00388 hours\n",
      "Training at Epoch 57 iteration 700 with loss 0.10553. Total time 4.01083 hours\n",
      "Training at Epoch 57 iteration 800 with loss 0.11793. Total time 4.01805 hours\n",
      "Validation at Epoch 57 with loss:0.64660, MSE: 0.70692 , Pearson Correlation: 0.82030 with p-value: 0.00E+00 , Concordance Index: 0.81637\n",
      "Training at Epoch 58 iteration 0 with loss 0.11136. Total time 4.03194 hours\n",
      "Training at Epoch 58 iteration 100 with loss 0.09011. Total time 4.03916 hours\n",
      "Training at Epoch 58 iteration 200 with loss 0.17347. Total time 4.04611 hours\n",
      "Training at Epoch 58 iteration 300 with loss 0.09981. Total time 4.05305 hours\n",
      "Training at Epoch 58 iteration 400 with loss 0.11357. Total time 4.06027 hours\n",
      "Training at Epoch 58 iteration 500 with loss 0.09210. Total time 4.06722 hours\n",
      "Training at Epoch 58 iteration 600 with loss 0.10697. Total time 4.07444 hours\n",
      "Training at Epoch 58 iteration 700 with loss 0.11069. Total time 4.08138 hours\n",
      "Training at Epoch 58 iteration 800 with loss 0.07296. Total time 4.08861 hours\n",
      "Validation at Epoch 58 with loss:0.64298, MSE: 0.69316 , Pearson Correlation: 0.82032 with p-value: 0.00E+00 , Concordance Index: 0.81626\n",
      "Training at Epoch 59 iteration 0 with loss 0.11039. Total time 4.10277 hours\n",
      "Training at Epoch 59 iteration 100 with loss 0.08859. Total time 4.10972 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 59 iteration 200 with loss 0.14129. Total time 4.11666 hours\n",
      "Training at Epoch 59 iteration 300 with loss 0.11066. Total time 4.12388 hours\n",
      "Training at Epoch 59 iteration 400 with loss 0.13655. Total time 4.13111 hours\n",
      "Training at Epoch 59 iteration 500 with loss 0.09517. Total time 4.13833 hours\n",
      "Training at Epoch 59 iteration 600 with loss 0.11143. Total time 4.14527 hours\n",
      "Training at Epoch 59 iteration 700 with loss 0.08504. Total time 4.1525 hours\n",
      "Training at Epoch 59 iteration 800 with loss 0.13237. Total time 4.15944 hours\n",
      "Validation at Epoch 59 with loss:0.70321, MSE: 0.69899 , Pearson Correlation: 0.82021 with p-value: 0.00E+00 , Concordance Index: 0.81605\n",
      "Training at Epoch 60 iteration 0 with loss 0.10487. Total time 4.17361 hours\n",
      "Training at Epoch 60 iteration 100 with loss 0.08572. Total time 4.18083 hours\n",
      "Training at Epoch 60 iteration 200 with loss 0.17532. Total time 4.18777 hours\n",
      "Training at Epoch 60 iteration 300 with loss 0.09446. Total time 4.195 hours\n",
      "Training at Epoch 60 iteration 400 with loss 0.12005. Total time 4.20194 hours\n",
      "Training at Epoch 60 iteration 500 with loss 0.10562. Total time 4.20916 hours\n",
      "Training at Epoch 60 iteration 600 with loss 0.10872. Total time 4.21611 hours\n",
      "Training at Epoch 60 iteration 700 with loss 0.09719. Total time 4.22333 hours\n",
      "Training at Epoch 60 iteration 800 with loss 0.15243. Total time 4.23027 hours\n",
      "Validation at Epoch 60 with loss:0.69184, MSE: 0.70836 , Pearson Correlation: 0.81965 with p-value: 0.00E+00 , Concordance Index: 0.81624\n",
      "Training at Epoch 61 iteration 0 with loss 0.10411. Total time 4.24444 hours\n",
      "Training at Epoch 61 iteration 100 with loss 0.11612. Total time 4.25166 hours\n",
      "Training at Epoch 61 iteration 200 with loss 0.08765. Total time 4.25861 hours\n",
      "Training at Epoch 61 iteration 300 with loss 0.12936. Total time 4.26583 hours\n",
      "Training at Epoch 61 iteration 400 with loss 0.13634. Total time 4.27277 hours\n",
      "Training at Epoch 61 iteration 500 with loss 0.12805. Total time 4.28 hours\n",
      "Training at Epoch 61 iteration 600 with loss 0.17146. Total time 4.28694 hours\n",
      "Training at Epoch 61 iteration 700 with loss 0.11230. Total time 4.29416 hours\n",
      "Training at Epoch 61 iteration 800 with loss 0.09578. Total time 4.30111 hours\n",
      "Validation at Epoch 61 with loss:0.74153, MSE: 0.71529 , Pearson Correlation: 0.81957 with p-value: 0.00E+00 , Concordance Index: 0.81607\n",
      "Training at Epoch 62 iteration 0 with loss 0.14603. Total time 4.31555 hours\n",
      "Training at Epoch 62 iteration 100 with loss 0.12172. Total time 4.3225 hours\n",
      "Training at Epoch 62 iteration 200 with loss 0.09689. Total time 4.32972 hours\n",
      "Training at Epoch 62 iteration 300 with loss 0.07703. Total time 4.33666 hours\n",
      "Training at Epoch 62 iteration 400 with loss 0.09946. Total time 4.34361 hours\n",
      "Training at Epoch 62 iteration 500 with loss 0.09101. Total time 4.35083 hours\n",
      "Training at Epoch 62 iteration 600 with loss 0.12834. Total time 4.35777 hours\n",
      "Training at Epoch 62 iteration 700 with loss 0.10790. Total time 4.365 hours\n",
      "Training at Epoch 62 iteration 800 with loss 0.08625. Total time 4.37194 hours\n",
      "Validation at Epoch 62 with loss:0.68496, MSE: 0.70369 , Pearson Correlation: 0.82075 with p-value: 0.00E+00 , Concordance Index: 0.81675\n",
      "Training at Epoch 63 iteration 0 with loss 0.10445. Total time 4.38611 hours\n",
      "Training at Epoch 63 iteration 100 with loss 0.09874. Total time 4.39305 hours\n",
      "Training at Epoch 63 iteration 200 with loss 0.13069. Total time 4.4 hours\n",
      "Training at Epoch 63 iteration 300 with loss 0.09645. Total time 4.40722 hours\n",
      "Training at Epoch 63 iteration 400 with loss 0.10528. Total time 4.41416 hours\n",
      "Training at Epoch 63 iteration 500 with loss 0.11932. Total time 4.42111 hours\n",
      "Training at Epoch 63 iteration 600 with loss 0.09116. Total time 4.42805 hours\n",
      "Training at Epoch 63 iteration 700 with loss 0.09971. Total time 4.43527 hours\n",
      "Training at Epoch 63 iteration 800 with loss 0.12636. Total time 4.44222 hours\n",
      "Validation at Epoch 63 with loss:0.69887, MSE: 0.70760 , Pearson Correlation: 0.82046 with p-value: 0.00E+00 , Concordance Index: 0.81682\n",
      "Training at Epoch 64 iteration 0 with loss 0.08373. Total time 4.45638 hours\n",
      "Training at Epoch 64 iteration 100 with loss 0.11891. Total time 4.46361 hours\n",
      "Training at Epoch 64 iteration 200 with loss 0.08344. Total time 4.47111 hours\n",
      "Training at Epoch 64 iteration 300 with loss 0.10812. Total time 4.47833 hours\n",
      "Training at Epoch 64 iteration 400 with loss 0.13785. Total time 4.48555 hours\n",
      "Training at Epoch 64 iteration 500 with loss 0.10968. Total time 4.49305 hours\n",
      "Training at Epoch 64 iteration 600 with loss 0.10895. Total time 4.50027 hours\n",
      "Training at Epoch 64 iteration 700 with loss 0.13824. Total time 4.5075 hours\n",
      "Training at Epoch 64 iteration 800 with loss 0.12911. Total time 4.51472 hours\n",
      "Validation at Epoch 64 with loss:0.79981, MSE: 0.71417 , Pearson Correlation: 0.82055 with p-value: 0.00E+00 , Concordance Index: 0.81665\n",
      "Training at Epoch 65 iteration 0 with loss 0.09840. Total time 4.52916 hours\n",
      "Training at Epoch 65 iteration 100 with loss 0.11653. Total time 4.53611 hours\n",
      "Training at Epoch 65 iteration 200 with loss 0.10162. Total time 4.54305 hours\n",
      "Training at Epoch 65 iteration 300 with loss 0.12511. Total time 4.55 hours\n",
      "Training at Epoch 65 iteration 400 with loss 0.11985. Total time 4.55722 hours\n",
      "Training at Epoch 65 iteration 500 with loss 0.07213. Total time 4.56444 hours\n",
      "Training at Epoch 65 iteration 600 with loss 0.10956. Total time 4.57166 hours\n",
      "Training at Epoch 65 iteration 700 with loss 0.11807. Total time 4.57888 hours\n",
      "Training at Epoch 65 iteration 800 with loss 0.11147. Total time 4.58611 hours\n",
      "Validation at Epoch 65 with loss:0.68084, MSE: 0.70568 , Pearson Correlation: 0.82076 with p-value: 0.00E+00 , Concordance Index: 0.81711\n",
      "Training at Epoch 66 iteration 0 with loss 0.11231. Total time 4.60083 hours\n",
      "Training at Epoch 66 iteration 100 with loss 0.12767. Total time 4.60777 hours\n",
      "Training at Epoch 66 iteration 200 with loss 0.13126. Total time 4.61472 hours\n",
      "Training at Epoch 66 iteration 300 with loss 0.10554. Total time 4.62194 hours\n",
      "Training at Epoch 66 iteration 400 with loss 0.08388. Total time 4.62888 hours\n",
      "Training at Epoch 66 iteration 500 with loss 0.09698. Total time 4.63611 hours\n",
      "Training at Epoch 66 iteration 600 with loss 0.11179. Total time 4.64333 hours\n",
      "Training at Epoch 66 iteration 700 with loss 0.13369. Total time 4.65027 hours\n",
      "Training at Epoch 66 iteration 800 with loss 0.15077. Total time 4.65722 hours\n",
      "Validation at Epoch 66 with loss:0.51063, MSE: 0.69919 , Pearson Correlation: 0.82081 with p-value: 0.00E+00 , Concordance Index: 0.81679\n",
      "Training at Epoch 67 iteration 0 with loss 0.10026. Total time 4.67166 hours\n",
      "Training at Epoch 67 iteration 100 with loss 0.09915. Total time 4.67861 hours\n",
      "Training at Epoch 67 iteration 200 with loss 0.13900. Total time 4.68555 hours\n",
      "Training at Epoch 67 iteration 300 with loss 0.12334. Total time 4.6925 hours\n",
      "Training at Epoch 67 iteration 400 with loss 0.09134. Total time 4.69944 hours\n",
      "Training at Epoch 67 iteration 500 with loss 0.13502. Total time 4.70666 hours\n",
      "Training at Epoch 67 iteration 600 with loss 0.09407. Total time 4.71361 hours\n",
      "Training at Epoch 67 iteration 700 with loss 0.09462. Total time 4.72055 hours\n",
      "Training at Epoch 67 iteration 800 with loss 0.11759. Total time 4.7275 hours\n",
      "Validation at Epoch 67 with loss:0.79899, MSE: 0.71285 , Pearson Correlation: 0.81946 with p-value: 0.00E+00 , Concordance Index: 0.81672\n",
      "Training at Epoch 68 iteration 0 with loss 0.08166. Total time 4.74166 hours\n",
      "Training at Epoch 68 iteration 100 with loss 0.08858. Total time 4.74888 hours\n",
      "Training at Epoch 68 iteration 200 with loss 0.09070. Total time 4.75583 hours\n",
      "Training at Epoch 68 iteration 300 with loss 0.09054. Total time 4.76277 hours\n",
      "Training at Epoch 68 iteration 400 with loss 0.10444. Total time 4.77 hours\n",
      "Training at Epoch 68 iteration 500 with loss 0.07864. Total time 4.77694 hours\n",
      "Training at Epoch 68 iteration 600 with loss 0.08677. Total time 4.78388 hours\n",
      "Training at Epoch 68 iteration 700 with loss 0.11915. Total time 4.79111 hours\n",
      "Training at Epoch 68 iteration 800 with loss 0.09427. Total time 4.79805 hours\n",
      "Validation at Epoch 68 with loss:0.62184, MSE: 0.71186 , Pearson Correlation: 0.82078 with p-value: 0.00E+00 , Concordance Index: 0.81720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 69 iteration 0 with loss 0.09069. Total time 4.81277 hours\n",
      "Training at Epoch 69 iteration 100 with loss 0.08286. Total time 4.81972 hours\n",
      "Training at Epoch 69 iteration 200 with loss 0.09723. Total time 4.82666 hours\n",
      "Training at Epoch 69 iteration 300 with loss 0.10390. Total time 4.83388 hours\n",
      "Training at Epoch 69 iteration 400 with loss 0.12288. Total time 4.84111 hours\n",
      "Training at Epoch 69 iteration 500 with loss 0.10990. Total time 4.84805 hours\n",
      "Training at Epoch 69 iteration 600 with loss 0.10462. Total time 4.85527 hours\n",
      "Training at Epoch 69 iteration 700 with loss 0.09034. Total time 4.86222 hours\n",
      "Training at Epoch 69 iteration 800 with loss 0.11665. Total time 4.86916 hours\n",
      "Validation at Epoch 69 with loss:0.72146, MSE: 0.69065 , Pearson Correlation: 0.82234 with p-value: 0.00E+00 , Concordance Index: 0.81771\n",
      "Training at Epoch 70 iteration 0 with loss 0.12071. Total time 4.88333 hours\n",
      "Training at Epoch 70 iteration 100 with loss 0.07450. Total time 4.89027 hours\n",
      "Training at Epoch 70 iteration 200 with loss 0.11777. Total time 4.8975 hours\n",
      "Training at Epoch 70 iteration 300 with loss 0.11187. Total time 4.90444 hours\n",
      "Training at Epoch 70 iteration 400 with loss 0.10378. Total time 4.91138 hours\n",
      "Training at Epoch 70 iteration 500 with loss 0.09121. Total time 4.91861 hours\n",
      "Training at Epoch 70 iteration 600 with loss 0.10543. Total time 4.92555 hours\n",
      "Training at Epoch 70 iteration 700 with loss 0.09048. Total time 4.9325 hours\n",
      "Training at Epoch 70 iteration 800 with loss 0.10059. Total time 4.93972 hours\n",
      "Validation at Epoch 70 with loss:0.56640, MSE: 0.69827 , Pearson Correlation: 0.82033 with p-value: 0.00E+00 , Concordance Index: 0.81680\n",
      "Training at Epoch 71 iteration 0 with loss 0.08215. Total time 4.95416 hours\n",
      "Training at Epoch 71 iteration 100 with loss 0.10376. Total time 4.96111 hours\n",
      "Training at Epoch 71 iteration 200 with loss 0.08236. Total time 4.96833 hours\n",
      "Training at Epoch 71 iteration 300 with loss 0.08762. Total time 4.97527 hours\n",
      "Training at Epoch 71 iteration 400 with loss 0.10735. Total time 4.98222 hours\n",
      "Training at Epoch 71 iteration 500 with loss 0.08950. Total time 4.98944 hours\n",
      "Training at Epoch 71 iteration 600 with loss 0.10506. Total time 4.99638 hours\n",
      "Training at Epoch 71 iteration 700 with loss 0.14502. Total time 5.00361 hours\n",
      "Training at Epoch 71 iteration 800 with loss 0.11159. Total time 5.01055 hours\n",
      "Validation at Epoch 71 with loss:0.64340, MSE: 0.69521 , Pearson Correlation: 0.82046 with p-value: 0.00E+00 , Concordance Index: 0.81713\n",
      "Training at Epoch 72 iteration 0 with loss 0.06325. Total time 5.02527 hours\n",
      "Training at Epoch 72 iteration 100 with loss 0.07706. Total time 5.0325 hours\n",
      "Training at Epoch 72 iteration 200 with loss 0.07985. Total time 5.04 hours\n",
      "Training at Epoch 72 iteration 300 with loss 0.10832. Total time 5.04722 hours\n",
      "Training at Epoch 72 iteration 400 with loss 0.11915. Total time 5.05444 hours\n",
      "Training at Epoch 72 iteration 500 with loss 0.10073. Total time 5.06194 hours\n",
      "Training at Epoch 72 iteration 600 with loss 0.06656. Total time 5.06888 hours\n",
      "Training at Epoch 72 iteration 700 with loss 0.08217. Total time 5.07583 hours\n",
      "Training at Epoch 72 iteration 800 with loss 0.15817. Total time 5.08277 hours\n",
      "Validation at Epoch 72 with loss:0.73406, MSE: 0.71061 , Pearson Correlation: 0.82020 with p-value: 0.00E+00 , Concordance Index: 0.81630\n",
      "Training at Epoch 73 iteration 0 with loss 0.08850. Total time 5.09694 hours\n",
      "Training at Epoch 73 iteration 100 with loss 0.10694. Total time 5.10388 hours\n",
      "Training at Epoch 73 iteration 200 with loss 0.09120. Total time 5.11111 hours\n",
      "Training at Epoch 73 iteration 300 with loss 0.09642. Total time 5.11805 hours\n",
      "Training at Epoch 73 iteration 400 with loss 0.09673. Total time 5.125 hours\n",
      "Training at Epoch 73 iteration 500 with loss 0.09975. Total time 5.13222 hours\n",
      "Training at Epoch 73 iteration 600 with loss 0.08714. Total time 5.13916 hours\n",
      "Training at Epoch 73 iteration 700 with loss 0.09471. Total time 5.14638 hours\n",
      "Training at Epoch 73 iteration 800 with loss 0.09473. Total time 5.15361 hours\n",
      "Validation at Epoch 73 with loss:0.74895, MSE: 0.70324 , Pearson Correlation: 0.82055 with p-value: 0.00E+00 , Concordance Index: 0.81680\n",
      "Training at Epoch 74 iteration 0 with loss 0.08166. Total time 5.16777 hours\n",
      "Training at Epoch 74 iteration 100 with loss 0.08878. Total time 5.17472 hours\n",
      "Training at Epoch 74 iteration 200 with loss 0.10863. Total time 5.18194 hours\n",
      "Training at Epoch 74 iteration 300 with loss 0.07450. Total time 5.18888 hours\n",
      "Training at Epoch 74 iteration 400 with loss 0.08311. Total time 5.19611 hours\n",
      "Training at Epoch 74 iteration 500 with loss 0.11833. Total time 5.20305 hours\n",
      "Training at Epoch 74 iteration 600 with loss 0.08615. Total time 5.21027 hours\n",
      "Training at Epoch 74 iteration 700 with loss 0.09900. Total time 5.21722 hours\n",
      "Training at Epoch 74 iteration 800 with loss 0.09865. Total time 5.22444 hours\n",
      "Validation at Epoch 74 with loss:0.62386, MSE: 0.70692 , Pearson Correlation: 0.82165 with p-value: 0.00E+00 , Concordance Index: 0.81725\n",
      "Training at Epoch 75 iteration 0 with loss 0.08924. Total time 5.23888 hours\n",
      "Training at Epoch 75 iteration 100 with loss 0.09546. Total time 5.24583 hours\n",
      "Training at Epoch 75 iteration 200 with loss 0.07894. Total time 5.25277 hours\n",
      "Training at Epoch 75 iteration 300 with loss 0.10835. Total time 5.26 hours\n",
      "Training at Epoch 75 iteration 400 with loss 0.14018. Total time 5.26722 hours\n",
      "Training at Epoch 75 iteration 500 with loss 0.09909. Total time 5.27416 hours\n",
      "Training at Epoch 75 iteration 600 with loss 0.08250. Total time 5.28138 hours\n",
      "Training at Epoch 75 iteration 700 with loss 0.10076. Total time 5.28861 hours\n",
      "Training at Epoch 75 iteration 800 with loss 0.13422. Total time 5.29583 hours\n",
      "Validation at Epoch 75 with loss:0.69552, MSE: 0.69820 , Pearson Correlation: 0.81966 with p-value: 0.00E+00 , Concordance Index: 0.81592\n",
      "Training at Epoch 76 iteration 0 with loss 0.11021. Total time 5.31 hours\n",
      "Training at Epoch 76 iteration 100 with loss 0.09795. Total time 5.31722 hours\n",
      "Training at Epoch 76 iteration 200 with loss 0.12044. Total time 5.32444 hours\n",
      "Training at Epoch 76 iteration 300 with loss 0.10758. Total time 5.33166 hours\n",
      "Training at Epoch 76 iteration 400 with loss 0.07922. Total time 5.33888 hours\n",
      "Training at Epoch 76 iteration 500 with loss 0.07891. Total time 5.34583 hours\n",
      "Training at Epoch 76 iteration 600 with loss 0.10756. Total time 5.35305 hours\n",
      "Training at Epoch 76 iteration 700 with loss 0.09319. Total time 5.36 hours\n",
      "Training at Epoch 76 iteration 800 with loss 0.07694. Total time 5.36722 hours\n",
      "Validation at Epoch 76 with loss:0.76414, MSE: 0.70851 , Pearson Correlation: 0.82012 with p-value: 0.00E+00 , Concordance Index: 0.81639\n",
      "Training at Epoch 77 iteration 0 with loss 0.07775. Total time 5.38166 hours\n",
      "Training at Epoch 77 iteration 100 with loss 0.08939. Total time 5.38861 hours\n",
      "Training at Epoch 77 iteration 200 with loss 0.10861. Total time 5.39583 hours\n",
      "Training at Epoch 77 iteration 300 with loss 0.09423. Total time 5.40277 hours\n",
      "Training at Epoch 77 iteration 400 with loss 0.09901. Total time 5.41 hours\n",
      "Training at Epoch 77 iteration 500 with loss 0.08007. Total time 5.41694 hours\n",
      "Training at Epoch 77 iteration 600 with loss 0.13079. Total time 5.42388 hours\n",
      "Training at Epoch 77 iteration 700 with loss 0.11131. Total time 5.43083 hours\n",
      "Training at Epoch 77 iteration 800 with loss 0.11166. Total time 5.43805 hours\n",
      "Validation at Epoch 77 with loss:0.53672, MSE: 0.71324 , Pearson Correlation: 0.82071 with p-value: 0.00E+00 , Concordance Index: 0.81692\n",
      "Training at Epoch 78 iteration 0 with loss 0.07928. Total time 5.45222 hours\n",
      "Training at Epoch 78 iteration 100 with loss 0.07492. Total time 5.45916 hours\n",
      "Training at Epoch 78 iteration 200 with loss 0.06261. Total time 5.46638 hours\n",
      "Training at Epoch 78 iteration 300 with loss 0.07777. Total time 5.47333 hours\n",
      "Training at Epoch 78 iteration 400 with loss 0.07308. Total time 5.48055 hours\n",
      "Training at Epoch 78 iteration 500 with loss 0.09688. Total time 5.4875 hours\n",
      "Training at Epoch 78 iteration 600 with loss 0.10934. Total time 5.49444 hours\n",
      "Training at Epoch 78 iteration 700 with loss 0.12798. Total time 5.50166 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 78 iteration 800 with loss 0.12950. Total time 5.50861 hours\n",
      "Validation at Epoch 78 with loss:0.66235, MSE: 0.69698 , Pearson Correlation: 0.82049 with p-value: 0.00E+00 , Concordance Index: 0.81684\n",
      "Training at Epoch 79 iteration 0 with loss 0.07505. Total time 5.52277 hours\n",
      "Training at Epoch 79 iteration 100 with loss 0.09727. Total time 5.52972 hours\n",
      "Training at Epoch 79 iteration 200 with loss 0.09323. Total time 5.53694 hours\n",
      "Training at Epoch 79 iteration 300 with loss 0.10662. Total time 5.54388 hours\n",
      "Training at Epoch 79 iteration 400 with loss 0.08975. Total time 5.55083 hours\n",
      "Training at Epoch 79 iteration 500 with loss 0.07569. Total time 5.55777 hours\n",
      "Training at Epoch 79 iteration 600 with loss 0.09669. Total time 5.565 hours\n",
      "Training at Epoch 79 iteration 700 with loss 0.09106. Total time 5.57194 hours\n",
      "Training at Epoch 79 iteration 800 with loss 0.11656. Total time 5.57888 hours\n",
      "Validation at Epoch 79 with loss:0.66526, MSE: 0.69479 , Pearson Correlation: 0.82133 with p-value: 0.00E+00 , Concordance Index: 0.81727\n",
      "Training at Epoch 80 iteration 0 with loss 0.07386. Total time 5.59305 hours\n",
      "Training at Epoch 80 iteration 100 with loss 0.09165. Total time 5.60027 hours\n",
      "Training at Epoch 80 iteration 200 with loss 0.11019. Total time 5.60722 hours\n",
      "Training at Epoch 80 iteration 300 with loss 0.07954. Total time 5.61416 hours\n",
      "Training at Epoch 80 iteration 400 with loss 0.08102. Total time 5.62111 hours\n",
      "Training at Epoch 80 iteration 500 with loss 0.06489. Total time 5.62833 hours\n",
      "Training at Epoch 80 iteration 600 with loss 0.08977. Total time 5.63527 hours\n",
      "Training at Epoch 80 iteration 700 with loss 0.10136. Total time 5.64222 hours\n",
      "Training at Epoch 80 iteration 800 with loss 0.07775. Total time 5.64916 hours\n",
      "Validation at Epoch 80 with loss:0.78337, MSE: 0.69589 , Pearson Correlation: 0.82148 with p-value: 0.00E+00 , Concordance Index: 0.81722\n",
      "Training at Epoch 81 iteration 0 with loss 0.06195. Total time 5.66333 hours\n",
      "Training at Epoch 81 iteration 100 with loss 0.08361. Total time 5.67027 hours\n",
      "Training at Epoch 81 iteration 200 with loss 0.10003. Total time 5.6775 hours\n",
      "Training at Epoch 81 iteration 300 with loss 0.08185. Total time 5.68444 hours\n",
      "Training at Epoch 81 iteration 400 with loss 0.07251. Total time 5.69138 hours\n",
      "Training at Epoch 81 iteration 500 with loss 0.09839. Total time 5.69861 hours\n",
      "Training at Epoch 81 iteration 600 with loss 0.08855. Total time 5.70555 hours\n",
      "Training at Epoch 81 iteration 700 with loss 0.11604. Total time 5.7125 hours\n",
      "Training at Epoch 81 iteration 800 with loss 0.08607. Total time 5.71972 hours\n",
      "Validation at Epoch 81 with loss:0.56680, MSE: 0.70438 , Pearson Correlation: 0.82015 with p-value: 0.00E+00 , Concordance Index: 0.81667\n",
      "Training at Epoch 82 iteration 0 with loss 0.06041. Total time 5.73388 hours\n",
      "Training at Epoch 82 iteration 100 with loss 0.08291. Total time 5.74083 hours\n",
      "Training at Epoch 82 iteration 200 with loss 0.09675. Total time 5.74777 hours\n",
      "Training at Epoch 82 iteration 300 with loss 0.07067. Total time 5.75472 hours\n",
      "Training at Epoch 82 iteration 400 with loss 0.06501. Total time 5.76194 hours\n",
      "Training at Epoch 82 iteration 500 with loss 0.09942. Total time 5.76888 hours\n",
      "Training at Epoch 82 iteration 600 with loss 0.09093. Total time 5.77583 hours\n",
      "Training at Epoch 82 iteration 700 with loss 0.09241. Total time 5.78277 hours\n",
      "Training at Epoch 82 iteration 800 with loss 0.08760. Total time 5.78972 hours\n",
      "Validation at Epoch 82 with loss:0.56397, MSE: 0.69457 , Pearson Correlation: 0.82081 with p-value: 0.00E+00 , Concordance Index: 0.81739\n",
      "Training at Epoch 83 iteration 0 with loss 0.08101. Total time 5.80388 hours\n",
      "Training at Epoch 83 iteration 100 with loss 0.09307. Total time 5.81083 hours\n",
      "Training at Epoch 83 iteration 200 with loss 0.13626. Total time 5.81777 hours\n",
      "Training at Epoch 83 iteration 300 with loss 0.07042. Total time 5.825 hours\n",
      "Training at Epoch 83 iteration 400 with loss 0.09827. Total time 5.83194 hours\n",
      "Training at Epoch 83 iteration 500 with loss 0.08156. Total time 5.83888 hours\n",
      "Training at Epoch 83 iteration 600 with loss 0.09347. Total time 5.84611 hours\n",
      "Training at Epoch 83 iteration 700 with loss 0.09216. Total time 5.85333 hours\n",
      "Training at Epoch 83 iteration 800 with loss 0.11178. Total time 5.86027 hours\n",
      "Validation at Epoch 83 with loss:0.78927, MSE: 0.70973 , Pearson Correlation: 0.81997 with p-value: 0.00E+00 , Concordance Index: 0.81664\n",
      "Training at Epoch 84 iteration 0 with loss 0.06082. Total time 5.87444 hours\n",
      "Training at Epoch 84 iteration 100 with loss 0.07535. Total time 5.88166 hours\n",
      "Training at Epoch 84 iteration 200 with loss 0.05455. Total time 5.88861 hours\n",
      "Training at Epoch 84 iteration 300 with loss 0.07269. Total time 5.89555 hours\n",
      "Training at Epoch 84 iteration 400 with loss 0.07600. Total time 5.90277 hours\n",
      "Training at Epoch 84 iteration 500 with loss 0.10881. Total time 5.90972 hours\n",
      "Training at Epoch 84 iteration 600 with loss 0.08506. Total time 5.91666 hours\n",
      "Training at Epoch 84 iteration 700 with loss 0.09620. Total time 5.92388 hours\n",
      "Training at Epoch 84 iteration 800 with loss 0.10543. Total time 5.93083 hours\n",
      "Validation at Epoch 84 with loss:0.56523, MSE: 0.71193 , Pearson Correlation: 0.82086 with p-value: 0.00E+00 , Concordance Index: 0.81690\n",
      "Training at Epoch 85 iteration 0 with loss 0.08835. Total time 5.945 hours\n",
      "Training at Epoch 85 iteration 100 with loss 0.07978. Total time 5.95194 hours\n",
      "Training at Epoch 85 iteration 200 with loss 0.08314. Total time 5.95916 hours\n",
      "Training at Epoch 85 iteration 300 with loss 0.09399. Total time 5.96611 hours\n",
      "Training at Epoch 85 iteration 400 with loss 0.14837. Total time 5.97333 hours\n",
      "Training at Epoch 85 iteration 500 with loss 0.08084. Total time 5.98027 hours\n",
      "Training at Epoch 85 iteration 600 with loss 0.06490. Total time 5.9875 hours\n",
      "Training at Epoch 85 iteration 700 with loss 0.09706. Total time 5.99444 hours\n",
      "Training at Epoch 85 iteration 800 with loss 0.07693. Total time 6.00166 hours\n",
      "Validation at Epoch 85 with loss:0.66699, MSE: 0.70257 , Pearson Correlation: 0.82072 with p-value: 0.00E+00 , Concordance Index: 0.81738\n",
      "Training at Epoch 86 iteration 0 with loss 0.06667. Total time 6.01583 hours\n",
      "Training at Epoch 86 iteration 100 with loss 0.06386. Total time 6.02305 hours\n",
      "Training at Epoch 86 iteration 200 with loss 0.09548. Total time 6.03 hours\n",
      "Training at Epoch 86 iteration 300 with loss 0.13264. Total time 6.03694 hours\n",
      "Training at Epoch 86 iteration 400 with loss 0.06422. Total time 6.04388 hours\n",
      "Training at Epoch 86 iteration 500 with loss 0.09438. Total time 6.05111 hours\n",
      "Training at Epoch 86 iteration 600 with loss 0.10706. Total time 6.05805 hours\n",
      "Training at Epoch 86 iteration 700 with loss 0.10433. Total time 6.065 hours\n",
      "Training at Epoch 86 iteration 800 with loss 0.11563. Total time 6.07222 hours\n",
      "Validation at Epoch 86 with loss:0.73180, MSE: 0.70669 , Pearson Correlation: 0.81934 with p-value: 0.00E+00 , Concordance Index: 0.81639\n",
      "Training at Epoch 87 iteration 0 with loss 0.07051. Total time 6.08638 hours\n",
      "Training at Epoch 87 iteration 100 with loss 0.08269. Total time 6.09333 hours\n",
      "Training at Epoch 87 iteration 200 with loss 0.07837. Total time 6.10027 hours\n",
      "Training at Epoch 87 iteration 300 with loss 0.06914. Total time 6.1075 hours\n",
      "Training at Epoch 87 iteration 400 with loss 0.08150. Total time 6.11444 hours\n",
      "Training at Epoch 87 iteration 500 with loss 0.05420. Total time 6.12138 hours\n",
      "Training at Epoch 87 iteration 600 with loss 0.09463. Total time 6.12861 hours\n",
      "Training at Epoch 87 iteration 700 with loss 0.08757. Total time 6.13555 hours\n",
      "Training at Epoch 87 iteration 800 with loss 0.09617. Total time 6.1425 hours\n",
      "Validation at Epoch 87 with loss:0.68826, MSE: 0.70187 , Pearson Correlation: 0.82040 with p-value: 0.00E+00 , Concordance Index: 0.81708\n",
      "Training at Epoch 88 iteration 0 with loss 0.08323. Total time 6.15694 hours\n",
      "Training at Epoch 88 iteration 100 with loss 0.08825. Total time 6.16388 hours\n",
      "Training at Epoch 88 iteration 200 with loss 0.07682. Total time 6.17111 hours\n",
      "Training at Epoch 88 iteration 300 with loss 0.09477. Total time 6.17805 hours\n",
      "Training at Epoch 88 iteration 400 with loss 0.08336. Total time 6.18527 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 88 iteration 500 with loss 0.09108. Total time 6.1925 hours\n",
      "Training at Epoch 88 iteration 600 with loss 0.09882. Total time 6.19944 hours\n",
      "Training at Epoch 88 iteration 700 with loss 0.13781. Total time 6.20666 hours\n",
      "Training at Epoch 88 iteration 800 with loss 0.07250. Total time 6.21361 hours\n",
      "Validation at Epoch 88 with loss:0.71176, MSE: 0.70825 , Pearson Correlation: 0.82012 with p-value: 0.00E+00 , Concordance Index: 0.81678\n",
      "Training at Epoch 89 iteration 0 with loss 0.06242. Total time 6.22777 hours\n",
      "Training at Epoch 89 iteration 100 with loss 0.08279. Total time 6.235 hours\n",
      "Training at Epoch 89 iteration 200 with loss 0.05234. Total time 6.24194 hours\n",
      "Training at Epoch 89 iteration 300 with loss 0.08764. Total time 6.24916 hours\n",
      "Training at Epoch 89 iteration 400 with loss 0.05991. Total time 6.25611 hours\n",
      "Training at Epoch 89 iteration 500 with loss 0.08636. Total time 6.26305 hours\n",
      "Training at Epoch 89 iteration 600 with loss 0.07072. Total time 6.27027 hours\n",
      "Training at Epoch 89 iteration 700 with loss 0.10184. Total time 6.27722 hours\n",
      "Training at Epoch 89 iteration 800 with loss 0.06049. Total time 6.28444 hours\n",
      "Validation at Epoch 89 with loss:0.60312, MSE: 0.69862 , Pearson Correlation: 0.81985 with p-value: 0.00E+00 , Concordance Index: 0.81686\n",
      "Training at Epoch 90 iteration 0 with loss 0.07250. Total time 6.29861 hours\n",
      "Training at Epoch 90 iteration 100 with loss 0.09250. Total time 6.30555 hours\n",
      "Training at Epoch 90 iteration 200 with loss 0.07070. Total time 6.3125 hours\n",
      "Training at Epoch 90 iteration 300 with loss 0.06901. Total time 6.31972 hours\n",
      "Training at Epoch 90 iteration 400 with loss 0.09241. Total time 6.32666 hours\n",
      "Training at Epoch 90 iteration 500 with loss 0.06729. Total time 6.33361 hours\n",
      "Training at Epoch 90 iteration 600 with loss 0.08211. Total time 6.34083 hours\n",
      "Training at Epoch 90 iteration 700 with loss 0.07926. Total time 6.34777 hours\n",
      "Training at Epoch 90 iteration 800 with loss 0.08454. Total time 6.35472 hours\n",
      "Validation at Epoch 90 with loss:1.02835, MSE: 0.70144 , Pearson Correlation: 0.81911 with p-value: 0.00E+00 , Concordance Index: 0.81655\n",
      "Training at Epoch 91 iteration 0 with loss 0.06491. Total time 6.36916 hours\n",
      "Training at Epoch 91 iteration 100 with loss 0.07748. Total time 6.37611 hours\n",
      "Training at Epoch 91 iteration 200 with loss 0.09427. Total time 6.38333 hours\n",
      "Training at Epoch 91 iteration 300 with loss 0.08382. Total time 6.39027 hours\n",
      "Training at Epoch 91 iteration 400 with loss 0.06955. Total time 6.3975 hours\n",
      "Training at Epoch 91 iteration 500 with loss 0.10073. Total time 6.40472 hours\n",
      "Training at Epoch 91 iteration 600 with loss 0.09748. Total time 6.41166 hours\n",
      "Training at Epoch 91 iteration 700 with loss 0.12705. Total time 6.41888 hours\n",
      "Training at Epoch 91 iteration 800 with loss 0.07557. Total time 6.42583 hours\n",
      "Validation at Epoch 91 with loss:0.58516, MSE: 0.70286 , Pearson Correlation: 0.81899 with p-value: 0.00E+00 , Concordance Index: 0.81636\n",
      "Training at Epoch 92 iteration 0 with loss 0.09313. Total time 6.44027 hours\n",
      "Training at Epoch 92 iteration 100 with loss 0.07600. Total time 6.44722 hours\n",
      "Training at Epoch 92 iteration 200 with loss 0.08752. Total time 6.45416 hours\n",
      "Training at Epoch 92 iteration 300 with loss 0.10717. Total time 6.46138 hours\n",
      "Training at Epoch 92 iteration 400 with loss 0.08160. Total time 6.46833 hours\n",
      "Training at Epoch 92 iteration 500 with loss 0.09606. Total time 6.47527 hours\n",
      "Training at Epoch 92 iteration 600 with loss 0.07117. Total time 6.4825 hours\n",
      "Training at Epoch 92 iteration 700 with loss 0.09384. Total time 6.48944 hours\n",
      "Training at Epoch 92 iteration 800 with loss 0.08632. Total time 6.49638 hours\n",
      "Validation at Epoch 92 with loss:0.45204, MSE: 0.70687 , Pearson Correlation: 0.81899 with p-value: 0.00E+00 , Concordance Index: 0.81656\n",
      "Training at Epoch 93 iteration 0 with loss 0.07231. Total time 6.51055 hours\n",
      "Training at Epoch 93 iteration 100 with loss 0.09596. Total time 6.51777 hours\n",
      "Training at Epoch 93 iteration 200 with loss 0.10155. Total time 6.525 hours\n",
      "Training at Epoch 93 iteration 300 with loss 0.09410. Total time 6.53194 hours\n",
      "Training at Epoch 93 iteration 400 with loss 0.08344. Total time 6.53916 hours\n",
      "Training at Epoch 93 iteration 500 with loss 0.09710. Total time 6.54611 hours\n",
      "Training at Epoch 93 iteration 600 with loss 0.07097. Total time 6.55333 hours\n",
      "Training at Epoch 93 iteration 700 with loss 0.07593. Total time 6.56027 hours\n",
      "Training at Epoch 93 iteration 800 with loss 0.08908. Total time 6.5675 hours\n",
      "Validation at Epoch 93 with loss:0.64799, MSE: 0.70671 , Pearson Correlation: 0.81857 with p-value: 0.00E+00 , Concordance Index: 0.81629\n",
      "Training at Epoch 94 iteration 0 with loss 0.08749. Total time 6.58166 hours\n",
      "Training at Epoch 94 iteration 100 with loss 0.06378. Total time 6.58861 hours\n",
      "Training at Epoch 94 iteration 200 with loss 0.06200. Total time 6.59583 hours\n",
      "Training at Epoch 94 iteration 300 with loss 0.06729. Total time 6.60277 hours\n",
      "Training at Epoch 94 iteration 400 with loss 0.11146. Total time 6.61 hours\n",
      "Training at Epoch 94 iteration 500 with loss 0.06924. Total time 6.61694 hours\n",
      "Training at Epoch 94 iteration 600 with loss 0.07309. Total time 6.62388 hours\n",
      "Training at Epoch 94 iteration 700 with loss 0.08213. Total time 6.63083 hours\n",
      "Training at Epoch 94 iteration 800 with loss 0.07407. Total time 6.63805 hours\n",
      "Validation at Epoch 94 with loss:0.68098, MSE: 0.70497 , Pearson Correlation: 0.81978 with p-value: 0.00E+00 , Concordance Index: 0.81703\n",
      "Training at Epoch 95 iteration 0 with loss 0.05643. Total time 6.65222 hours\n",
      "Training at Epoch 95 iteration 100 with loss 0.06156. Total time 6.65916 hours\n",
      "Training at Epoch 95 iteration 200 with loss 0.06507. Total time 6.66638 hours\n",
      "Training at Epoch 95 iteration 300 with loss 0.07518. Total time 6.67361 hours\n",
      "Training at Epoch 95 iteration 400 with loss 0.07223. Total time 6.68055 hours\n",
      "Training at Epoch 95 iteration 500 with loss 0.11769. Total time 6.68777 hours\n",
      "Training at Epoch 95 iteration 600 with loss 0.07395. Total time 6.69472 hours\n",
      "Training at Epoch 95 iteration 700 with loss 0.07831. Total time 6.70194 hours\n",
      "Training at Epoch 95 iteration 800 with loss 0.08206. Total time 6.70888 hours\n",
      "Validation at Epoch 95 with loss:0.51686, MSE: 0.70683 , Pearson Correlation: 0.81875 with p-value: 0.00E+00 , Concordance Index: 0.81641\n",
      "Training at Epoch 96 iteration 0 with loss 0.06206. Total time 6.72361 hours\n",
      "Training at Epoch 96 iteration 100 with loss 0.06579. Total time 6.73083 hours\n",
      "Training at Epoch 96 iteration 200 with loss 0.07152. Total time 6.73777 hours\n",
      "Training at Epoch 96 iteration 300 with loss 0.09696. Total time 6.745 hours\n",
      "Training at Epoch 96 iteration 400 with loss 0.09111. Total time 6.75194 hours\n",
      "Training at Epoch 96 iteration 500 with loss 0.08976. Total time 6.75888 hours\n",
      "Training at Epoch 96 iteration 600 with loss 0.06632. Total time 6.76583 hours\n",
      "Training at Epoch 96 iteration 700 with loss 0.06034. Total time 6.77305 hours\n",
      "Training at Epoch 96 iteration 800 with loss 0.11703. Total time 6.78 hours\n",
      "Validation at Epoch 96 with loss:0.69405, MSE: 0.70904 , Pearson Correlation: 0.81934 with p-value: 0.00E+00 , Concordance Index: 0.81681\n",
      "Training at Epoch 97 iteration 0 with loss 0.04822. Total time 6.79444 hours\n",
      "Training at Epoch 97 iteration 100 with loss 0.06201. Total time 6.80138 hours\n",
      "Training at Epoch 97 iteration 200 with loss 0.11301. Total time 6.80861 hours\n",
      "Training at Epoch 97 iteration 300 with loss 0.05611. Total time 6.81555 hours\n",
      "Training at Epoch 97 iteration 400 with loss 0.10957. Total time 6.8225 hours\n",
      "Training at Epoch 97 iteration 500 with loss 0.05331. Total time 6.82972 hours\n",
      "Training at Epoch 97 iteration 600 with loss 0.07320. Total time 6.83666 hours\n",
      "Training at Epoch 97 iteration 700 with loss 0.09968. Total time 6.84388 hours\n",
      "Training at Epoch 97 iteration 800 with loss 0.10215. Total time 6.85111 hours\n",
      "Validation at Epoch 97 with loss:0.54156, MSE: 0.70355 , Pearson Correlation: 0.81916 with p-value: 0.00E+00 , Concordance Index: 0.81664\n",
      "Training at Epoch 98 iteration 0 with loss 0.07795. Total time 6.86583 hours\n",
      "Training at Epoch 98 iteration 100 with loss 0.06518. Total time 6.87305 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 98 iteration 200 with loss 0.06711. Total time 6.88027 hours\n",
      "Training at Epoch 98 iteration 300 with loss 0.08551. Total time 6.8875 hours\n",
      "Training at Epoch 98 iteration 400 with loss 0.07223. Total time 6.89444 hours\n",
      "Training at Epoch 98 iteration 500 with loss 0.10641. Total time 6.90166 hours\n",
      "Training at Epoch 98 iteration 600 with loss 0.06565. Total time 6.90861 hours\n",
      "Training at Epoch 98 iteration 700 with loss 0.10730. Total time 6.91583 hours\n",
      "Training at Epoch 98 iteration 800 with loss 0.10277. Total time 6.92305 hours\n",
      "Validation at Epoch 98 with loss:0.67991, MSE: 0.70402 , Pearson Correlation: 0.81954 with p-value: 0.00E+00 , Concordance Index: 0.81668\n",
      "Training at Epoch 99 iteration 0 with loss 0.07469. Total time 6.93722 hours\n",
      "Training at Epoch 99 iteration 100 with loss 0.07695. Total time 6.94416 hours\n",
      "Training at Epoch 99 iteration 200 with loss 0.08508. Total time 6.95166 hours\n",
      "Training at Epoch 99 iteration 300 with loss 0.06241. Total time 6.95888 hours\n",
      "Training at Epoch 99 iteration 400 with loss 0.07310. Total time 6.96611 hours\n",
      "Training at Epoch 99 iteration 500 with loss 0.06416. Total time 6.97305 hours\n",
      "Training at Epoch 99 iteration 600 with loss 0.08712. Total time 6.98 hours\n",
      "Training at Epoch 99 iteration 700 with loss 0.08776. Total time 6.98722 hours\n",
      "Training at Epoch 99 iteration 800 with loss 0.07616. Total time 6.99416 hours\n",
      "Validation at Epoch 99 with loss:0.61216, MSE: 0.69304 , Pearson Correlation: 0.82083 with p-value: 0.00E+00 , Concordance Index: 0.81711\n",
      "Training at Epoch 100 iteration 0 with loss 0.07916. Total time 7.00861 hours\n",
      "Training at Epoch 100 iteration 100 with loss 0.04923. Total time 7.01555 hours\n",
      "Training at Epoch 100 iteration 200 with loss 0.07867. Total time 7.0225 hours\n",
      "Training at Epoch 100 iteration 300 with loss 0.08434. Total time 7.02972 hours\n",
      "Training at Epoch 100 iteration 400 with loss 0.08334. Total time 7.03666 hours\n",
      "Training at Epoch 100 iteration 500 with loss 0.07315. Total time 7.04388 hours\n",
      "Training at Epoch 100 iteration 600 with loss 0.08056. Total time 7.05111 hours\n",
      "Training at Epoch 100 iteration 700 with loss 0.05711. Total time 7.05833 hours\n",
      "Training at Epoch 100 iteration 800 with loss 0.08871. Total time 7.06555 hours\n",
      "Validation at Epoch 100 with loss:0.66749, MSE: 0.70157 , Pearson Correlation: 0.81880 with p-value: 0.00E+00 , Concordance Index: 0.81618\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.6946947715637034 , Pearson Correlation: 0.8218908299094938 with p-value: 0.00E+00 , Concordance Index: 0.8179830375968684\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/r3/title_r3_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r3/model_morgan_cnn_r3_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r1/title_r1_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'Transformer'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r1/model_cnn_trans_r1_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r2/title_r2_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'Transformer'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r2/model_cnn_trans_r2_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r3/title_r3_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'Transformer'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r3/model_cnn_trans_r3_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r1/title_r1_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r1/model_morgan_aac_r1_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r2/title_r2_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r2/model_morgan_aac_r2_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r3/title_r3_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r3/model_morgan_aac_r3_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r1/title_r1_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r1/model_daylight_aac_r1_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r2/title_r2_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r2/model_daylight_aac_r2_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/r3/title_r3_320k.csv', sep = ',', error_bad_lines=False)\n",
    "X_drug, X_target, y = df['Drug'].values, df['Target'].values, df['Label'].values\n",
    "\n",
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y,\n",
    "                                drug_encoding, target_encoding,\n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding,\n",
    "                         target_encoding = target_encoding,\n",
    "                         cls_hidden_dims = [1024,1024,512],\n",
    "                         train_epoch = 100,\n",
    "                         LR = 0.001,\n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                         )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)\n",
    "model.save_model('./result/DeepDTA/r3/model_daylight_aac_r3_320k_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
